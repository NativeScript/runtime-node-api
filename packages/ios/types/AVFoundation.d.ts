/// <reference types="@nativescript/objc-node-api" />
/// <reference path="./QuartzCore.d.ts" />
/// <reference path="./Foundation.d.ts" />
/// <reference path="./Runtime.d.ts" />

declare const AVCaptureSystemPressureLevelShutdown: string;

declare const AVCaptureSystemPressureLevelSerious: string;

declare const AVSemanticSegmentationMatteTypeHair: string;

declare const AVSemanticSegmentationMatteTypeSkin: string;

declare const AVMetadataObjectTypeMicroQRCode: string;

declare const AVMetadataObjectTypeGS1DataBarExpandedCode: string;

declare const AVMetadataObjectTypeGS1DataBarCode: string;

declare const AVMetadataObjectTypeDataMatrixCode: string;

declare const AVMetadataObjectTypeQRCode: string;

declare const AVMetadataObjectTypeCode128Code: string;

declare const AVMetadataObjectTypeEAN13Code: string;

declare const AVMetadataObjectTypeCode39Mod43Code: string;

declare const AVMetadataObjectTypeDogBody: string;

declare const AVMetadataObjectTypeCatBody: string;

declare const AVMetadataObjectTypeHumanFullBody: string;

declare const AVCaptureSessionInterruptionEndedNotification: string;

declare const AVCaptureSessionInterruptionReasonKey: string;

declare const AVCaptureSessionWasInterruptedNotification: string;

declare const AVCaptureSessionDidStartRunningNotification: string;

declare const AVCaptureSessionErrorKey: string;

declare const AVCaptureWhiteBalanceGainsCurrent: AVCaptureWhiteBalanceGains;

declare const AVCaptureExposureDurationCurrent: CMTime;

declare const AVCaptureLensPositionCurrent: number;

declare const AVCaptureMaxAvailableTorchLevel: number;

declare const AVCaptureDeviceTypeBuiltInMicrophone: string;

declare const AVCaptureDeviceTypeContinuityCamera: string;

declare const AVCaptureDeviceTypeBuiltInLiDARDepthCamera: string;

declare const AVCaptureDeviceTypeBuiltInTrueDepthCamera: string;

declare const AVCaptureDeviceTypeBuiltInDualWideCamera: string;

declare const AVCaptureDeviceTypeBuiltInDualCamera: string;

declare const AVCaptureDeviceTypeBuiltInUltraWideCamera: string;

declare const AVCaptureDeviceTypeMicrophone: string;

declare const AVCaptureDeviceTypeExternal: string;

declare const AVCaptureDeviceSubjectAreaDidChangeNotification: string;

declare const AVCaptureDeviceWasDisconnectedNotification: string;

declare const AVCaptureReactionTypeLasers: string;

declare const AVCaptureReactionTypeRain: string;

declare const AVCaptureReactionTypeHeart: string;

declare const AVCaptureReactionTypeThumbsUp: string;

declare const AVMetadataObjectTypeEAN8Code: string;

declare const AVCaptureSessionPresetiFrame1280x720: string;

declare const AVCaptureSessionPresetiFrame960x540: string;

declare const AVCaptureSessionPreset3840x2160: string;

declare const AVCaptureSessionPreset1920x1080: string;

declare const AVSemanticSegmentationMatteTypeGlasses: string;

declare const AVCaptureSessionPreset1280x720: string;

declare const AVCaptureSessionPreset640x480: string;

declare const AVCaptureSessionPreset352x288: string;

declare const AVCaptureSessionPresetLow: string;

declare const AVCaptureSessionPresetMedium: string;

declare const AVCaptureSessionPresetHigh: string;

declare const AVCaptureSessionPresetPhoto: string;

declare const AVSampleBufferVideoRendererDidFailToDecodeNotificationErrorKey: string;

declare const AVSampleBufferVideoRendererDidFailToDecodeNotification: string;

declare const AVSampleBufferDisplayLayerRequiresFlushToResumeDecodingDidChangeNotification: string;

declare const AVSampleBufferDisplayLayerFailedToDecodeNotificationErrorKey: string;

declare const AVSampleBufferAudioRendererFlushTimeKey: string;

declare const AVSampleBufferAudioRendererOutputConfigurationDidChangeNotification: string;

declare const AVSampleBufferAudioRendererWasFlushedAutomaticallyNotification: string;

declare const AVRouteDetectorMultipleRoutesDetectedDidChangeNotification: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncReasonLoadedTimeRangesChanged: string;

declare const AVMetadataObjectTypeAztecCode: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncReasonCurrentSegmentChanged: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncReasonSegmentsChanged: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncNotification: string;

declare const AVPlayerWaitingDuringInterstitialEventReason: string;

declare const AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChangeStatusKey: string;

declare const AVPlayerInterstitialEventLeaveCue: string;

declare const AVCaptureDeviceTypeBuiltInDuoCamera: string;

declare const AVPlayerInterstitialEventNoCue: string;

declare const AVPlayerItemLegibleOutputTextStylingResolutionSourceAndRulesOnly: string;

declare const AVPlayerItemLegibleOutputTextStylingResolutionDefault: string;

declare const AVPlayerItemFailedToPlayToEndTimeErrorKey: string;

declare const AVPlayerItemMediaSelectionDidChangeNotification: string;

declare const AVPlayerItemRecommendedTimeOffsetFromLiveDidChangeNotification: string;

declare const AVPlayerItemNewErrorLogEntryNotification: string;

declare const AVPlayerItemNewAccessLogEntryNotification: string;

declare const AVPlayerItemPlaybackStalledNotification: string;

declare const AVPlayerItemTimeJumpedNotification: string;

declare const AVCoordinatedPlaybackSuspensionReasonUserIsChangingCurrentTime: string;

declare const AVCoordinatedPlaybackSuspensionReasonUserActionRequired: string;

declare const AVCoordinatedPlaybackSuspensionReasonPlayingInterstitial: string;

declare const AVPlayerEligibleForHDRPlaybackDidChangeNotification: string;

declare const AVPlayerWaitingWithNoItemToPlayReason: string;

declare const AVPlayerWaitingWhileEvaluatingBufferingRateReason: string;

declare const AVPlayerWaitingToMinimizeStallsReason: string;

declare const AVPlayerRateDidChangeReasonAppBackgrounded: string;

declare const AVPlayerRateDidChangeReasonAudioSessionInterrupted: string;

declare const AVPlayerRateDidChangeReasonSetRateFailed: string;

declare const AVPlayerRateDidChangeOriginatingParticipantKey: string;

declare const AVPlayerIntegratedTimelineSnapshotsOutOfSyncReasonKey: string;

declare const AVOutputSettingsPresetMVHEVC1440x1440: string;

declare const AVOutputSettingsPresetMVHEVC960x960: string;

declare const AVOutputSettingsPresetHEVC3840x2160: string;

declare const AVOutputSettingsPresetHEVC1920x1080: string;

declare const AVOutputSettingsPreset1280x720: string;

declare const AVOutputSettingsPreset640x480: string;

declare const AVFragmentedMovieWasDefragmentedNotification: string;

declare const AVFragmentedMovieDurationDidChangeNotification: string;

declare const AVMovieShouldSupportAliasDataReferencesKey: string;

declare const AVMovieReferenceRestrictionsKey: string;

declare const AVFragmentedMovieTrackTimeRangeDidChangeNotification: string;

declare const AVMetadataIdentifierIcyMetadataStreamURL: string;

declare const AVMetadataIdentifierIcyMetadataStreamTitle: string;

declare const AVMetadataIdentifierID3MetadataUserURL: string;

declare const AVMetadataIdentifierID3MetadataPayment: string;

declare const AVMetadataIdentifierID3MetadataOfficialInternetRadioStationHomepage: string;

declare const AVMetadataIdentifierID3MetadataOfficialAudioSourceWebpage: string;

declare const AVMetadataIdentifierID3MetadataOfficialArtistWebpage: string;

declare const AVMetadataIdentifierID3MetadataCommercialInformation: string;

declare const AVMetadataIdentifierID3MetadataUnsynchronizedLyric: string;

declare const AVMetadataIdentifierID3MetadataUniqueFileIdentifier: string;

declare const AVMetadataIdentifierID3MetadataUserText: string;

declare const AVMetadataIdentifierID3MetadataYear: string;

declare const AVMetadataIdentifierID3MetadataSetSubtitle: string;

declare const AVMetadataIdentifierID3MetadataEncodedWith: string;

declare const AVMetadataIdentifierID3MetadataTitleSortOrder: string;

declare const AVMetadataIdentifierID3MetadataSize: string;

declare const AVMetadataIdentifierID3MetadataPublisher: string;

declare const AVMetadataIdentifierID3MetadataProducedNotice: string;

declare const AVMetadataIdentifierID3MetadataConductor: string;

declare const AVMetadataIdentifierID3MetadataModifiedBy: string;

declare const AVMetadataIdentifierID3MetadataLeadPerformer: string;

declare const AVMetadataIdentifierID3MetadataOriginalArtist: string;

declare const AVMetadataIdentifierID3MetadataOriginalLyricist: string;

declare const AVMetadataIdentifierID3MetadataOriginalFilename: string;

declare const AVMetadataIdentifierID3MetadataSubTitle: string;

declare const AVMetadataIdentifierID3MetadataContentGroupDescription: string;

declare const AVMetadataIdentifierID3MetadataInvolvedPeopleList_v24: string;

declare const AVMetadataIdentifierID3MetadataTime: string;

declare const AVMetadataIdentifierID3MetadataTaggingTime: string;

declare const AVMetadataIdentifierID3MetadataRecordingTime: string;

declare const AVMetadataIdentifierID3MetadataContentType: string;

declare const AVMetadataIdentifierID3MetadataComposer: string;

declare const AVMetadataIdentifierID3MetadataAlbumTitle: string;

declare const AVMetadataIdentifierID3MetadataReverb: string;

declare const AVMetadataIdentifierID3MetadataOriginalReleaseYear: string;

declare const AVMetadataIdentifierQuickTimeUserDataArranger: string;

declare const AVMetadataIdentifierID3MetadataRelativeVolumeAdjustment: string;

declare const AVMetadataIdentifierID3MetadataPrivate: string;

declare const AVMetadataIdentifierID3MetadataMPEGLocationLookupTable: string;

declare const AVMetadataIdentifieriTunesMetadataAccountKind: string;

declare const AVMetadataIdentifierID3MetadataMusicCDIdentifier: string;

declare const AVMetadataIdentifierID3MetadataLink: string;

declare const AVMetadataIdentifierID3MetadataGroupIdentifier: string;

declare const AVMetadataIdentifierID3MetadataEncryption: string;

declare const AVMetadataIdentifieriTunesMetadataProducer: string;

declare const AVMetadataIdentifieriTunesMetadataPhonogramRights: string;

declare const AVMetadataIdentifieriTunesMetadataLinerNotes: string;

declare const AVMetadataIdentifieriTunesMetadataDescription: string;

declare const AVMetadataIdentifieriTunesMetadataConductor: string;

declare const AVMetadataIdentifieriTunesMetadataLyrics: string;

declare const AVMetadataIdentifieriTunesMetadataTrackNumber: string;

declare const AVMetadataIdentifieriTunesMetadataPlaylistID: string;

declare const AVMetadataIdentifieriTunesMetadataGrouping: string;

declare const AVMetadataIdentifieriTunesMetadataDiscNumber: string;

declare const AVMetadataIdentifieriTunesMetadataDiscCompilation: string;

declare const AVMetadataIdentifieriTunesMetadataSongID: string;

declare const AVMetadataIdentifieriTunesMetadataArtistID: string;

declare const AVMetadataIdentifieriTunesMetadataEncodingTool: string;

declare const AVMetadataIdentifieriTunesMetadataEncodedBy: string;

declare const AVMetadataIdentifieriTunesMetadataCopyright: string;

declare const AVMetadataIdentifieriTunesMetadataArtist: string;

declare const AVMetadataIdentifieriTunesMetadataAlbum: string;

declare const AVMetadataIdentifierQuickTimeMetadataSpatialOverCaptureQualityScoringVersion: string;

declare const AVMetadataIdentifierQuickTimeMetadataLivePhotoVitalityScoringVersion: string;

declare const AVMetadataIdentifierQuickTimeMetadataAccessibilityDescription: string;

declare const AVMetadataIdentifierQuickTimeMetadataContentIdentifier: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedSalientObject: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedDogBody: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationDate: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationRole: string;

declare const AVMetadataIdentifierQuickTimeMetadataArtwork: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationNote: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationBody: string;

declare const AVMetadataIdentifierQuickTimeMetadataRatingUser: string;

declare const AVMetadataIdentifierQuickTimeMetadataPerformer: string;

declare const AVMetadataIdentifierQuickTimeMetadataArranger: string;

declare const AVMediaCharacteristicAudible: string;

declare const AVMetadataIdentifierQuickTimeMetadataMake: string;

declare const AVMetadataIdentifierQuickTimeMetadataGenre: string;

declare const AVMetadataIdentifierQuickTimeMetadataSoftware: string;

declare const AVMetadataIdentifierQuickTimeMetadataDescription: string;

declare const AVMetadataIdentifierQuickTimeMetadataDirector: string;

declare const AVMetadataISOUserDataKeyTaggedCharacteristic: string;

declare const AVMetadataIdentifierQuickTimeMetadataCreationDate: string;

declare const AVMetadataIdentifierQuickTimeMetadataComment: string;

declare const AVMetadataIdentifier3GPUserDataMediaRating: string;

declare const AVMetadataIdentifier3GPUserDataUserRating: string;

declare const AVMetadataiTunesMetadataKeyTrackNumber: string;

declare const AVMetadataIdentifier3GPUserDataGenre: string;

declare const AVMetadataIdentifier3GPUserDataPerformer: string;

declare const AVMetadataIdentifier3GPUserDataCopyright: string;

declare const AVMetadataIdentifierID3MetadataOriginalAlbumTitle: string;

declare const AVMetadataIdentifierISOUserDataDate: string;

declare const AVMetadataIdentifierQuickTimeUserDataTrackName: string;

declare const AVMetadataIdentifierQuickTimeUserDataWriter: string;

declare const AVMetadataIdentifierQuickTimeUserDataOriginalSource: string;

declare const AVMetadataIdentifierQuickTimeUserDataOriginalFormat: string;

declare const AVMetadataIdentifierQuickTimeUserDataOriginalArtist: string;

declare const AVMetadataIdentifierQuickTimeUserDataModel: string;

declare const AVMetadataIdentifierQuickTimeUserDataGenre: string;

declare const AVMetadataIdentifierQuickTimeUserDataFullName: string;

declare const AVMetadataIdentifierQuickTimeUserDataComposer: string;

declare const AVMetadataIdentifierQuickTimeUserDataChapter: string;

declare const AVMetadataIdentifierQuickTimeUserDataArtist: string;

declare const AVMetadataIdentifierQuickTimeUserDataAlbum: string;

declare const AVMetadataCommonIdentifierModel: string;

declare const AVMetadataCommonIdentifierAuthor: string;

declare const AVMetadataCommonIdentifierCopyrights: string;

declare const AVMetadataCommonIdentifierLanguage: string;

declare const AVMetadataCommonIdentifierSource: string;

declare const AVMetadataCommonIdentifierCreationDate: string;

declare const AVMetadataCommonIdentifierPublisher: string;

declare const AVMetadataCommonIdentifierSubject: string;

declare const AVMetadataCommonIdentifierCreator: string;

declare const AVErrorFileTypeKey: string;

declare const AVErrorPersistentTrackIDKey: string;

declare const AVErrorTimeKey: string;

declare const AVFoundationErrorDomain: string;

declare const AVCaptionUseDropFrameTimeCodeKey: string;

declare const AVAssetDownloadTaskPrefersHDRKey: string;

declare const AVAssetDownloadTaskMinimumRequiredPresentationSizeKey: string;

declare const AVMetadataIdentifier3GPUserDataAuthor: string;

declare const AVErrorFileSizeKey: string;

declare const AVMetadataIdentifierID3MetadataTitleDescription: string;

declare const AVCaptionConversionAdjustmentTypeTimeRange: string;

declare const AVMetadataIdentifieriTunesMetadataSongName: string;

declare const AVMetadataiTunesMetadataKeyAcknowledgement: string;

declare const AVMetadataIdentifierQuickTimeMetadataIsMontage: string;

declare const AVMetadataIdentifierID3MetadataComments: string;

declare const AVMetadataObjectTypePDF417Code: string;

declare const AVMetadataIdentifierID3MetadataInternationalStandardRecordingCode: string;

declare const AVMetadataIdentifierID3MetadataMusicianCreditsList: string;

declare const AVTrackAssociationTypeSelectionFollower: string;

declare const AVMetadataIdentifierQuickTimeMetadataLivePhotoVitalityScore: string;

declare const AVMetadataQuickTimeUserDataKeySpecialPlaybackRequirements: string;

declare const AVMetadataIdentifierID3MetadataInvolvedPeopleList_v23: string;

declare const AVMetadataQuickTimeUserDataKeyAuthor: string;

declare const AVMetadataIdentifierID3MetadataLanguage: string;

declare const AVCaptureSystemPressureLevelNominal: string;

declare const AVErrorRecordingSuccessfullyFinishedKey: string;

declare const AVSampleBufferVideoRendererRequiresFlushToResumeDecodingDidChangeNotification: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationHorizontalAccuracyInMeters: string;

declare const AVMetadataIdentifierID3MetadataTrackNumber: string;

declare const AVMetadataQuickTimeUserDataKeyPhonogramRights: string;

declare const AVMetadataIdentifierID3MetadataFileOwner: string;

declare const AVMetadata3GPUserDataKeyThumbnail: string;

declare const AVMetadataCommonIdentifierMake: string;

declare const AVVideoMaxKeyFrameIntervalDurationKey: string;

declare const AVMetadataIdentifieriTunesMetadataCoverArt: string;

declare const AVMetadataIdentifierQuickTimeUserDataPublisher: string;

declare const AVPlayerRateDidChangeNotification: string;

declare const AVMetadataIdentifieriTunesMetadataReleaseDate: string;

declare const AVPlayerInterstitialEventMonitorCurrentEventDidChangeNotification: string;

declare const AVMetadataQuickTimeUserDataKeyChapter: string;

declare const AVMetadataIdentifierQuickTimeMetadataProducer: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationName: string;

declare const AVMetadataIdentifierID3MetadataMediaType: string;

declare const AVMetadataIdentifierID3MetadataInternetRadioStationOwner: string;

declare const AVMetadata3GPUserDataKeyKeywordList: string;

declare const AVMetadataIdentifierID3MetadataPerformerSortOrder: string;

declare const AVErrorMediaSubTypeKey: string;

declare const AVMetadataIdentifieriTunesMetadataDirector: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraFrameReadoutTime: string;

declare const AVMetadataIdentifieriTunesMetadataOriginalArtist: string;

declare const AVMetadataIdentifierQuickTimeUserDataHostComputer: string;

declare const AVAssetExportPresetMediumQuality: string;

declare const AVOutputSettingsPreset3840x2160: string;

declare const AVMediaTypeVideo: string;

declare const AVMetadataID3MetadataKeyMPEGLocationLookupTable: string;

declare const AVMetadataIdentifierQuickTimeMetadataDirectionFacing: string;

declare const AVMetadataIdentifierQuickTimeMetadataPreferredAffineTransform: string;

declare const AVMetadataIdentifier3GPUserDataKeywordList: string;

declare const AVMetadataiTunesMetadataKeyGrouping: string;

declare const AVURLAssetPreferPreciseDurationAndTimingKey: string;

declare const AVMetadataIdentifier3GPUserDataTitle: string;

declare const AVMetadataQuickTimeMetadataKeyArranger: string;

declare const AVPlayerItemTimeJumpedOriginatingParticipantKey: string;

declare const AVMetadataIdentifieriTunesMetadataComposer: string;

declare const AVAssetExportPresetHEVCHighestQuality: string;

declare const AVMetadataIdentifierQuickTimeMetadataYear: string;

declare const AVMetadataKeySpaceISOUserData: string;

declare const AVMetadataIdentifierQuickTimeUserDataLocationISO6709: string;

declare const AVMetadataIdentifierID3MetadataOfficialAudioFileWebpage: string;

declare const AVMetadata3GPUserDataKeyUserRating: string;

declare const AVMetadataID3MetadataKeyTime: string;

declare const AVMetadataIdentifier3GPUserDataRecordingYear: string;

declare const AVPlayerInterstitialEventJoinCue: string;

declare const AVMetadataIdentifier3GPUserDataLocation: string;

declare const AVMetadataCommonIdentifierContributor: string;

declare const AVAssetWriterInputMediaDataLocationBeforeMainMediaDataNotInterleaved: string;

declare const AVAssetTrackSegmentsDidChangeNotification: string;

declare const AVAssetTrackTimeRangeDidChangeNotification: string;

declare const AVAssetResourceLoadingRequestStreamingContentKeyRequestRequiresPersistentKey: string;

declare const AVVideoCompositionPerFrameHDRDisplayMetadataPolicyPropagate: string;

declare const AVAssetImageGeneratorApertureModeCleanAperture: string;

declare const AVAssetExportPresetAppleProRes4444LPCM: string;

declare const AVAssetExportPresetAppleProRes422LPCM: string;

declare const AVAssetExportPresetMVHEVC960x960: string;

declare const AVAssetExportPresetHEVC3840x2160WithAlpha: string;

declare const AVAssetExportPreset3840x2160: string;

declare const AVAssetExportPreset1920x1080: string;

declare const AVAssetExportPreset640x480: string;

declare const AVAssetExportPresetHEVCHighestQualityWithAlpha: string;

declare const AVAudioTimePitchAlgorithmSpectral: string;

declare const AVAudioTimePitchAlgorithmLowQualityZeroLatency: string;

declare const AVAssetMediaSelectionGroupsDidChangeNotification: string;

declare const AVAssetWasDefragmentedNotification: string;

declare const AVAssetContainsFragmentsDidChangeNotification: string;

declare const AVURLAssetPrimarySessionIdentifierKey: string;

declare const AVURLAssetHTTPUserAgentKey: string;

declare const AVMetadataIdentifierID3MetadataRecommendedBufferSize: string;

declare const AVMetadataIdentifierQuickTimeMetadataiXML: string;

declare const AVMetadataCommonIdentifierTitle: string;

declare const AVSampleBufferDisplayLayerOutputObscuredDueToInsufficientExternalProtectionDidChangeNotification: string;

declare const AVVideoApertureModeEncodedPixels: string;

declare const AVVideoDecompressionPropertiesKey: string;

declare const AVVideoAverageNonDroppableFrameRateKey: string;

declare const AVVideoProfileLevelH264HighAutoLevel: string;

declare const AVVideoProfileLevelH264Main41: string;

declare const AVMetadataIdentifieriTunesMetadataSoundEngineer: string;

declare const AVVideoProfileLevelH264Main31: string;

declare const AVVideoProfileLevelH264Baseline41: string;

declare const AVVideoProfileLevelH264Baseline30: string;

declare const AVVideoYCbCrMatrix_ITU_R_601_4: string;

declare const AVVideoYCbCrMatrixKey: string;

declare const AVVideoTransferFunction_Linear: string;

declare const AVVideoTransferFunction_ITU_R_2100_HLG: string;

declare const AVVideoTransferFunction_SMPTE_ST_2084_PQ: string;

declare const AVVideoTransferFunction_ITU_R_709_2: string;

declare const AVVideoColorPrimaries_ITU_R_2020: string;

declare const AVLayerVideoGravityResize: string;

declare const AVVideoColorPrimaries_SMPTE_C: string;

declare const AVVideoColorPrimariesKey: string;

declare const AVVideoScalingModeFit: string;

declare const AVVideoCleanApertureHorizontalOffsetKey: string;

declare const AVVideoCleanApertureHeightKey: string;

declare const AVVideoCleanApertureWidthKey: string;

declare const AVVideoPixelAspectRatioKey: string;

declare const AVVideoWidthKey: string;

declare const AVVideoCodecH264: string;

declare const AVMetadataIdentifierID3MetadataAlbumSortOrder: string;

declare const AVVideoCodecTypeHEVCWithAlpha: string;

declare const AVMetadataIdentifierID3MetadataOriginalReleaseTime: string;

declare const AVVideoCodecTypeAppleProRes422LT: string;

declare const AVVideoCodecTypeJPEGXL: string;

declare const AVVideoCodecTypeH264: string;

declare const AVVideoCodecKey: string;

declare const AVMetadataExtraAttributeValueURIKey: string;

declare const AVMetadataKeySpaceAudioFile: string;

declare const AVMetadataKeySpaceHLSDateRange: string;

declare const AVMetadataFormatHLSMetadata: string;

declare const AVMetadataIcyMetadataKeyStreamTitle: string;

declare const AVMetadataIdentifieriTunesMetadataEQ: string;

declare const AVMetadata3GPUserDataKeyRecordingYear: string;

declare const AVMetadataKeySpaceIcy: string;

declare const AVMetadataID3MetadataKeyOfficialAudioSourceWebpage: string;

declare const AVMetadataID3MetadataKeyOfficialArtistWebpage: string;

declare const AVMetadataID3MetadataKeyOfficialAudioFileWebpage: string;

declare const AVMetadataID3MetadataKeyCopyrightInformation: string;

declare const AVMetadataID3MetadataKeyCommercialInformation: string;

declare const AVMetadataID3MetadataKeyTermsOfUse: string;

declare const AVMetadataID3MetadataKeyUniqueFileIdentifier: string;

declare const AVMetadataID3MetadataKeyTitleSortOrder: string;

declare const AVMetadataID3MetadataKeyAlbumSortOrder: string;

declare const AVMetadataID3MetadataKeySize: string;

declare const AVMetadataIdentifierQuickTimeUserDataEncodedBy: string;

declare const AVMetadataIdentifieriTunesMetadataExecProducer: string;

declare const AVMetadataID3MetadataKeyRecordingDates: string;

declare const AVMetadataID3MetadataKeyPublisher: string;

declare const AVMetadataID3MetadataKeyPartOfASet: string;

declare const AVMetadataID3MetadataKeyModifiedBy: string;

declare const AVMetadataID3MetadataKeyFileOwner: string;

declare const AVMetadataID3MetadataKeyOriginalReleaseYear: string;

declare const AVMetadataID3MetadataKeyOriginalArtist: string;

declare const AVMetadataID3MetadataKeyOriginalLyricist: string;

declare const AVCaptureDeviceTypeBuiltInWideAngleCamera: string;

declare const AVMetadataID3MetadataKeyOriginalFilename: string;

declare const AVMetadataID3MetadataKeyMusicianCreditsList: string;

declare const AVMetadataID3MetadataKeyTitleDescription: string;

declare const AVMetadataID3MetadataKeyInvolvedPeopleList_v24: string;

declare const AVMetadataID3MetadataKeyFileType: string;

declare const AVMetadataID3MetadataKeyLyricist: string;

declare const AVMetadataID3MetadataKeyEncodedBy: string;

declare const AVMetadataID3MetadataKeyReleaseTime: string;

declare const AVMetadataID3MetadataKeyOriginalReleaseTime: string;

declare const AVMetadataID3MetadataKeyPlaylistDelay: string;

declare const AVMetadataID3MetadataKeyDate: string;

declare const AVMetadataID3MetadataKeyBeatsPerMinute: string;

declare const AVMetadataID3MetadataKeyAlbumTitle: string;

declare const AVMetadataID3MetadataKeySynchronizedTempoCodes: string;

declare const AVMetadataID3MetadataKeyReverb: string;

declare const AVMetadataIdentifierQuickTimeMetadataFullFrameRatePlaybackIntent: string;

declare const AVMetadataID3MetadataKeyRelativeVolumeAdjustment2: string;

declare const AVMetadataID3MetadataKeyRecommendedBufferSize: string;

declare const AVMetadataID3MetadataKeyPrivate: string;

declare const AVMetadataID3MetadataKeyOwnership: string;

declare const AVMetadataID3MetadataKeyInvolvedPeopleList_v23: string;

declare const AVMetadataID3MetadataKeyLink: string;

declare const AVMetadataID3MetadataKeyEqualization: string;

declare const AVMetadataID3MetadataKeyCommerical: string;

declare const AVMetadataKeySpaceID3: string;

declare const AVMetadataiTunesMetadataKeyExecProducer: string;

declare const AVMetadataiTunesMetadataKeyOnlineExtras: string;

declare const AVMetadataiTunesMetadataKeyThanks: string;

declare const AVMetadataiTunesMetadataKeySoloist: string;

declare const AVMetadataiTunesMetadataKeySoundEngineer: string;

declare const AVMetadataiTunesMetadataKeyPublisher: string;

declare const AVAssetWriterInputMediaDataLocationInterleavedWithMainMediaData: string;

declare const AVMetadataiTunesMetadataKeyProducer: string;

declare const AVMetadataiTunesMetadataKeyEQ: string;

declare const AVMetadataiTunesMetadataKeyDirector: string;

declare const AVMetadataiTunesMetadataKeyDescription: string;

declare const AVMetadataiTunesMetadataKeyAuthor: string;

declare const AVMetadataiTunesMetadataKeyArranger: string;

declare const AVMetadataiTunesMetadataKeyArtDirector: string;

declare const AVMetadataiTunesMetadataKeyBeatsPerMin: string;

declare const AVMetadataiTunesMetadataKeyGenreID: string;

declare const AVMetadataiTunesMetadataKeySongID: string;

declare const AVMetadataiTunesMetadataKeyAppleID: string;

declare const AVMetadataiTunesMetadataKeyPredefinedGenre: string;

declare const AVMetadataiTunesMetadataKeyEncodedBy: string;

declare const AVMetadataiTunesMetadataKeyCoverArt: string;

declare const AVMetadataiTunesMetadataKeyArtist: string;

declare const AVMetadataiTunesMetadataKeyAlbum: string;

declare const AVVideoScalingModeResizeAspectFill: string;

declare const AVMetadataKeySpaceiTunes: string;

declare const AVMetadataQuickTimeMetadataKeyFullFrameRatePlaybackIntent: string;

declare const AVMetadataQuickTimeMetadataKeyAccessibilityDescription: string;

declare const AVMetadataCommonIdentifierFormat: string;

declare const AVMetadataQuickTimeMetadataKeyDirectionFacing: string;

declare const AVMetadataIdentifieriTunesMetadataContentRating: string;

declare const AVMetadataQuickTimeMetadataKeyLocationBody: string;

declare const AVMetadataQuickTimeMetadataKeyLocationName: string;

declare const AVCaptionMediaTypeKey: string;

declare const AVMetadataQuickTimeMetadataKeyRatingUser: string;

declare const AVMetadataQuickTimeMetadataKeyCollectionUser: string;

declare const AVMetadataQuickTimeMetadataKeyTitle: string;

declare const AVMetadataQuickTimeMetadataKeyCameraFrameReadoutTime: string;

declare const AVMetadataQuickTimeMetadataKeyComposer: string;

declare const AVAssetImageGeneratorDynamicRangePolicyForceSDR: string;

declare const AVMetadataQuickTimeMetadataKeyPerformer: string;

declare const AVMetadataiTunesMetadataKeyArtistID: string;

declare const AVMetadataiTunesMetadataKeySongName: string;

declare const AVMetadataQuickTimeMetadataKeyOriginalArtist: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedCatBody: string;

declare const AVMetadataQuickTimeMetadataKeyMake: string;

declare const AVVideoCodecTypeAppleProRes4444XQ: string;

declare const AVMetadataQuickTimeMetadataKeyiXML: string;

declare const AVURLAssetAllowsCellularAccessKey: string;

declare const AVMetadataQuickTimeMetadataKeyYear: string;

declare const AVMetadataQuickTimeMetadataKeyDescription: string;

declare const AVMetadataID3MetadataKeyProducedNotice: string;

declare const AVMetadataQuickTimeMetadataKeyArtwork: string;

declare const AVMetadataQuickTimeMetadataKeyArtist: string;

declare const AVMetadataQuickTimeMetadataKeyProducer: string;

declare const AVMediaCharacteristicContainsOnlyForcedSubtitles: string;

declare const AVMetadataQuickTimeMetadataKeyInformation: string;

declare const AVMetadataQuickTimeMetadataKeyDisplayName: string;

declare const AVMetadataQuickTimeMetadataKeyDirector: string;

declare const AVMetadataQuickTimeMetadataKeyCreationDate: string;

declare const AVMetadataKeySpaceQuickTimeMetadata: string;

declare const AVMetadataFormatQuickTimeMetadata: string;

declare const AVMetadata3GPUserDataKeyMediaClassification: string;

declare const AVMetadata3GPUserDataKeyAlbumAndTrack: string;

declare const AVMetadata3GPUserDataKeyCollection: string;

declare const AVMetadata3GPUserDataKeyDescription: string;

declare const AVMetadata3GPUserDataKeyLocation: string;

declare const AVMetadata3GPUserDataKeyGenre: string;

declare const AVMetadataIdentifieriTunesMetadataUserComment: string;

declare const AVMetadata3GPUserDataKeyAuthor: string;

declare const AVMetadataISOUserDataKeyAccessibilityDescription: string;

declare const AVMetadataISOUserDataKeyCopyright: string;

declare const AVMetadataFormatISOUserData: string;

declare const AVMetadataQuickTimeUserDataKeyTrackName: string;

declare const AVMetadataQuickTimeUserDataKeyLocationISO6709: string;

declare const AVMetadataID3MetadataKeyLeadPerformer: string;

declare const AVMetadataQuickTimeUserDataKeyURLLink: string;

declare const AVTrackAssociationTypeMetadataReferent: string;

declare const AVMetadataQuickTimeUserDataKeyWriter: string;

declare const AVMetadataQuickTimeUserDataKeyWarning: string;

declare const AVMetadataQuickTimeUserDataKeyTrack: string;

declare const AVMetadataQuickTimeUserDataKeySoftware: string;

declare const AVMetadataID3MetadataKeySetSubtitle: string;

declare const AVMetadataQuickTimeUserDataKeyProduct: string;

declare const AVMetadataQuickTimeUserDataKeyPublisher: string;

declare const AVMetadataQuickTimeUserDataKeyProducer: string;

declare const AVMetadataQuickTimeUserDataKeyPerformers: string;

declare const AVMetadataQuickTimeUserDataKeyOriginalSource: string;

declare const AVMetadataQuickTimeUserDataKeyOriginalArtist: string;

declare const AVMetadataQuickTimeUserDataKeyModel: string;

declare const AVMetadataQuickTimeUserDataKeyHostComputer: string;

declare const AVMetadataQuickTimeUserDataKeyGenre: string;

declare const AVMetadataQuickTimeUserDataKeyEncodedBy: string;

declare const AVMetadataQuickTimeUserDataKeyDirector: string;

declare const AVMetadataQuickTimeUserDataKeyCreationDate: string;

declare const AVFileTypeEnhancedAC3: string;

declare const AVMetadataQuickTimeUserDataKeyComposer: string;

declare const AVMetadataQuickTimeUserDataKeyComment: string;

declare const AVMetadataQuickTimeUserDataKeyAlbum: string;

declare const AVMetadataKeySpaceQuickTimeUserData: string;

declare const AVMetadataCommonKeyModel: string;

declare const AVMetadataCommonKeyAuthor: string;

declare const AVMetadataCommonKeyAlbumName: string;

declare const AVMetadataCommonKeyLanguage: string;

declare const AVMetadataCommonKeyIdentifier: string;

declare const AVMetadataCommonKeyFormat: string;

declare const AVMetadataCommonKeyContributor: string;

declare const AVMetadataCommonKeyPublisher: string;

declare const AVMetadataCommonKeyDescription: string;

declare const AVMetadataCommonKeySubject: string;

declare const AVMetadataCommonKeyCreator: string;

declare const AVMetadataKeySpaceCommon: string;

declare const AVMetadataQuickTimeMetadataKeyCredits: string;

declare const AVFileTypeProfileMPEG4CMAFCompliant: string;

declare const AVFileTypeProfileMPEG4AppleHLS: string;

declare const AVFileTypeAHAP: string;

declare const AVFileTypeSCC: string;

declare const AVFileTypeAppleiTT: string;

declare const AVFileTypeTIFF: string;

declare const AVFileTypeHEIF: string;

declare const AVFileTypeAVCI: string;

declare const AVVideoCompositionPerFrameHDRDisplayMetadataPolicyGenerate: string;

declare const AVFileTypeDNG: string;

declare const AVFileTypeSunAU: string;

declare const AVMetadataIdentifierQuickTimeMetadataDisplayName: string;

declare const AVMetadataIdentifier3GPUserDataMediaClassification: string;

declare const AVFileTypeCoreAudioFormat: string;

declare const AVFileType3GPP2: string;

declare const AVFileType3GPP: string;

declare const AVFileTypeAppleM4A: string;

declare const AVFileTypeAppleM4V: string;

declare const AVFileTypeQuickTimeMovie: string;

declare const AVMediaCharacteristicVoiceOverTranslation: string;

declare const AVMediaCharacteristicLanguageTranslation: string;

declare const AVMediaCharacteristicEasyToRead: string;

declare const AVMediaCharacteristicEnhancesSpeechIntelligibility: string;

declare const AVMetadataIdentifierID3MetadataAudioEncryption: string;

declare const AVMediaCharacteristicDescribesMusicAndSoundForAccessibility: string;

declare const AVMediaCharacteristicIsAuxiliaryContent: string;

declare const AVTrackAssociationTypeForcedSubtitlesOnly: string;

declare const AVMediaCharacteristicFrameBased: string;

declare const AVMediaCharacteristicLegible: string;

declare const AVMediaTypeMetadataObject: string;

declare const AVVideoRangePQ: string;

declare const AVVideoRangeSDR: string;

declare const AVMediaTypeMetadata: string;

declare const AVMediaTypeClosedCaption: string;

declare const AVMediaTypeText: string;

declare const AVMediaTypeAudio: string;

declare const AVContentKeyRequestRetryReasonReceivedObsoleteContentKey: string;

declare const AVContentKeySystemAuthorizationToken: string;

declare const AVContentKeySystemClearKey: string;

declare const AVContentKeySystemFairPlayStreaming: string;

declare const AVMetadataiTunesMetadataKeyDiscCompilation: string;

declare const AVMetadataIdentifierQuickTimeUserDataCredits: string;

declare const AVMetadataIdentifierID3MetadataSynchronizedLyric: string;

declare const AVPlayerAvailableHDRModesDidChangeNotification: string;

declare const AVAssetExportPresetLowQuality: string;

declare const AVVideoCodecJPEG: string;

declare const AVMetadataIdentifierID3MetadataPlayCounter: string;

declare const AVMetadataIdentifierID3MetadataEventTimingCodes: string;

declare const AVMetadataID3MetadataKeyInternetRadioStationName: string;

declare const AVVideoCompressionPropertiesKey: string;

declare const AVMetadataIdentifierQuickTimeUserDataDirector: string;

declare const AVVideoApertureModeCleanAperture: string;

declare const AVMetadataIdentifierID3MetadataPlaylistDelay: string;

declare const AVVideoProfileLevelH264Baseline31: string;

declare const AVVideoCleanApertureKey: string;

declare const AVContentKeySessionServerPlaybackContextOptionServerChallenge: string;

declare const AVMediaCharacteristicContainsHDRVideo: string;

declare const AVVideoProfileLevelH264Main32: string;

declare const AVMetadataQuickTimeUserDataKeyFullName: string;

declare const AVMetadataObjectTypeUPCECode: string;

declare const AVMetadataIdentifierID3MetadataDate: string;

declare const AVMediaCharacteristicDescribesVideoForAccessibility: string;

declare const AVMetadataCommonKeyAccessibilityDescription: string;

declare const AVMetadataQuickTimeMetadataKeyCameraIdentifier: string;

declare const AVMetadataIdentifierID3MetadataEncodingTime: string;

declare const AVMetadataIdentifierID3MetadataReleaseTime: string;

declare const AVLayerVideoGravityResizeAspect: string;

declare const AVStreamingKeyDeliveryContentKeyType: string;

declare const AVCoordinatedPlaybackSuspensionReasonStallRecovery: string;

declare const AVMetadataQuickTimeUserDataKeyKeywords: string;

declare const AVVideoProfileLevelH264High40: string;

declare const AVVideoColorPrimaries_ITU_R_709_2: string;

declare const AVAssetDownloadTaskMinimumRequiredMediaBitrateKey: string;

declare const AVMetadataQuickTimeUserDataKeyInformation: string;

declare const AVMetadataiTunesMetadataKeyConductor: string;

declare const AVMetadataIdentifierQuickTimeMetadataAuthor: string;

declare const AVCaptionConversionWarningTypeExcessMediaData: string;

declare const AVMetadataIdentifierQuickTimeUserDataMake: string;

declare const AVMetadataiTunesMetadataKeyPhonogramRights: string;

declare const AVMediaCharacteristicIsMainProgramContent: string;

declare const AVVideoCodecTypeAppleProRes4444: string;

declare const AVFileTypeHEIC: string;

declare const AVMetadataIdentifieriTunesMetadataSoloist: string;

declare const AVMetadataIdentifierID3MetadataGeneralEncapsulatedObject: string;

declare const AVMetadataISOUserDataKeyDate: string;

declare const AVMetadataID3MetadataKeyComments: string;

declare const AVMetadataQuickTimeMetadataKeyModel: string;

declare const AVMetadataQuickTimeMetadataKeyLocationDate: string;

declare const AVMetadataIdentifierID3MetadataBand: string;

declare const AVMetadataIdentifierID3MetadataLength: string;

declare const AVMetadataIdentifierQuickTimeUserDataDisclaimer: string;

declare const AVMetadataiTunesMetadataKeyUserComment: string;

declare const AVMetadataIdentifieriTunesMetadataRecordCompany: string;

declare const AVVideoMaxKeyFrameIntervalKey: string;

declare const AVMetadataIdentifierID3MetadataInitialKey: string;

declare const AVMetadataExtraAttributeInfoKey: string;

declare const AVMetadataObjectTypeITF14Code: string;

declare const AVMetadataID3MetadataKeyEqualization2: string;

declare const AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChangeNotification: string;

declare const AVMetadataQuickTimeMetadataKeyPhonogramRights: string;

declare const AVMetadataIdentifierID3MetadataOfficialPublisherWebpage: string;

declare const AVAssetPlaybackConfigurationOptionStereoVideo: string;

declare const AVMetadataiTunesMetadataKeyLinerNotes: string;

declare const AVVideoRangeHLG: string;

declare const AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChangeErrorKey: string;

declare const AVMetadataIdentifier3GPUserDataThumbnail: string;

declare const AVMediaTypeAuxiliaryPicture: string;

declare const AVCaptionTimeCodeFrameDurationKey: string;

declare const AVMetadataIdentifierID3MetadataSignature: string;

declare const AVCaptureSystemPressureLevelCritical: string;

declare const AVMetadataCommonIdentifierAlbumName: string;

declare const AVMetadataID3MetadataKeyTaggingTime: string;

declare const AVMediaCharacteristicIsOriginalContent: string;

declare const AVCoordinatedPlaybackSuspensionReasonAudioSessionInterrupted: string;

declare const AVAssetImageGeneratorApertureModeEncodedPixels: string;

declare const AVVideoTransferFunction_IEC_sRGB: string;

declare const AVFileTypeMPEGLayer3: string;

declare const AVMetadataID3MetadataKeyUnsynchronizedLyric: string;

declare const AVMetadataFormatID3Metadata: string;

declare const AVFileTypeAMR: string;

declare const AVMetadataIdentifierQuickTimeUserDataAuthor: string;

declare const AVMetadataIdentifierQuickTimeUserDataSoftware: string;

declare const AVMetadataQuickTimeMetadataKeyEncodedBy: string;

declare const AVMetadataIdentifierQuickTimeUserDataCreationDate: string;

declare const AVAssetExportPreset960x540: string;

declare const AVURLAssetAllowsExpensiveNetworkAccessKey: string;

declare const AVSampleBufferDisplayLayerFailedToDecodeNotification: string;

declare const AVOutputSettingsPresetHEVC1920x1080WithAlpha: string;

declare const AVMetadataIdentifieriTunesMetadataThanks: string;

declare const AVMetadataFormatUnknown: string;

declare const AVVideoCodecTypeHEVC: string;

declare const AVSemanticSegmentationMatteTypeTeeth: string;

declare const AVOutputSettingsPreset960x540: string;

declare const AVMetadataIdentifierQuickTimeMetadataVideoOrientation: string;

declare const AVOutputSettingsPresetHEVC3840x2160WithAlpha: string;

declare const AVErrorDeviceKey: string;

declare const AVMetadataIdentifier3GPUserDataDescription: string;

declare const AVMetadataID3MetadataKeyPopularimeter: string;

declare const AVMetadataIdentifierQuickTimeMetadataCameraIdentifier: string;

declare const AVMetadataIdentifieriTunesMetadataAlbumArtist: string;

declare const AVMetadataQuickTimeMetadataKeyCopyright: string;

declare const AVMetadataiTunesMetadataKeyRecordCompany: string;

declare const AVVideoH264EntropyModeKey: string;

declare const AVCaptureReactionTypeBalloons: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedFace: string;

declare const AVMetadataID3MetadataKeyConductor: string;

declare const AVPlaybackCoordinatorOtherParticipantsDidChangeNotification: string;

declare const AVMetadataIdentifierQuickTimeMetadataPhonogramRights: string;

declare const AVMetadataID3MetadataKeyInternationalStandardRecordingCode: string;

declare const AVVideoCodecTypeAppleProRes422Proxy: string;

declare const AVMetadataIdentifierQuickTimeUserDataDescription: string;

declare const AVMetadataiTunesMetadataKeyCredits: string;

declare const AVVideoTransferFunctionKey: string;

declare const AVStreamingKeyDeliveryPersistentContentKeyType: string;

declare const AVMetadataID3MetadataKeyLength: string;

declare const AVMetadataIdentifieriTunesMetadataOnlineExtras: string;

declare const AVMetadataID3MetadataKeySubTitle: string;

declare const AVMediaCharacteristicUsesWideGamutColorSpace: string;

declare const AVVideoHeightKey: string;

declare const AVAssetChapterMetadataGroupsDidChangeNotification: string;

declare const AVAssetDownloadedAssetEvictionPriorityImportant: string;

declare const AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChangeEventKey: string;

declare const AVMetadataIdentifierQuickTimeMetadataSpatialOverCaptureQualityScore: string;

declare const AVMetadataIdentifierID3MetadataRecordingDates: string;

declare const AVVideoScalingModeKey: string;

declare const AVMetadataIdentifierID3MetadataInternetRadioStationName: string;

declare const AVMetadataCommonIdentifierAccessibilityDescription: string;

declare const AVMediaCharacteristicVisual: string;

declare const AVMetadataCommonKeySoftware: string;

declare const AVMetadataIdentifierQuickTimeUserDataProduct: string;

declare const AVMetadataQuickTimeUserDataKeyCredits: string;

declare const AVCaptureSystemPressureLevelFair: string;

declare const AVMetadataQuickTimeMetadataKeyAuthor: string;

declare const AVMediaCharacteristicDubbedTranslation: string;

declare const AVMetadataiTunesMetadataKeyEncodingTool: string;

declare const AVAudioTimePitchAlgorithmVarispeed: string;

declare const AVMetadata3GPUserDataKeyMediaRating: string;

declare const AVMetadataIdentifierID3MetadataTermsOfUse: string;

declare const AVFileTypeJPEG: string;

declare const AVMetadataID3MetadataKeyEncodedWith: string;

declare const AVMetadataID3MetadataKeySignature: string;

declare const AVMetadata3GPUserDataKeyTitle: string;

declare const AVMetadataCommonKeyLocation: string;

declare const AVMetadataIdentifierQuickTimeUserDataKeywords: string;

declare const AVURLAssetOverrideMIMETypeKey: string;

declare const AVAssetExportPresetAppleM4A: string;

declare const AVMetadataID3MetadataKeyContentGroupDescription: string;

declare const AVMetadataiTunesMetadataKeyLyrics: string;

declare const AVAssetDownloadTaskPrefersLosslessAudioKey: string;

declare const AVMetadataFormatQuickTimeUserData: string;

declare const AVCaptureSessionPresetInputPriority: string;

declare const AVMetadataiTunesMetadataKeyAccountKind: string;

declare const AVCoordinatedPlaybackSuspensionReasonCoordinatedPlaybackNotPossible: string;

declare const AVMetadataObjectTypeMicroPDF417Code: string;

declare const AVMetadataObjectTypeFace: string;

declare const AVMetadataIdentifierID3MetadataPartOfASet: string;

declare const AVFileTypeWAVE: string;

declare const AVMetadataIdentifierID3MetadataSynchronizedTempoCodes: string;

declare const AVMetadataExtraAttributeBaseURIKey: string;

declare const AVMetadataCommonIdentifierArtist: string;

declare const AVMetadataCommonIdentifierAssetIdentifier: string;

declare const AVMetadataiTunesMetadataKeyAlbumArtist: string;

declare const AVMetadataIdentifieriTunesMetadataCredits: string;

declare const AVContentKeyRequestProtocolVersionsKey: string;

declare const AVVideoCodecTypeAppleProRes422: string;

declare const AVFragmentedMovieTrackSegmentsDidChangeNotification: string;

declare const AVErrorMediaTypeKey: string;

declare const AVVideoApertureModeProductionAperture: string;

declare const AVMetadataID3MetadataKeyAudioSeekPointIndex: string;

declare const AVMetadataQuickTimeUserDataKeyCopyright: string;

declare const AVMetadataIdentifieriTunesMetadataArranger: string;

declare const AVMetadataIdentifierISOUserDataTaggedCharacteristic: string;

declare const AVMetadataQuickTimeMetadataKeyComment: string;

declare const AVMetadataQuickTimeUserDataKeyDescription: string;

declare const AVMetadataObjectTypeInterleaved2of5Code: string;

declare const AVMetadataIdentifierID3MetadataCommerical: string;

declare const AVMetadataQuickTimeMetadataKeyKeywords: string;

declare const AVMetadataID3MetadataKeyOfficialInternetRadioStationHomepage: string;

declare const AVMediaTypeHaptic: string;

declare const AVMetadataIdentifierID3MetadataOwnership: string;

declare const AVMetadataObjectTypeCodabarCode: string;

declare const AVMetadataIdentifierID3MetadataEqualization: string;

declare const AVMetadataIdentifierID3MetadataLyricist: string;

declare const AVMetadataIdentifieriTunesMetadataPublisher: string;

declare const AVMetadataIdentifieriTunesMetadataAcknowledgement: string;

declare const AVMetadataCommonKeyTitle: string;

declare const AVMetadataQuickTimeUserDataKeyTaggedCharacteristic: string;

declare const AVMetadataID3MetadataKeyInitialKey: string;

declare const AVMetadata3GPUserDataKeyCopyright: string;

declare const AVTrackAssociationTypeTimecode: string;

declare const AVAssetExportPresetHEVC1920x1080: string;

declare const AVVideoYCbCrMatrix_ITU_R_709_2: string;

declare const AVContentKeyRequestRequiresValidationDataInSecureTokenKey: string;

declare const AVMediaTypeDepthData: string;

declare const AVMetadataIdentifierQuickTimeUserDataCopyright: string;

declare const AVMetadataIdentifierID3MetadataCopyright: string;

declare const AVAudioTimePitchAlgorithmTimeDomain: string;

declare const AVCaptureSessionInterruptionSystemPressureStateKey: string;

declare const AVMetadataQuickTimeMetadataKeyLocationISO6709: string;

declare const AVOutputSettingsPreset1920x1080: string;

declare const AVCoreAnimationBeginTimeAtZero: number;

declare const AVMetadataID3MetadataKeyUserText: string;

declare const AVMetadataIdentifieriTunesMetadataPerformer: string;

declare const AVErrorPIDKey: string;

declare const AVMetadataQuickTimeUserDataKeyMake: string;

declare const AVCaptionMediaSubTypeKey: string;

declare const AVMetadataCommonKeyType: string;

declare const AVMetadataID3MetadataKeyContentType: string;

declare const AVAssetExportPresetHEVC1920x1080WithAlpha: string;

declare const AVMetadataFormatiTunesMetadata: string;

declare const AVVideoScalingModeResizeAspect: string;

declare const AVMetadataiTunesMetadataKeyContentRating: string;

declare const AVTrackAssociationTypeAudioFallback: string;

declare const AVMetadataIdentifierQuickTimeMetadataCollectionUser: string;

declare const AVMetadataID3MetadataKeyEventTimingCodes: string;

declare const AVMetadataCommonKeySource: string;

declare const AVVideoProfileLevelH264Main30: string;

declare const AVMediaCharacteristicIndicatesHorizontalFieldOfView: string;

declare const AVMetadataID3MetadataKeyGroupIdentifier: string;

declare const AVMetadataID3MetadataKeyInternetRadioStationOwner: string;

declare const AVMetadataObjectTypeCode39Code: string;

declare const AVAssetDownloadTaskMediaSelectionKey: string;

declare const AVMetadataQuickTimeUserDataKeyDisclaimer: string;

declare const AVMetadataID3MetadataKeyBand: string;

declare const AVMetadataIdentifierQuickTimeUserDataInformation: string;

declare const AVMetadataiTunesMetadataKeyCopyright: string;

declare const AVMetadataID3MetadataKeyRecordingTime: string;

declare const AVVideoH264EntropyModeCABAC: string;

declare const AVMetadataID3MetadataKeyEncryption: string;

declare const AVMetadataIdentifierID3MetadataAttachedPicture: string;

declare const AVCaptureReactionTypeThumbsDown: string;

declare const AVURLAssetURLRequestAttributionKey: string;

declare const AVMetadataIdentifierQuickTimeMetadataModel: string;

declare const AVVideoProfileLevelH264BaselineAutoLevel: string;

declare const AVAssetExportPresetMVHEVC1440x1440: string;

declare const AVVideoCodecHEVC: string;

declare const AVMetadataID3MetadataKeyLanguage: string;

declare const AVMetadataIdentifierID3MetadataMood: string;

declare const AVMetadataIdentifierID3MetadataRelativeVolumeAdjustment2: string;

declare const AVMetadataID3MetadataKeyGeneralEncapsulatedObject: string;

declare const AVMetadataIdentifierQuickTimeUserDataTrack: string;

declare const AVURLAssetHTTPCookiesKey: string;

declare const AVURLAssetReferenceRestrictionsKey: string;

declare const AVMetadataQuickTimeMetadataKeyLocationNote: string;

declare const AVMetadataIdentifierID3MetadataEncodedBy: string;

declare const AVAssetTrackTrackAssociationsDidChangeNotification: string;

declare const AVMetadataID3MetadataKeyAttachedPicture: string;

declare const AVCaptureISOCurrent: number;

declare const AVMetadataIdentifierQuickTimeMetadataComposer: string;

declare const AVMetadataiTunesMetadataKeyUserGenre: string;

declare const AVMetadataIdentifierQuickTimeMetadataKeywords: string;

declare const AVVideoYCbCrMatrix_ITU_R_2020: string;

declare const AVMetadataIdentifierQuickTimeMetadataAutoLivePhoto: string;

declare const AVMetadataQuickTimeUserDataKeyAccessibilityDescription: string;

declare const AVVideoProfileLevelH264High41: string;

declare const AVVideoColorPropertiesKey: string;

declare const AVCaptureExposureTargetBiasCurrent: number;

declare const AVMetadataQuickTimeUserDataKeyOriginalFormat: string;

declare const AVAssetDownloadTaskMediaSelectionPrefersMultichannelKey: string;

declare const AVPlayerInterstitialEventMonitorEventsDidChangeNotification: string;

declare const AVPlayerItemFailedToPlayToEndTimeNotification: string;

declare const AVPlayerWaitingForCoordinatedPlaybackReason: string;

declare const AVMetadataID3MetadataKeyCommercial: string;

declare const AVMetadataQuickTimeMetadataKeyIsMontage: string;

declare const AVMetadataIdentifierQuickTimeUserDataComment: string;

declare const AVVideoColorPrimaries_P3_D65: string;

declare const AVAssetExportPresetPassthrough: string;

declare const AVAssetExportPresetHEVC3840x2160: string;

declare const AVVideoCleanApertureVerticalOffsetKey: string;

declare const AVFileTypeAIFF: string;

declare const AVMetadataCommonKeyMake: string;

declare const AVMetadataID3MetadataKeyRelativeVolumeAdjustment: string;

declare const AVPlayerRateDidChangeReasonSetRateCalled: string;

declare const AVMetadataIdentifierQuickTimeUserDataProducer: string;

declare const AVCaptureSessionRuntimeErrorNotification: string;

declare const AVMetadataID3MetadataKeyComposer: string;

declare const AVMetadataiTunesMetadataKeyReleaseDate: string;

declare const AVMetadataCommonKeyLastModifiedDate: string;

declare const AVMetadataObjectTypeHumanBody: string;

declare const AVVideoQualityKey: string;

declare const AVAssetImageGeneratorApertureModeProductionAperture: string;

declare const AVMetadataIdentifieriTunesMetadataUserGenre: string;

declare const AVLayerVideoGravityResizeAspectFill: string;

declare const AVMediaCharacteristicContainsStereoMultiviewVideo: string;

declare const AVAssetDownloadedAssetEvictionPriorityDefault: string;

declare const AVMetadataIdentifierQuickTimeMetadataAlbum: string;

declare const AVMetadataiTunesMetadataKeyComposer: string;

declare const AVMetadataIdentifier3GPUserDataAlbumAndTrack: string;

declare const AVVideoCodecTypeAppleProRes422HQ: string;

declare const AVAssetExportPresetHighestQuality: string;

declare const AVPlaybackCoordinatorSuspensionReasonsDidChangeNotification: string;

declare const AVContentKeyRequestRetryReasonReceivedResponseWithExpiredLease: string;

declare const AVMetadataCommonIdentifierArtwork: string;

declare const AVMetadataID3MetadataKeyPayment: string;

declare const AVAssetImageGeneratorDynamicRangePolicyMatchSource: string;

declare const AVCaptureDeviceTypeBuiltInTripleCamera: string;

declare const AVMediaCharacteristicCarriesVideoStereoMetadata: string;

declare const AVMetadataIdentifierQuickTimeMetadataOriginalArtist: string;

declare const AVMetadataQuickTimeMetadataKeyAlbum: string;

declare const AVSpatialCaptureDiscomfortReasonNotEnoughLight: string;

declare const AVMetadataIdentifierID3MetadataSeek: string;

declare const AVMetadataIdentifierID3MetadataCommercial: string;

declare const AVCaptureDeviceWasConnectedNotification: string;

declare const AVVideoScalingModeResize: string;

declare const AVVideoAppleProRAWBitDepthKey: string;

declare const AVMetadataID3MetadataKeyMusicCDIdentifier: string;

declare const AVVideoAllowFrameReorderingKey: string;

declare const AVMetadataIdentifierID3MetadataAudioSeekPointIndex: string;

declare const AVMetadataIdentifierQuickTimeMetadataDirectionMotion: string;

declare const AVAssetPlaybackConfigurationOptionSpatialVideo: string;

declare const AVMetadataCommonIdentifierLastModifiedDate: string;

declare const AVMetadataIdentifierQuickTimeUserDataTaggedCharacteristic: string;

declare const AVVideoH264EntropyModeCAVLC: string;

declare const AVFragmentedMovieContainsMovieFragmentsDidChangeNotification: string;

declare const AVMetadataID3MetadataKeyAudioEncryption: string;

declare const AVSpatialCaptureDiscomfortReasonSubjectTooClose: string;

declare const AVMetadataIdentifierQuickTimeMetadataArtist: string;

declare const AVMetadataID3MetadataKeyUserURL: string;

declare const AVMetadataID3MetadataKeyEncodingTime: string;

declare const AVMetadataID3MetadataKeyMood: string;

declare const AVVideoExpectedSourceFrameRateKey: string;

declare const AVMetadataIdentifierQuickTimeUserDataSpecialPlaybackRequirements: string;

declare const AVFileTypeAC3: string;

declare const AVCaptureReactionTypeFireworks: string;

declare const AVVideoProfileLevelKey: string;

declare const AVMetadataCommonKeyRelation: string;

declare const AVCaptureSessionDidStopRunningNotification: string;

declare const AVMetadataID3MetadataKeySeek: string;

declare const AVMetadataIdentifierID3MetadataFileType: string;

declare const AVFileTypeAIFC: string;

declare const AVPlayerRateDidChangeReasonKey: string;

declare const AVMetadataCommonKeyArtist: string;

declare const AVMetadataIdentifierID3MetadataPositionSynchronization: string;

declare const AVMetadataiTunesMetadataKeyOriginalArtist: string;

declare const AVMediaTypeMuxed: string;

declare const AVCaptureReactionTypeConfetti: string;

declare const AVMetadataIdentifierQuickTimeUserDataWarning: string;

declare const AVMetadata3GPUserDataKeyPerformer: string;

declare const AVMetadataID3MetadataKeyTrackNumber: string;

declare const AVMetadataQuickTimeMetadataKeyContentIdentifier: string;

declare const AVMediaTypeSubtitle: string;

declare const AVMetadataIdentifierQuickTimeMetadataCredits: string;

declare const AVContentKeyRequestRetryReasonTimedOut: string;

declare const AVAssetPlaybackConfigurationOptionStereoMultiviewVideo: string;

declare const AVMetadataObjectTypeGS1DataBarLimitedCode: string;

declare const AVVideoCodecTypeJPEG: string;

declare const AVMetadataiTunesMetadataKeyTrackSubTitle: string;

declare const AVMetadataIdentifierISOUserDataAccessibilityDescription: string;

declare const AVCaptureDeviceTypeBuiltInTelephotoCamera: string;

declare const AVAssetExportPreset1280x720: string;

declare const AVMetadataQuickTimeUserDataKeyArtist: string;

declare const AVMetadataiTunesMetadataKeyPerformer: string;

declare const AVMetadataIdentifierID3MetadataPopularimeter: string;

declare const AVMetadataIdentifierQuickTimeMetadataPublisher: string;

declare const AVMetadataIdentifieriTunesMetadataAppleID: string;

declare const AVURLAssetAllowsConstrainedNetworkAccessKey: string;

declare const AVMetadataIdentifieriTunesMetadataBeatsPerMin: string;

declare const AVMetadataIdentifierQuickTimeMetadataLocationISO6709: string;

declare const AVMetadataQuickTimeUserDataKeyArranger: string;

declare const AVMetadataCommonKeyCreationDate: string;

declare const AVTrackAssociationTypeChapterList: string;

declare const AVMetadataObjectTypeCode93Code: string;

declare const AVMetadataIdentifierID3MetadataCopyrightInformation: string;

declare const AVVideoProfileLevelH264MainAutoLevel: string;

declare const AVMetadataIdentifieriTunesMetadataPredefinedGenre: string;

declare const AVMetadataID3MetadataKeyPlayCounter: string;

declare const AVMetadataIdentifierQuickTimeUserDataURLLink: string;

declare const AVMetadataIdentifieriTunesMetadataAuthor: string;

declare const AVMediaCharacteristicTactileMinimal: string;

declare const AVMetadataIdentifierQuickTimeUserDataPhonogramRights: string;

declare const AVContentKeySessionServerPlaybackContextOptionProtocolVersions: string;

declare const AVMetadataObjectTypeSalientObject: string;

declare const AVMetadataIdentifierQuickTimeUserDataAccessibilityDescription: string;

declare const AVMetadataID3MetadataKeyYear: string;

declare const AVMediaCharacteristicContainsAlphaChannel: string;

declare const AVErrorPresentationTimeStampKey: string;

declare const AVMetadataiTunesMetadataKeyPlaylistID: string;

declare const AVMetadataCommonIdentifierDescription: string;

declare const AVMetadataQuickTimeMetadataKeyPublisher: string;

declare const AVMetadataQuickTimeMetadataKeySoftware: string;

declare const AVMetadataIdentifier3GPUserDataCollection: string;

declare const AVMetadataIdentifierID3MetadataBeatsPerMinute: string;

declare const AVMetadataCommonIdentifierLocation: string;

declare const AVMetadataQuickTimeMetadataKeyLocationRole: string;

declare const AVPlayerItemDidPlayToEndTimeNotification: string;

declare const AVMetadataCommonIdentifierSoftware: string;

declare const AVMetadataIdentifierQuickTimeMetadataTitle: string;

declare const AVMetadataID3MetadataKeySynchronizedLyric: string;

declare const AVMetadataIdentifierQuickTimeMetadataInformation: string;

declare const AVMetadataCommonIdentifierRelation: string;

declare const AVMetadataIdentifieriTunesMetadataGenreID: string;

declare const AVCaptureInputPortFormatDescriptionDidChangeNotification: string;

declare const AVMetadataIcyMetadataKeyStreamURL: string;

declare const AVMetadataID3MetadataKeyOriginalAlbumTitle: string;

declare const AVSampleBufferDisplayLayerReadyForDisplayDidChangeNotification: string;

declare const AVMetadataIdentifieriTunesMetadataArtDirector: string;

declare const AVMetadataiTunesMetadataKeyDiscNumber: string;

declare const AVMetadataQuickTimeMetadataKeyDirectionMotion: string;

declare const AVAssetDurationDidChangeNotification: string;

declare const AVMetadataID3MetadataKeyMediaType: string;

declare const AVFileTypeMPEG4: string;

declare const AVMetadataIdentifierID3MetadataEqualization2: string;

declare const AVMetadataQuickTimeMetadataKeyGenre: string;

declare const AVVideoAverageBitRateKey: string;

declare const AVVideoPixelAspectRatioVerticalSpacingKey: string;

declare const AVSampleBufferRenderSynchronizerRateDidChangeNotification: string;

declare const AVMetadataIdentifierQuickTimeUserDataPerformers: string;

declare const AVMetadataIdentifierQuickTimeMetadataEncodedBy: string;

declare const AVMetadataIdentifierQuickTimeMetadataDetectedHumanBody: string;

declare const AVMetadataIdentifieriTunesMetadataTrackSubTitle: string;

declare const AVMediaTypeTimecode: string;

declare const AVVideoPixelAspectRatioHorizontalSpacingKey: string;

declare const AVMetadataIdentifierISOUserDataCopyright: string;

declare const AVMetadataID3MetadataKeyPositionSynchronization: string;

declare const AVMediaCharacteristicTranscribesSpokenDialogForAccessibility: string;

declare const AVMetadataID3MetadataKeyOfficialPublisherWebpage: string;

declare const AVMetadataCommonKeyArtwork: string;

declare const AVMetadataCommonKeyCopyrights: string;

declare const AVVideoAllowWideColorKey: string;

declare const AVMetadataID3MetadataKeyPerformerSortOrder: string;

declare const AVMetadataCommonIdentifierType: string;

declare const AVMetadataID3MetadataKeyCopyright: string;

declare const AVMetadataIdentifierQuickTimeMetadataCopyright: string;

declare const AVDepthDataAccuracy: {
  Relative: 0,
  Absolute: 1,
};

declare const AVDepthDataQuality: {
  Low: 0,
  High: 1,
};

declare const AVCaptureMultichannelAudioMode: {
  None: 0,
  Stereo: 1,
  FirstOrderAmbisonics: 2,
};

declare const AVCaptureLensStabilizationStatus: {
  Unsupported: 0,
  Off: 1,
  Active: 2,
  OutOfRange: 3,
  Unavailable: 4,
};

declare const AVCapturePhotoOutputCaptureReadiness: {
  SessionNotRunning: 0,
  Ready: 1,
  NotReadyMomentarily: 2,
  NotReadyWaitingForCapture: 3,
  NotReadyWaitingForProcessing: 4,
};

declare const AVCapturePhotoQualityPrioritization: {
  Speed: 1,
  Balanced: 2,
  Quality: 3,
};

declare const AVCaptureOutputDataDroppedReason: {
  None: 0,
  LateData: 1,
  OutOfBuffers: 2,
  Discontinuity: 3,
};

declare const AVCaptureSessionInterruptionReason: {
  VideoDeviceNotAvailableInBackground: 1,
  AudioDeviceInUseByAnotherClient: 2,
  VideoDeviceInUseByAnotherClient: 3,
  VideoDeviceNotAvailableWithMultipleForegroundApps: 4,
  VideoDeviceNotAvailableDueToSystemPressure: 5,
};

declare const AVCaptureAutoFocusSystem: {
  None: 0,
  ContrastDetection: 1,
  PhaseDetection: 2,
};

declare const AVCaptureVideoStabilizationMode: {
  Off: 0,
  Standard: 1,
  Cinematic: 2,
  CinematicExtended: 3,
  PreviewOptimized: 4,
  CinematicExtendedEnhanced: 5,
  Auto: -1,
};

declare const AVCaptureSystemUserInterface: {
  VideoEffects: 1,
  MicrophoneModes: 2,
};

declare const AVCaptureMicrophoneMode: {
  Standard: 0,
  WideSpectrum: 1,
  VoiceIsolation: 2,
};

declare const AVAuthorizationStatus: {
  NotDetermined: 0,
  Restricted: 1,
  Denied: 2,
  Authorized: 3,
};

declare const AVCaptureWhiteBalanceMode: {
  Locked: 0,
  AutoWhiteBalance: 1,
  ContinuousAutoWhiteBalance: 2,
};

declare const AVCaptureFocusMode: {
  Locked: 0,
  AutoFocus: 1,
  ContinuousAutoFocus: 2,
};

declare const AVCaptureFlashMode: {
  Off: 0,
  On: 1,
  Auto: 2,
};

declare const AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions: {
  None: 0,
  VideoZoomChanged: 1,
  FocusModeChanged: 2,
  ExposureModeChanged: 4,
};

declare const AVCaptureDevicePosition: {
  Unspecified: 0,
  Back: 1,
  Front: 2,
};

declare const AVQueuedSampleBufferRenderingStatus: {
  Unknown: 0,
  Rendering: 1,
  Failed: 2,
};

declare const AVPlayerInterstitialEventAssetListResponseStatus: {
  Available: 0,
  Cleared: 1,
  Unavailable: 2,
};

declare const AVCaptureAutoFocusRangeRestriction: {
  None: 0,
  Near: 1,
  Far: 2,
};

declare const AVPlayerInterstitialEventTimelineOccupancy: {
  SinglePoint: 0,
  Fill: 1,
};

declare const AVPlayerInterstitialEventRestrictions: {
  None: 0,
  ConstrainsSeekingForwardInPrimaryContent: 1,
  RequiresPlaybackAtPreferredRateForAdvancement: 4,
  DefaultPolicy: 0,
};

declare const AVPlayerLooperItemOrdering: {
  Precede: 0,
  Follow: 1,
};

declare const AVPlayerLooperStatus: {
  Unknown: 0,
  Ready: 1,
  Failed: 2,
  Cancelled: 3,
};

declare const AVVariantPreferences: {
  None: 0,
  ScalabilityToLosslessAudio: 1,
};

declare const AVDelegatingPlaybackCoordinatorSeekOptions: {
  AVDelegatingPlaybackCoordinatorSeekOptionResumeImmediately: 1,
};

declare const AVPlayerHDRMode: {
  HLG: 1,
  HDR10: 2,
  DolbyVision: 4,
};

declare const AVPlayerTimeControlStatus: {
  Paused: 0,
  WaitingToPlayAtSpecifiedRate: 1,
  Playing: 2,
};

declare const AVPlayerStatus: {
  Unknown: 0,
  ReadyToPlay: 1,
  Failed: 2,
};

declare const AVMovieWritingOptions: {
  AddMovieHeaderToDestination: 0,
  TruncateDestinationToMovieHeaderOnly: 1,
};

declare const AVError: {
  Unknown: -11800,
  OutOfMemory: -11801,
  SessionNotRunning: -11803,
  DeviceAlreadyUsedByAnotherSession: -11804,
  NoDataCaptured: -11805,
  SessionConfigurationChanged: -11806,
  DiskFull: -11807,
  DeviceWasDisconnected: -11808,
  MediaChanged: -11809,
  MaximumDurationReached: -11810,
  MaximumFileSizeReached: -11811,
  MediaDiscontinuity: -11812,
  MaximumNumberOfSamplesForFileFormatReached: -11813,
  DeviceNotConnected: -11814,
  DeviceInUseByAnotherApplication: -11815,
  DeviceLockedForConfigurationByAnotherProcess: -11817,
  SessionWasInterrupted: -11818,
  MediaServicesWereReset: -11819,
  ExportFailed: -11820,
  DecodeFailed: -11821,
  InvalidSourceMedia: -11822,
  FileAlreadyExists: -11823,
  CompositionTrackSegmentsNotContiguous: -11824,
  InvalidCompositionTrackSegmentDuration: -11825,
  InvalidCompositionTrackSegmentSourceStartTime: -11826,
  InvalidCompositionTrackSegmentSourceDuration: -11827,
  FileFormatNotRecognized: -11828,
  FileFailedToParse: -11829,
  MaximumStillImageCaptureRequestsExceeded: -11830,
  ContentIsProtected: -11831,
  NoImageAtTime: -11832,
  DecoderNotFound: -11833,
  EncoderNotFound: -11834,
  ContentIsNotAuthorized: -11835,
  ApplicationIsNotAuthorized: -11836,
  DeviceIsNotAvailableInBackground: -11837,
  OperationNotSupportedForAsset: -11838,
  DecoderTemporarilyUnavailable: -11839,
  EncoderTemporarilyUnavailable: -11840,
  InvalidVideoComposition: -11841,
  ReferenceForbiddenByReferencePolicy: -11842,
  InvalidOutputURLPathExtension: -11843,
  ScreenCaptureFailed: -11844,
  DisplayWasDisabled: -11845,
  TorchLevelUnavailable: -11846,
  OperationInterrupted: -11847,
  IncompatibleAsset: -11848,
  FailedToLoadMediaData: -11849,
  ServerIncorrectlyConfigured: -11850,
  ApplicationIsNotAuthorizedToUseDevice: -11852,
  FailedToParse: -11853,
  FileTypeDoesNotSupportSampleReferences: -11854,
  UndecodableMediaData: -11855,
  AirPlayControllerRequiresInternet: -11856,
  AirPlayReceiverRequiresInternet: -11857,
  VideoCompositorFailed: -11858,
  RecordingAlreadyInProgress: -11859,
  UnsupportedOutputSettings: -11861,
  OperationNotAllowed: -11862,
  ContentIsUnavailable: -11863,
  FormatUnsupported: -11864,
  MalformedDepth: -11865,
  ContentNotUpdated: -11866,
  NoLongerPlayable: -11867,
  NoCompatibleAlternatesForExternalDisplay: -11868,
  NoSourceTrack: -11869,
  ExternalPlaybackNotSupportedForAsset: -11870,
  OperationNotSupportedForPreset: -11871,
  SessionHardwareCostOverage: -11872,
  UnsupportedDeviceActiveFormat: -11873,
  IncorrectlyConfigured: -11875,
  SegmentStartedWithNonSyncSample: -11876,
  RosettaNotInstalled: -11877,
  OperationCancelled: -11878,
  ContentKeyRequestCancelled: -11879,
  InvalidSampleCursor: -11880,
  FailedToLoadSampleData: -11881,
  AirPlayReceiverTemporarilyUnavailable: -11882,
  EncodeFailed: -11883,
  SandboxExtensionDenied: -11884,
  ToneMappingFailed: -11885,
};

declare const AVCaptionConversionValidatorStatus: {
  Unknown: 0,
  Validating: 1,
  Completed: 2,
  Stopped: 3,
};

declare const AVCaptionRubyAlignment: {
  Start: 0,
  Center: 1,
  DistributeSpaceBetween: 2,
  DistributeSpaceAround: 3,
};

declare const AVCaptionDecoration: {
  None: 0,
  Underline: 1,
  LineThrough: 2,
  Overline: 4,
};

declare const AVCaptionAnimation: {
  None: 0,
  CharacterReveal: 1,
};

declare const AVCaptionRegionScroll: {
  None: 0,
  RollUp: 1,
};

declare const AVCaptionRegionWritingMode: {
  LeftToRightAndTopToBottom: 0,
  TopToBottomAndRightToLeft: 2,
};

declare const AVCaptionUnitsType: {
  Unspecified: 0,
  Cells: 1,
  Percent: 2,
};

declare const AVAssetSegmentType: {
  Initialization: 1,
  Separable: 2,
};

declare const AVAssetTrackGroupOutputHandling: {
  None: 0,
  PreserveAlternateTracks: 1,
  DefaultPolicy: 0,
};

declare const AVAssetReferenceRestrictions: {
  ForbidNone: 0,
  ForbidRemoteReferenceToLocal: 1,
  ForbidLocalReferenceToRemote: 2,
  ForbidCrossSiteReference: 4,
  ForbidLocalReferenceToLocal: 8,
  ForbidAll: 65535,
  DefaultPolicy: 2,
};

declare const AVExternalContentProtectionStatus: {
  Pending: 0,
  Sufficient: 1,
  Insufficient: 2,
};

declare const AVKeyValueStatus: {
  Unknown: 0,
  Loading: 1,
  Loaded: 2,
  Failed: 3,
  Cancelled: 4,
};

declare const AVAssetExportSessionStatus: {
  Unknown: 0,
  Waiting: 1,
  Exporting: 2,
  Completed: 3,
  Failed: 4,
  Cancelled: 5,
};

declare const AVCaptionRegionDisplayAlignment: {
  Before: 0,
  Center: 1,
  After: 2,
};

declare const AVContentKeyRequestStatus: {
  RequestingResponse: 0,
  ReceivedResponse: 1,
  Renewed: 2,
  Retried: 3,
  Cancelled: 4,
  Failed: 5,
};

declare const AVAudioSpatializationFormats: {
  None: 0,
  MonoAndStereo: 3,
  Multichannel: 4,
  MonoStereoAndMultichannel: 7,
};

declare const AVSampleBufferRequestMode: {
  Immediate: 0,
  Scheduled: 1,
  Opportunistic: 2,
};

declare const AVCaptureColorSpace: {
  Space_sRGB: 0,
  Space_P3_D65: 1,
  Space_HLG_BT2020: 2,
  Space_AppleLog: 3,
};

declare const AVCaptureCenterStageControlMode: {
  User: 0,
  App: 1,
  Cooperative: 2,
};

declare const AVCaptionFontWeight: {
  Unknown: 0,
  Normal: 1,
  Bold: 2,
};

declare const AVAssetReaderStatus: {
  Unknown: 0,
  Reading: 1,
  Completed: 2,
  Failed: 3,
  Cancelled: 4,
};

declare const AVPlayerAudiovisualBackgroundPlaybackPolicy: {
  Automatic: 1,
  Pauses: 2,
  ContinuesIfPossible: 3,
};

declare const AVPlayerItemSegmentType: {
  Primary: 0,
  Interstitial: 1,
};

declare const AVAssetImageGeneratorResult: {
  Succeeded: 0,
  Failed: 1,
  Cancelled: 2,
};

declare const AVCaptionRubyPosition: {
  Before: 0,
  After: 1,
};

declare const AVPlayerActionAtItemEnd: {
  Advance: 0,
  Pause: 1,
  None: 2,
};

declare const AVCaptionTextAlignment: {
  Start: 0,
  End: 1,
  Center: 2,
  Left: 3,
  Right: 4,
};

declare const AVCapturePrimaryConstituentDeviceSwitchingBehavior: {
  Unsupported: 0,
  Auto: 1,
  Restricted: 2,
  Locked: 3,
};

declare const AVCaptureVideoOrientation: {
  Portrait: 1,
  PortraitUpsideDown: 2,
  LandscapeRight: 3,
  LandscapeLeft: 4,
};

declare const AVAssetWriterStatus: {
  Unknown: 0,
  Writing: 1,
  Completed: 2,
  Failed: 3,
  Cancelled: 4,
};

declare const AVCaptionFontStyle: {
  Unknown: 0,
  Normal: 1,
  Italic: 2,
};

declare const AVSampleBufferRequestDirection: {
  Forward: 1,
  None: 0,
  Reverse: -1,
};

declare const AVCaptureTorchMode: {
  Off: 0,
  On: 1,
  Auto: 2,
};

declare const AVCaptionTextCombine: {
  All: -1,
  None: 0,
  OneDigit: 1,
  TwoDigits: 2,
  ThreeDigits: 3,
  FourDigits: 4,
};

declare const AVCaptureSystemPressureFactors: {
  None: 0,
  SystemTemperature: 1,
  PeakPower: 2,
  DepthModuleTemperature: 4,
  CameraTemperature: 8,
};

declare const AVDelegatingPlaybackCoordinatorRateChangeOptions: {
  AVDelegatingPlaybackCoordinatorRateChangeOptionPlayImmediately: 1,
};

declare const AVCaptureExposureMode: {
  Locked: 0,
  AutoExpose: 1,
  ContinuousAutoExposure: 2,
  Custom: 3,
};

declare const AVPlayerItemStatus: {
  Unknown: 0,
  ReadyToPlay: 1,
  Failed: 2,
};

declare const CMTagCollectionVideoOutputPreset: {
  Monoscopic: 0,
  Stereoscopic: 1,
};

declare class AVCaptureWhiteBalanceGains {
  constructor(init?: AVCaptureWhiteBalanceGains);
  redGain: number;
  greenGain: number;
  blueGain: number;
}

declare class AVSampleCursorStorageRange {
  constructor(init?: AVSampleCursorStorageRange);
  offset: number;
  length: number;
}

declare class AVSampleCursorAudioDependencyInfo {
  constructor(init?: AVSampleCursorAudioDependencyInfo);
  audioSampleIsIndependentlyDecodable: boolean;
  audioSamplePacketRefreshCount: number;
}

declare class AVSampleCursorSyncInfo {
  constructor(init?: AVSampleCursorSyncInfo);
  sampleIsFullSync: boolean;
  sampleIsPartialSync: boolean;
  sampleIsDroppable: boolean;
}

declare class AVCaptionSize {
  constructor(init?: AVCaptionSize);
  width: AVCaptionDimension;
  height: AVCaptionDimension;
}

declare class AVSampleCursorChunkInfo {
  constructor(init?: AVSampleCursorChunkInfo);
  chunkSampleCount: number;
  chunkHasUniformSampleSizes: boolean;
  chunkHasUniformSampleDurations: boolean;
  chunkHasUniformFormatDescriptions: boolean;
}

declare class AVCaptureWhiteBalanceChromaticityValues {
  constructor(init?: AVCaptureWhiteBalanceChromaticityValues);
  x: number;
  y: number;
}

declare class AVEdgeWidths {
  constructor(init?: AVEdgeWidths);
  left: number;
  top: number;
  right: number;
  bottom: number;
}

declare class AVCaptionPoint {
  constructor(init?: AVCaptionPoint);
  x: AVCaptionDimension;
  y: AVCaptionDimension;
}

declare class AVSampleCursorDependencyInfo {
  constructor(init?: AVSampleCursorDependencyInfo);
  sampleIndicatesWhetherItHasDependentSamples: boolean;
  sampleHasDependentSamples: boolean;
  sampleIndicatesWhetherItDependsOnOthers: boolean;
  sampleDependsOnOthers: boolean;
  sampleIndicatesWhetherItHasRedundantCoding: boolean;
  sampleHasRedundantCoding: boolean;
}

declare class AVPixelAspectRatio {
  constructor(init?: AVPixelAspectRatio);
  horizontalSpacing: number;
  verticalSpacing: number;
}

declare class AVCaptureWhiteBalanceTemperatureAndTintValues {
  constructor(init?: AVCaptureWhiteBalanceTemperatureAndTintValues);
  temperature: number;
  tint: number;
}

declare class AVCaptionDimension {
  constructor(init?: AVCaptionDimension);
  value: number;
  units: interop.Enum<typeof AVCaptionUnitsType>;
}

declare function AVSampleBufferAttachContentKey(sbuf: interop.PointerConvertible, contentKey: AVContentKey, outError: interop.PointerConvertible): boolean;

declare function AVCaptionDimensionMake(value: number, units: interop.Enum<typeof AVCaptionUnitsType>): AVCaptionDimension;

declare function AVCaptionPointMake(x: AVCaptionDimension, y: AVCaptionDimension): AVCaptionPoint;

declare function AVCaptionSizeMake(width: AVCaptionDimension, height: AVCaptionDimension): AVCaptionSize;

declare function AVMakeRectWithAspectRatioInsideRect(aspectRatio: CGSize, boundingRect: CGRect): CGRect;

declare function CMTagCollectionCreateWithVideoOutputPreset(allocator: interop.PointerConvertible, preset: interop.Enum<typeof CMTagCollectionVideoOutputPreset>, newCollectionOut: interop.PointerConvertible): number;

declare function AVCaptureReactionSystemImageNameForType(reactionType: string): string;

declare interface AVCaptureDataOutputSynchronizerDelegate extends NSObjectProtocol {
  dataOutputSynchronizerDidOutputSynchronizedDataCollection(synchronizer: AVCaptureDataOutputSynchronizer, synchronizedDataCollection: AVCaptureSynchronizedDataCollection): void;
}

declare class AVCaptureDataOutputSynchronizerDelegate extends NativeObject implements AVCaptureDataOutputSynchronizerDelegate {
}

declare interface AVCaptureVideoDataOutputSampleBufferDelegate extends NSObjectProtocol {
  captureOutputDidOutputSampleBufferFromConnection?(output: AVCaptureOutput, sampleBuffer: interop.PointerConvertible, connection: AVCaptureConnection): void;

  captureOutputDidDropSampleBufferFromConnection?(output: AVCaptureOutput, sampleBuffer: interop.PointerConvertible, connection: AVCaptureConnection): void;
}

declare class AVCaptureVideoDataOutputSampleBufferDelegate extends NativeObject implements AVCaptureVideoDataOutputSampleBufferDelegate {
}

declare interface AVCapturePhotoFileDataRepresentationCustomizer extends NSObjectProtocol {
  replacementMetadataForPhoto?(photo: AVCapturePhoto): NSDictionary;

  replacementEmbeddedThumbnailPixelBufferWithPhotoFormatForPhoto?(replacementEmbeddedThumbnailPhotoFormatOut: interop.PointerConvertible, photo: AVCapturePhoto): interop.Pointer;

  replacementDepthDataForPhoto?(photo: AVCapturePhoto): AVDepthData;

  replacementPortraitEffectsMatteForPhoto?(photo: AVCapturePhoto): AVPortraitEffectsMatte;

  replacementSemanticSegmentationMatteOfTypeForPhoto?(semanticSegmentationMatteType: string, photo: AVCapturePhoto): AVSemanticSegmentationMatte;

  replacementAppleProRAWCompressionSettingsForPhotoDefaultSettingsMaximumBitDepth?(photo: AVCapturePhoto, defaultSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, maximumBitDepth: number): NSDictionary;
}

declare class AVCapturePhotoFileDataRepresentationCustomizer extends NativeObject implements AVCapturePhotoFileDataRepresentationCustomizer {
}

declare interface AVCaptureDepthDataOutputDelegate extends NSObjectProtocol {
  depthDataOutputDidOutputDepthDataTimestampConnection?(output: AVCaptureDepthDataOutput, depthData: AVDepthData, timestamp: CMTime, connection: AVCaptureConnection): void;

  depthDataOutputDidDropDepthDataTimestampConnectionReason?(output: AVCaptureDepthDataOutput, depthData: AVDepthData, timestamp: CMTime, connection: AVCaptureConnection, reason: interop.Enum<typeof AVCaptureOutputDataDroppedReason>): void;
}

declare class AVCaptureDepthDataOutputDelegate extends NativeObject implements AVCaptureDepthDataOutputDelegate {
}

declare interface AVCaptureAudioDataOutputSampleBufferDelegate extends NSObjectProtocol {
  captureOutputDidOutputSampleBufferFromConnection?(output: AVCaptureOutput, sampleBuffer: interop.PointerConvertible, connection: AVCaptureConnection): void;
}

declare class AVCaptureAudioDataOutputSampleBufferDelegate extends NativeObject implements AVCaptureAudioDataOutputSampleBufferDelegate {
}

declare interface AVCaptureSessionControlsDelegate extends NSObjectProtocol {
  sessionControlsDidBecomeActive(session: AVCaptureSession): void;

  sessionControlsWillEnterFullscreenAppearance(session: AVCaptureSession): void;

  sessionControlsWillExitFullscreenAppearance(session: AVCaptureSession): void;

  sessionControlsDidBecomeInactive(session: AVCaptureSession): void;
}

declare class AVCaptureSessionControlsDelegate extends NativeObject implements AVCaptureSessionControlsDelegate {
}

declare interface AVPlayerItemIntegratedTimelineObserver extends NSObjectProtocol {
}

declare class AVPlayerItemIntegratedTimelineObserver extends NativeObject implements AVPlayerItemIntegratedTimelineObserver {
}

declare interface AVPlayerItemOutputPushDelegate extends NSObjectProtocol {
  outputSequenceWasFlushed?(output: AVPlayerItemOutput): void;
}

declare class AVPlayerItemOutputPushDelegate extends NativeObject implements AVPlayerItemOutputPushDelegate {
}

declare interface AVPlayerItemOutputPullDelegate extends NSObjectProtocol {
  outputMediaDataWillChange?(sender: AVPlayerItemOutput): void;

  outputSequenceWasFlushed?(output: AVPlayerItemOutput): void;
}

declare class AVPlayerItemOutputPullDelegate extends NativeObject implements AVPlayerItemOutputPullDelegate {
}

declare interface AVMetricEventStreamSubscriber {
  publisherDidReceiveEvent(publisher: AVMetricEventStreamPublisher, event: AVMetricEvent): void;
}

declare class AVMetricEventStreamSubscriber extends NativeObject implements AVMetricEventStreamSubscriber {
}

declare interface AVPlayerItemMetadataOutputPushDelegate extends AVPlayerItemOutputPushDelegate {
  metadataOutputDidOutputTimedMetadataGroupsFromPlayerItemTrack?(output: AVPlayerItemMetadataOutput, groups: NSArray<interop.Object> | Array<interop.Object>, track: AVPlayerItemTrack | null): void;
}

declare class AVPlayerItemMetadataOutputPushDelegate extends NativeObject implements AVPlayerItemMetadataOutputPushDelegate {
}

declare interface AVMetricEventStreamPublisher {
}

declare class AVMetricEventStreamPublisher extends NativeObject implements AVMetricEventStreamPublisher {
}

declare interface AVPlaybackCoordinatorPlaybackControlDelegate extends NSObjectProtocol {
  playbackCoordinatorDidIssuePlayCommandCompletionHandler(coordinator: AVDelegatingPlaybackCoordinator, playCommand: AVDelegatingPlaybackCoordinatorPlayCommand, completionHandler: () => void): void;

  playbackCoordinatorDidIssuePauseCommandCompletionHandler(coordinator: AVDelegatingPlaybackCoordinator, pauseCommand: AVDelegatingPlaybackCoordinatorPauseCommand, completionHandler: () => void): void;

  playbackCoordinatorDidIssueSeekCommandCompletionHandler(coordinator: AVDelegatingPlaybackCoordinator, seekCommand: AVDelegatingPlaybackCoordinatorSeekCommand, completionHandler: () => void): void;

  playbackCoordinatorDidIssueBufferingCommandCompletionHandler(coordinator: AVDelegatingPlaybackCoordinator, bufferingCommand: AVDelegatingPlaybackCoordinatorBufferingCommand, completionHandler: () => void): void;
}

declare class AVPlaybackCoordinatorPlaybackControlDelegate extends NativeObject implements AVPlaybackCoordinatorPlaybackControlDelegate {
}

declare interface AVPlayerPlaybackCoordinatorDelegate extends NSObjectProtocol {
  playbackCoordinatorIdentifierForPlayerItem?(coordinator: AVPlayerPlaybackCoordinator, playerItem: AVPlayerItem): string;

  playbackCoordinatorInterstitialTimeRangesForPlayerItem?(coordinator: AVPlayerPlaybackCoordinator, playerItem: AVPlayerItem): NSArray;
}

declare class AVPlayerPlaybackCoordinatorDelegate extends NativeObject implements AVPlayerPlaybackCoordinatorDelegate {
}

declare interface AVAssetDownloadDelegate extends NSURLSessionTaskDelegate {
  URLSessionAssetDownloadTaskDidFinishDownloadingToURL?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, location: NSURL): void;

  URLSessionAssetDownloadTaskDidLoadTimeRangeTotalTimeRangesLoadedTimeRangeExpectedToLoad?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, timeRange: CMTimeRange, loadedTimeRanges: NSArray<interop.Object> | Array<interop.Object>, timeRangeExpectedToLoad: CMTimeRange): void;

  URLSessionAssetDownloadTaskDidResolveMediaSelection?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, resolvedMediaSelection: AVMediaSelection): void;

  URLSessionAssetDownloadTaskWillDownloadToURL?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, location: NSURL): void;

  URLSessionAggregateAssetDownloadTaskWillDownloadToURL?(session: NSURLSession, aggregateAssetDownloadTask: AVAggregateAssetDownloadTask, location: NSURL): void;

  URLSessionAggregateAssetDownloadTaskDidCompleteForMediaSelection?(session: NSURLSession, aggregateAssetDownloadTask: AVAggregateAssetDownloadTask, mediaSelection: AVMediaSelection): void;

  URLSessionAggregateAssetDownloadTaskDidLoadTimeRangeTotalTimeRangesLoadedTimeRangeExpectedToLoadForMediaSelection?(session: NSURLSession, aggregateAssetDownloadTask: AVAggregateAssetDownloadTask, timeRange: CMTimeRange, loadedTimeRanges: NSArray<interop.Object> | Array<interop.Object>, timeRangeExpectedToLoad: CMTimeRange, mediaSelection: AVMediaSelection): void;

  URLSessionAssetDownloadTaskWillDownloadVariants?(session: NSURLSession, assetDownloadTask: AVAssetDownloadTask, variants: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVAssetDownloadDelegate extends NativeObject implements AVAssetDownloadDelegate {
}

declare interface AVAssetWriterDelegate extends NSObjectProtocol {
  assetWriterDidOutputSegmentDataSegmentTypeSegmentReport?(writer: AVAssetWriter, segmentData: NSData, segmentType: interop.Enum<typeof AVAssetSegmentType>, segmentReport: AVAssetSegmentReport | null): void;

  assetWriterDidOutputSegmentDataSegmentType?(writer: AVAssetWriter, segmentData: NSData, segmentType: interop.Enum<typeof AVAssetSegmentType>): void;
}

declare class AVAssetWriterDelegate extends NativeObject implements AVAssetWriterDelegate {
}

declare interface AVVideoCompositionValidationHandling extends NSObjectProtocol {
  videoCompositionShouldContinueValidatingAfterFindingInvalidValueForKey?(videoComposition: AVVideoComposition, key: string): boolean;

  videoCompositionShouldContinueValidatingAfterFindingEmptyTimeRange?(videoComposition: AVVideoComposition, timeRange: CMTimeRange): boolean;

  videoCompositionShouldContinueValidatingAfterFindingInvalidTimeRangeInInstruction?(videoComposition: AVVideoComposition, videoCompositionInstruction: AVVideoCompositionInstruction): boolean;

  videoCompositionShouldContinueValidatingAfterFindingInvalidTrackIDInInstructionLayerInstructionAsset?(videoComposition: AVVideoComposition, videoCompositionInstruction: AVVideoCompositionInstruction, layerInstruction: AVVideoCompositionLayerInstruction, asset: AVAsset): boolean;
}

declare class AVVideoCompositionValidationHandling extends NativeObject implements AVVideoCompositionValidationHandling {
}

declare interface AVPlayerItemMetadataCollectorPushDelegate extends NSObjectProtocol {
  metadataCollectorDidCollectDateRangeMetadataGroupsIndexesOfNewGroupsIndexesOfModifiedGroups(metadataCollector: AVPlayerItemMetadataCollector, metadataGroups: NSArray<interop.Object> | Array<interop.Object>, indexesOfNewGroups: NSIndexSet, indexesOfModifiedGroups: NSIndexSet): void;
}

declare class AVPlayerItemMetadataCollectorPushDelegate extends NativeObject implements AVPlayerItemMetadataCollectorPushDelegate {
}

declare interface AVVideoCompositing extends NSObjectProtocol {
  readonly sourcePixelBufferAttributes: NSDictionary;

  readonly requiredPixelBufferAttributesForRenderContext: NSDictionary;

  renderContextChanged(newRenderContext: AVVideoCompositionRenderContext): void;

  startVideoCompositionRequest(asyncVideoCompositionRequest: AVAsynchronousVideoCompositionRequest): void;

  cancelAllPendingVideoCompositionRequests?(): void;

  readonly supportsWideColorSourceFrames?: boolean;

  readonly supportsHDRSourceFrames?: boolean;

  readonly canConformColorOfSourceFrames?: boolean;

  anticipateRenderingUsingHint?(renderHint: AVVideoCompositionRenderHint): void;

  prerollForRenderingUsingHint?(renderHint: AVVideoCompositionRenderHint): void;
}

declare class AVVideoCompositing extends NativeObject implements AVVideoCompositing {
}

declare interface AVFragmentMinding {
  readonly isAssociatedWithFragmentMinder: boolean;
}

declare class AVFragmentMinding extends NativeObject implements AVFragmentMinding {
}

declare interface AVAsynchronousKeyValueLoading {
  statusOfValueForKeyError(key: string, outError: interop.PointerConvertible): interop.Enum<typeof AVKeyValueStatus>;

  loadValuesAsynchronouslyForKeysCompletionHandler(keys: NSArray<interop.Object> | Array<interop.Object>, handler: () => void | null): void;
}

declare class AVAsynchronousKeyValueLoading extends NativeObject implements AVAsynchronousKeyValueLoading {
}

declare interface AVQueuedSampleBufferRendering extends NSObjectProtocol {
  readonly timebase: interop.Pointer;

  enqueueSampleBuffer(sampleBuffer: interop.PointerConvertible): void;

  flush(): void;

  readonly isReadyForMoreMediaData: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  stopRequestingMediaData(): void;

  readonly hasSufficientMediaDataForReliablePlaybackStart: boolean;
}

declare class AVQueuedSampleBufferRendering extends NativeObject implements AVQueuedSampleBufferRendering {
}

declare interface AVContentKeySessionDelegate extends NSObjectProtocol {
  contentKeySessionDidProvideContentKeyRequest(session: AVContentKeySession, keyRequest: AVContentKeyRequest): void;

  contentKeySessionDidProvideRenewingContentKeyRequest?(session: AVContentKeySession, keyRequest: AVContentKeyRequest): void;

  contentKeySessionDidProvidePersistableContentKeyRequest?(session: AVContentKeySession, keyRequest: AVPersistableContentKeyRequest): void;

  contentKeySessionDidUpdatePersistableContentKeyForContentKeyIdentifier?(session: AVContentKeySession, persistableContentKey: NSData, keyIdentifier: interop.Object): void;

  contentKeySessionContentKeyRequestDidFailWithError?(session: AVContentKeySession, keyRequest: AVContentKeyRequest, err: NSError): void;

  contentKeySessionShouldRetryContentKeyRequestReason?(session: AVContentKeySession, keyRequest: AVContentKeyRequest, retryReason: string): boolean;

  contentKeySessionContentKeyRequestDidSucceed?(session: AVContentKeySession, keyRequest: AVContentKeyRequest): void;

  contentKeySessionContentProtectionSessionIdentifierDidChange?(session: AVContentKeySession): void;

  contentKeySessionDidGenerateExpiredSessionReport?(session: AVContentKeySession): void;

  contentKeySessionExternalProtectionStatusDidChangeForContentKey?(session: AVContentKeySession, contentKey: AVContentKey): void;

  contentKeySessionDidProvideContentKeyRequestsForInitializationData?(session: AVContentKeySession, keyRequests: NSArray<interop.Object> | Array<interop.Object>, initializationData: NSData | null): void;
}

declare class AVContentKeySessionDelegate extends NativeObject implements AVContentKeySessionDelegate {
}

declare interface AVCapturePhotoCaptureDelegate extends NSObjectProtocol {
  captureOutputWillBeginCaptureForResolvedSettings?(output: AVCapturePhotoOutput, resolvedSettings: AVCaptureResolvedPhotoSettings): void;

  captureOutputWillCapturePhotoForResolvedSettings?(output: AVCapturePhotoOutput, resolvedSettings: AVCaptureResolvedPhotoSettings): void;

  captureOutputDidCapturePhotoForResolvedSettings?(output: AVCapturePhotoOutput, resolvedSettings: AVCaptureResolvedPhotoSettings): void;

  captureOutputDidFinishProcessingPhotoError?(output: AVCapturePhotoOutput, photo: AVCapturePhoto, error: NSError | null): void;

  captureOutputDidFinishCapturingDeferredPhotoProxyError?(output: AVCapturePhotoOutput, deferredPhotoProxy: AVCaptureDeferredPhotoProxy | null, error: NSError | null): void;

  captureOutputDidFinishProcessingPhotoSampleBufferPreviewPhotoSampleBufferResolvedSettingsBracketSettingsError?(output: AVCapturePhotoOutput, photoSampleBuffer: interop.PointerConvertible, previewPhotoSampleBuffer: interop.PointerConvertible, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings | null, error: NSError | null): void;

  captureOutputDidFinishProcessingRawPhotoSampleBufferPreviewPhotoSampleBufferResolvedSettingsBracketSettingsError?(output: AVCapturePhotoOutput, rawSampleBuffer: interop.PointerConvertible, previewPhotoSampleBuffer: interop.PointerConvertible, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings | null, error: NSError | null): void;

  captureOutputDidFinishRecordingLivePhotoMovieForEventualFileAtURLResolvedSettings?(output: AVCapturePhotoOutput, outputFileURL: NSURL, resolvedSettings: AVCaptureResolvedPhotoSettings): void;

  captureOutputDidFinishProcessingLivePhotoToMovieFileAtURLDurationPhotoDisplayTimeResolvedSettingsError?(output: AVCapturePhotoOutput, outputFileURL: NSURL, duration: CMTime, photoDisplayTime: CMTime, resolvedSettings: AVCaptureResolvedPhotoSettings, error: NSError | null): void;

  captureOutputDidFinishCaptureForResolvedSettingsError?(output: AVCapturePhotoOutput, resolvedSettings: AVCaptureResolvedPhotoSettings, error: NSError | null): void;
}

declare class AVCapturePhotoCaptureDelegate extends NativeObject implements AVCapturePhotoCaptureDelegate {
}

declare interface AVPlayerItemRenderedLegibleOutputPushDelegate extends AVPlayerItemOutputPushDelegate {
  renderedLegibleOutputDidOutputRenderedCaptionImagesForItemTime?(output: AVPlayerItemRenderedLegibleOutput, captionImages: NSArray<interop.Object> | Array<interop.Object>, itemTime: CMTime): void;
}

declare class AVPlayerItemRenderedLegibleOutputPushDelegate extends NativeObject implements AVPlayerItemRenderedLegibleOutputPushDelegate {
}

declare interface AVVideoCompositionInstructionProtocol extends NSObjectProtocol {
  readonly timeRange: CMTimeRange;

  readonly enablePostProcessing: boolean;

  readonly containsTweening: boolean;

  readonly requiredSourceTrackIDs: NSArray;

  readonly passthroughTrackID: number;

  readonly requiredSourceSampleDataTrackIDs?: NSArray;
}

declare class AVVideoCompositionInstructionProtocol extends NativeObject implements AVVideoCompositionInstructionProtocol {
}

declare interface AVAssetResourceLoaderDelegate extends NSObjectProtocol {
  resourceLoaderShouldWaitForLoadingOfRequestedResource?(resourceLoader: AVAssetResourceLoader, loadingRequest: AVAssetResourceLoadingRequest): boolean;

  resourceLoaderShouldWaitForRenewalOfRequestedResource?(resourceLoader: AVAssetResourceLoader, renewalRequest: AVAssetResourceRenewalRequest): boolean;

  resourceLoaderDidCancelLoadingRequest?(resourceLoader: AVAssetResourceLoader, loadingRequest: AVAssetResourceLoadingRequest): void;

  resourceLoaderShouldWaitForResponseToAuthenticationChallenge?(resourceLoader: AVAssetResourceLoader, authenticationChallenge: NSURLAuthenticationChallenge): boolean;

  resourceLoaderDidCancelAuthenticationChallenge?(resourceLoader: AVAssetResourceLoader, authenticationChallenge: NSURLAuthenticationChallenge): void;
}

declare class AVAssetResourceLoaderDelegate extends NativeObject implements AVAssetResourceLoaderDelegate {
}

declare interface AVCapturePhotoOutputReadinessCoordinatorDelegate extends NSObjectProtocol {
  readinessCoordinatorCaptureReadinessDidChange?(coordinator: AVCapturePhotoOutputReadinessCoordinator, captureReadiness: interop.Enum<typeof AVCapturePhotoOutputCaptureReadiness>): void;
}

declare class AVCapturePhotoOutputReadinessCoordinatorDelegate extends NativeObject implements AVCapturePhotoOutputReadinessCoordinatorDelegate {
}

declare interface AVCaptureMetadataOutputObjectsDelegate extends NSObjectProtocol {
  captureOutputDidOutputMetadataObjectsFromConnection?(output: AVCaptureOutput, metadataObjects: NSArray<interop.Object> | Array<interop.Object>, connection: AVCaptureConnection): void;
}

declare class AVCaptureMetadataOutputObjectsDelegate extends NativeObject implements AVCaptureMetadataOutputObjectsDelegate {
}

declare interface AVPlayerItemLegibleOutputPushDelegate extends AVPlayerItemOutputPushDelegate {
  legibleOutputDidOutputAttributedStringsNativeSampleBuffersForItemTime?(output: AVPlayerItemLegibleOutput, strings: NSArray<interop.Object> | Array<interop.Object>, nativeSamples: NSArray<interop.Object> | Array<interop.Object>, itemTime: CMTime): void;
}

declare class AVPlayerItemLegibleOutputPushDelegate extends NativeObject implements AVPlayerItemLegibleOutputPushDelegate {
}

declare interface AVAssetReaderCaptionValidationHandling extends NSObjectProtocol {
  captionAdaptorDidVendCaptionSkippingUnsupportedSourceSyntaxElements?(adaptor: AVAssetReaderOutputCaptionAdaptor, caption: AVCaption, syntaxElements: NSArray<interop.Object> | Array<interop.Object>): void;
}

declare class AVAssetReaderCaptionValidationHandling extends NativeObject implements AVAssetReaderCaptionValidationHandling {
}

declare interface AVContentKeyRecipient {
  contentKeySessionDidProvideContentKey?(contentKeySession: AVContentKeySession, contentKey: AVContentKey): void;

  readonly mayRequireContentKeysForMediaDataProcessing: boolean;
}

declare class AVContentKeyRecipient extends NativeObject implements AVContentKeyRecipient {
}

declare interface AVCaptureFileOutputRecordingDelegate extends NSObjectProtocol {
  captureOutputDidStartRecordingToOutputFileAtURLFromConnections?(output: AVCaptureFileOutput, fileURL: NSURL, connections: NSArray<interop.Object> | Array<interop.Object>): void;

  captureOutputDidPauseRecordingToOutputFileAtURLFromConnections?(output: AVCaptureFileOutput, fileURL: NSURL, connections: NSArray<interop.Object> | Array<interop.Object>): void;

  captureOutputDidResumeRecordingToOutputFileAtURLFromConnections?(output: AVCaptureFileOutput, fileURL: NSURL, connections: NSArray<interop.Object> | Array<interop.Object>): void;

  captureOutputDidFinishRecordingToOutputFileAtURLFromConnectionsError(output: AVCaptureFileOutput, outputFileURL: NSURL, connections: NSArray<interop.Object> | Array<interop.Object>, error: NSError | null): void;
}

declare class AVCaptureFileOutputRecordingDelegate extends NativeObject implements AVCaptureFileOutputRecordingDelegate {
}

declare class AVCaptureSystemExposureBiasSlider extends AVCaptureControl {
  initWithDevice(device: AVCaptureDevice): this;

  initWithDeviceAction(device: AVCaptureDevice, action: (p1: number) => void): this;
}

declare class AVCaptureSystemZoomSlider extends AVCaptureControl {
  initWithDevice(device: AVCaptureDevice): this;

  initWithDeviceAction(device: AVCaptureDevice, action: (p1: number) => void): this;
}

declare class AVCaptureIndexPicker extends AVCaptureControl {
  initWithLocalizedTitleSymbolNameNumberOfIndexes(localizedTitle: string, symbolName: string, numberOfIndexes: number): this;

  initWithLocalizedTitleSymbolNameNumberOfIndexesLocalizedTitleTransform(localizedTitle: string, symbolName: string, numberOfIndexes: number, localizedTitleTransform: (p1: number) => string): this;

  initWithLocalizedTitleSymbolNameLocalizedIndexTitles(localizedTitle: string, symbolName: string, localizedIndexTitles: NSArray<interop.Object> | Array<interop.Object>): this;

  selectedIndex: number;

  readonly localizedTitle: string;

  readonly symbolName: string;

  readonly numberOfIndexes: number;

  readonly localizedIndexTitles: NSArray;

  accessibilityIdentifier: string;

  setActionQueueAction(actionQueue: NSObject, action: (p1: number) => void): void;
}

declare class AVCaptureSlider extends AVCaptureControl {
  initWithLocalizedTitleSymbolNameMinValueMaxValue(localizedTitle: string, symbolName: string, minValue: number, maxValue: number): this;

  initWithLocalizedTitleSymbolNameMinValueMaxValueStep(localizedTitle: string, symbolName: string, minValue: number, maxValue: number, step: number): this;

  initWithLocalizedTitleSymbolNameValues(localizedTitle: string, symbolName: string, values: NSArray<interop.Object> | Array<interop.Object>): this;

  value: number;

  localizedValueFormat: string;

  get prominentValues(): NSArray;
  set prominentValues(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly localizedTitle: string;

  readonly symbolName: string;

  accessibilityIdentifier: string;

  setActionQueueAction(actionQueue: NSObject, action: (p1: number) => void): void;
}

declare class AVCaptureControl extends NSObject {
  isEnabled: boolean;
}

declare class AVPortraitEffectsMatte extends NSObject {
  static portraitEffectsMatteFromDictionaryRepresentationError<This extends abstract new (...args: any) => any>(this: This, imageSourceAuxDataInfoDictionary: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, outError: interop.PointerConvertible): InstanceType<This>;

  portraitEffectsMatteByApplyingExifOrientation(exifOrientation: interop.Enum<typeof CGImagePropertyOrientation>): this;

  portraitEffectsMatteByReplacingPortraitEffectsMatteWithPixelBufferError(pixelBuffer: interop.PointerConvertible, outError: interop.PointerConvertible): this;

  dictionaryRepresentationForAuxiliaryDataType(outAuxDataType: interop.PointerConvertible): NSDictionary;

  readonly pixelFormatType: number;

  readonly mattingImage: interop.Pointer;
}

declare class AVExternalStorageDevice extends NSObject {
  readonly displayName: string;

  readonly freeSize: number;

  readonly totalSize: number;

  readonly isConnected: boolean;

  readonly uuid: NSUUID;

  readonly isNotRecommendedForCaptureUse: boolean;

  nextAvailableURLsWithPathExtensionsError(extensionArray: NSArray<interop.Object> | Array<interop.Object>, outError: interop.PointerConvertible): NSArray;

  static readonly authorizationStatus: interop.Enum<typeof AVAuthorizationStatus>;

  static requestAccessWithCompletionHandler(handler: (p1: boolean) => void): void;
}

declare class AVCameraCalibrationData extends NSObject {
  readonly intrinsicMatrix: simd_float3x3;

  readonly intrinsicMatrixReferenceDimensions: CGSize;

  readonly extrinsicMatrix: simd_float4x3;

  readonly pixelSize: number;

  readonly lensDistortionLookupTable: NSData;

  readonly inverseLensDistortionLookupTable: NSData;

  readonly lensDistortionCenter: CGPoint;
}

declare class AVCaptureVideoPreviewLayer extends CALayer {
  static layerWithSession<This extends abstract new (...args: any) => any>(this: This, session: AVCaptureSession): InstanceType<This>;

  initWithSession(session: AVCaptureSession): this;

  static layerWithSessionWithNoConnection<This extends abstract new (...args: any) => any>(this: This, session: AVCaptureSession): InstanceType<This>;

  initWithSessionWithNoConnection(session: AVCaptureSession): this;

  session: AVCaptureSession;

  setSessionWithNoConnection(session: AVCaptureSession): void;

  readonly connection: AVCaptureConnection;

  videoGravity: string;

  readonly isPreviewing: boolean;

  captureDevicePointOfInterestForPoint(pointInLayer: CGPoint): CGPoint;

  pointForCaptureDevicePointOfInterest(captureDevicePointOfInterest: CGPoint): CGPoint;

  metadataOutputRectOfInterestForRect(rectInLayerCoordinates: CGRect): CGRect;

  rectForMetadataOutputRectOfInterest(rectInMetadataOutputCoordinates: CGRect): CGRect;

  transformedMetadataObjectForMetadataObject(metadataObject: AVMetadataObject): AVMetadataObject;

  readonly isOrientationSupported: boolean;

  orientation: interop.Enum<typeof AVCaptureVideoOrientation>;

  readonly isMirroringSupported: boolean;

  automaticallyAdjustsMirroring: boolean;

  isMirrored: boolean;
}

declare class AVCaptureSystemPressureState extends NSObject {
  readonly level: string;

  readonly factors: interop.Enum<typeof AVCaptureSystemPressureFactors>;
}

declare class AVCaptureMetadataInput extends AVCaptureInput {
  static metadataInputWithFormatDescriptionClock<This extends abstract new (...args: any) => any>(this: This, desc: interop.PointerConvertible, clock: interop.PointerConvertible): InstanceType<This>;

  initWithFormatDescriptionClock(desc: interop.PointerConvertible, clock: interop.PointerConvertible): this;

  appendTimedMetadataGroupError(metadata: AVTimedMetadataGroup, outError: interop.PointerConvertible): boolean;
}

declare class AVCaptureDeviceInput extends AVCaptureInput {
  static deviceInputWithDeviceError<This extends abstract new (...args: any) => any>(this: This, device: AVCaptureDevice, outError: interop.PointerConvertible): InstanceType<This>;

  initWithDeviceError(device: AVCaptureDevice, outError: interop.PointerConvertible): this;

  readonly device: AVCaptureDevice;

  unifiedAutoExposureDefaultsEnabled: boolean;

  portsWithMediaTypeSourceDeviceTypeSourceDevicePosition(mediaType: string | null, sourceDeviceType: string | null, sourceDevicePosition: interop.Enum<typeof AVCaptureDevicePosition>): NSArray;

  videoMinFrameDurationOverride: CMTime;

  isMultichannelAudioModeSupported(multichannelAudioMode: interop.Enum<typeof AVCaptureMultichannelAudioMode>): boolean;

  multichannelAudioMode: interop.Enum<typeof AVCaptureMultichannelAudioMode>;

  readonly isWindNoiseRemovalSupported: boolean;

  isWindNoiseRemovalEnabled: boolean;
}

declare class AVCaptureInputPort extends NSObject {
  readonly input: AVCaptureInput;

  readonly mediaType: string;

  readonly formatDescription: interop.Pointer;

  isEnabled: boolean;

  readonly clock: interop.Pointer;

  readonly sourceDeviceType: string;

  readonly sourceDevicePosition: interop.Enum<typeof AVCaptureDevicePosition>;
}

declare class AVCaptureSynchronizedDepthData extends AVCaptureSynchronizedData {
  readonly depthData: AVDepthData;

  readonly depthDataWasDropped: boolean;

  readonly droppedReason: interop.Enum<typeof AVCaptureOutputDataDroppedReason>;
}

declare class AVCaptureSynchronizedSampleBufferData extends AVCaptureSynchronizedData {
  readonly sampleBuffer: interop.Pointer;

  readonly sampleBufferWasDropped: boolean;

  readonly droppedReason: interop.Enum<typeof AVCaptureOutputDataDroppedReason>;
}

declare class AVCaptureSynchronizedData extends NSObject {
  readonly timestamp: CMTime;
}

declare class AVCaptureSynchronizedDataCollection extends NSObject implements NSFastEnumeration {
  synchronizedDataForCaptureOutput(captureOutput: AVCaptureOutput): AVCaptureSynchronizedData;

  objectForKeyedSubscript(key: AVCaptureOutput): AVCaptureSynchronizedData;

  readonly count: number;

  countByEnumeratingWithStateObjectsCount(state: interop.PointerConvertible, buffer: interop.PointerConvertible, len: number): number;

  readonly [Symbol.iterator]: () => Iterator<any>;

}

declare class AVCaptureDataOutputSynchronizer extends NSObject {
  initWithDataOutputs(dataOutputs: NSArray<interop.Object> | Array<interop.Object>): this;

  readonly dataOutputs: NSArray;

  setDelegateQueue(delegate: AVCaptureDataOutputSynchronizerDelegate | null, delegateCallbackQueue: NSObject | null): void;

  readonly delegate: AVCaptureDataOutputSynchronizerDelegate;

  readonly delegateCallbackQueue: NSObject;
}

declare class AVCaptureAutoExposureBracketedStillImageSettings extends AVCaptureBracketedStillImageSettings {
  static autoExposureSettingsWithExposureTargetBias<This extends abstract new (...args: any) => any>(this: This, exposureTargetBias: number): InstanceType<This>;

  readonly exposureTargetBias: number;
}

declare class AVCaptureManualExposureBracketedStillImageSettings extends AVCaptureBracketedStillImageSettings {
  static manualExposureSettingsWithExposureDurationISO<This extends abstract new (...args: any) => any>(this: This, duration: CMTime, ISO: number): InstanceType<This>;

  readonly exposureDuration: CMTime;

  readonly ISO: number;
}

declare class AVCaptureBracketedStillImageSettings extends NSObject {
}

declare class AVCaptureStillImageOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  get outputSettings(): NSDictionary;
  set outputSettings(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  readonly availableImageDataCVPixelFormatTypes: NSArray;

  readonly availableImageDataCodecTypes: NSArray;

  readonly isStillImageStabilizationSupported: boolean;

  automaticallyEnablesStillImageStabilizationWhenAvailable: boolean;

  readonly isStillImageStabilizationActive: boolean;

  isHighResolutionStillImageOutputEnabled: boolean;

  readonly isCapturingStillImage: boolean;

  captureStillImageAsynchronouslyFromConnectionCompletionHandler(connection: AVCaptureConnection, handler: (p1: interop.PointerConvertible, p2: NSError) => void | null): void;

  static jpegStillImageNSDataRepresentation(jpegSampleBuffer: interop.PointerConvertible): NSData;

  readonly maxBracketedCaptureStillImageCount: number;

  readonly isLensStabilizationDuringBracketedCaptureSupported: boolean;

  isLensStabilizationDuringBracketedCaptureEnabled: boolean;

  prepareToCaptureStillImageBracketFromConnectionWithSettingsArrayCompletionHandler(connection: AVCaptureConnection, settings: NSArray<interop.Object> | Array<interop.Object>, handler: (p1: boolean, p2: NSError) => void | null): void;

  captureStillImageBracketAsynchronouslyFromConnectionWithSettingsArrayCompletionHandler(connection: AVCaptureConnection, settings: NSArray<interop.Object> | Array<interop.Object>, handler: (p1: interop.PointerConvertible, p2: AVCaptureBracketedStillImageSettings, p3: NSError) => void | null): void;
}

declare class AVCapturePhotoSettings extends NSObject implements NSCopying {
  static photoSettings<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  static photoSettingsWithFormat<This extends abstract new (...args: any) => any>(this: This, format: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static photoSettingsWithRawPixelFormatType<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number): InstanceType<This>;

  static photoSettingsWithRawPixelFormatTypeProcessedFormat<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number, processedFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static photoSettingsWithRawPixelFormatTypeRawFileTypeProcessedFormatProcessedFileType<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number, rawFileType: string | null, processedFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, processedFileType: string | null): InstanceType<This>;

  static photoSettingsFromPhotoSettings<This extends abstract new (...args: any) => any>(this: This, photoSettings: AVCapturePhotoSettings): InstanceType<This>;

  readonly uniqueID: number;

  readonly format: NSDictionary;

  get rawFileFormat(): NSDictionary;
  set rawFileFormat(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  readonly processedFileType: string;

  readonly rawPhotoPixelFormatType: number;

  readonly rawFileType: string;

  flashMode: interop.Enum<typeof AVCaptureFlashMode>;

  isAutoRedEyeReductionEnabled: boolean;

  photoQualityPrioritization: interop.Enum<typeof AVCapturePhotoQualityPrioritization>;

  isAutoStillImageStabilizationEnabled: boolean;

  isAutoVirtualDeviceFusionEnabled: boolean;

  isAutoDualCameraFusionEnabled: boolean;

  get virtualDeviceConstituentPhotoDeliveryEnabledDevices(): NSArray;
  set virtualDeviceConstituentPhotoDeliveryEnabledDevices(value: NSArray<interop.Object> | Array<interop.Object>);

  isDualCameraDualPhotoDeliveryEnabled: boolean;

  isHighResolutionPhotoEnabled: boolean;

  maxPhotoDimensions: CMVideoDimensions;

  isDepthDataDeliveryEnabled: boolean;

  embedsDepthDataInPhoto: boolean;

  isDepthDataFiltered: boolean;

  isCameraCalibrationDataDeliveryEnabled: boolean;

  isPortraitEffectsMatteDeliveryEnabled: boolean;

  embedsPortraitEffectsMatteInPhoto: boolean;

  get enabledSemanticSegmentationMatteTypes(): NSArray;
  set enabledSemanticSegmentationMatteTypes(value: NSArray<interop.Object> | Array<interop.Object>);

  embedsSemanticSegmentationMattesInPhoto: boolean;

  get metadata(): NSDictionary;
  set metadata(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  livePhotoMovieFileURL: NSURL;

  livePhotoVideoCodecType: string;

  get livePhotoMovieMetadata(): NSArray;
  set livePhotoMovieMetadata(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly availablePreviewPhotoPixelFormatTypes: NSArray;

  get previewPhotoFormat(): NSDictionary;
  set previewPhotoFormat(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  readonly availableEmbeddedThumbnailPhotoCodecTypes: NSArray;

  get embeddedThumbnailPhotoFormat(): NSDictionary;
  set embeddedThumbnailPhotoFormat(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  readonly availableRawEmbeddedThumbnailPhotoCodecTypes: NSArray;

  get rawEmbeddedThumbnailPhotoFormat(): NSDictionary;
  set rawEmbeddedThumbnailPhotoFormat(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  isAutoContentAwareDistortionCorrectionEnabled: boolean;

  isConstantColorEnabled: boolean;

  isConstantColorFallbackPhotoDeliveryEnabled: boolean;

  isShutterSoundSuppressionEnabled: boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCapturePhotoOutputReadinessCoordinator extends NSObject {
  initWithPhotoOutput(photoOutput: AVCapturePhotoOutput): this;

  delegate: AVCapturePhotoOutputReadinessCoordinatorDelegate;

  readonly captureReadiness: interop.Enum<typeof AVCapturePhotoOutputCaptureReadiness>;

  startTrackingCaptureRequestUsingPhotoSettings(settings: AVCapturePhotoSettings): void;

  stopTrackingCaptureRequestUsingPhotoSettingsUniqueID(settingsUniqueID: number): void;
}

declare class AVCapturePhotoOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  capturePhotoWithSettingsDelegate(settings: AVCapturePhotoSettings, delegate: AVCapturePhotoCaptureDelegate): void;

  readonly preparedPhotoSettingsArray: NSArray;

  setPreparedPhotoSettingsArrayCompletionHandler(preparedPhotoSettingsArray: NSArray<interop.Object> | Array<interop.Object>, completionHandler: (p1: boolean, p2: NSError) => void | null): void;

  readonly availablePhotoPixelFormatTypes: NSArray;

  readonly availablePhotoCodecTypes: NSArray;

  readonly availableRawPhotoCodecTypes: NSArray;

  readonly isAppleProRAWSupported: boolean;

  isAppleProRAWEnabled: boolean;

  static isBayerRAWPixelFormat(pixelFormat: number): boolean;

  static isAppleProRAWPixelFormat(pixelFormat: number): boolean;

  readonly availableRawPhotoPixelFormatTypes: NSArray;

  readonly availablePhotoFileTypes: NSArray;

  readonly availableRawPhotoFileTypes: NSArray;

  supportedPhotoPixelFormatTypesForFileType(fileType: string): NSArray;

  supportedPhotoCodecTypesForFileType(fileType: string): NSArray;

  supportedRawPhotoCodecTypesForRawPhotoPixelFormatTypeFileType(pixelFormatType: number, fileType: string): NSArray;

  supportedRawPhotoPixelFormatTypesForFileType(fileType: string): NSArray;

  maxPhotoQualityPrioritization: interop.Enum<typeof AVCapturePhotoQualityPrioritization>;

  isFastCapturePrioritizationSupported: boolean;

  isFastCapturePrioritizationEnabled: boolean;

  readonly isAutoDeferredPhotoDeliverySupported: boolean;

  isAutoDeferredPhotoDeliveryEnabled: boolean;

  readonly isStillImageStabilizationSupported: boolean;

  readonly isStillImageStabilizationScene: boolean;

  readonly isVirtualDeviceFusionSupported: boolean;

  readonly isDualCameraFusionSupported: boolean;

  readonly isVirtualDeviceConstituentPhotoDeliverySupported: boolean;

  readonly isDualCameraDualPhotoDeliverySupported: boolean;

  isVirtualDeviceConstituentPhotoDeliveryEnabled: boolean;

  isDualCameraDualPhotoDeliveryEnabled: boolean;

  readonly isCameraCalibrationDataDeliverySupported: boolean;

  readonly supportedFlashModes: NSArray;

  readonly isAutoRedEyeReductionSupported: boolean;

  readonly isFlashScene: boolean;

  photoSettingsForSceneMonitoring: AVCapturePhotoSettings;

  isHighResolutionCaptureEnabled: boolean;

  maxPhotoDimensions: CMVideoDimensions;

  readonly maxBracketedCapturePhotoCount: number;

  readonly isLensStabilizationDuringBracketedCaptureSupported: boolean;

  readonly isLivePhotoCaptureSupported: boolean;

  isLivePhotoCaptureEnabled: boolean;

  isLivePhotoCaptureSuspended: boolean;

  preservesLivePhotoCaptureSuspendedOnSessionStop: boolean;

  isLivePhotoAutoTrimmingEnabled: boolean;

  readonly availableLivePhotoVideoCodecTypes: NSArray;

  static JPEGPhotoDataRepresentationForJPEGSampleBufferPreviewPhotoSampleBuffer(JPEGSampleBuffer: interop.PointerConvertible, previewPhotoSampleBuffer: interop.PointerConvertible): NSData;

  static DNGPhotoDataRepresentationForRawSampleBufferPreviewPhotoSampleBuffer(rawSampleBuffer: interop.PointerConvertible, previewPhotoSampleBuffer: interop.PointerConvertible): NSData;

  readonly isContentAwareDistortionCorrectionSupported: boolean;

  isContentAwareDistortionCorrectionEnabled: boolean;

  readonly isZeroShutterLagSupported: boolean;

  isZeroShutterLagEnabled: boolean;

  readonly isResponsiveCaptureSupported: boolean;

  isResponsiveCaptureEnabled: boolean;

  readonly captureReadiness: interop.Enum<typeof AVCapturePhotoOutputCaptureReadiness>;

  readonly isConstantColorSupported: boolean;

  isConstantColorEnabled: boolean;

  readonly isShutterSoundSuppressionSupported: boolean;

  readonly isDepthDataDeliverySupported: boolean;

  isDepthDataDeliveryEnabled: boolean;

  readonly isPortraitEffectsMatteDeliverySupported: boolean;

  isPortraitEffectsMatteDeliveryEnabled: boolean;

  readonly availableSemanticSegmentationMatteTypes: NSArray;

  get enabledSemanticSegmentationMatteTypes(): NSArray;
  set enabledSemanticSegmentationMatteTypes(value: NSArray<interop.Object> | Array<interop.Object>);
}

declare class AVSemanticSegmentationMatte extends NSObject {
  static semanticSegmentationMatteFromImageSourceAuxiliaryDataTypeDictionaryRepresentationError<This extends abstract new (...args: any) => any>(this: This, imageSourceAuxiliaryDataType: interop.PointerConvertible, imageSourceAuxiliaryDataInfoDictionary: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, outError: interop.PointerConvertible): InstanceType<This>;

  readonly matteType: string;

  semanticSegmentationMatteByApplyingExifOrientation(exifOrientation: interop.Enum<typeof CGImagePropertyOrientation>): this;

  semanticSegmentationMatteByReplacingSemanticSegmentationMatteWithPixelBufferError(pixelBuffer: interop.PointerConvertible, outError: interop.PointerConvertible): this;

  dictionaryRepresentationForAuxiliaryDataType(outAuxDataType: interop.PointerConvertible): NSDictionary;

  readonly pixelFormatType: number;

  readonly mattingImage: interop.Pointer;
}

declare class AVCaptureMetadataOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  setMetadataObjectsDelegateQueue(objectsDelegate: AVCaptureMetadataOutputObjectsDelegate | null, objectsCallbackQueue: NSObject | null): void;

  readonly metadataObjectsDelegate: AVCaptureMetadataOutputObjectsDelegate;

  readonly metadataObjectsCallbackQueue: NSObject;

  readonly availableMetadataObjectTypes: NSArray;

  get metadataObjectTypes(): NSArray;
  set metadataObjectTypes(value: NSArray<interop.Object> | Array<interop.Object>);

  rectOfInterest: CGRect;
}

declare class AVMetadataMachineReadableCodeObject extends AVMetadataObject {
  readonly corners: NSArray;

  readonly stringValue: string;

  readonly descriptor: CIBarcodeDescriptor;
}

declare class AVMetadataDogBodyObject extends AVMetadataBodyObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataObject extends NSObject {
  readonly time: CMTime;

  readonly duration: CMTime;

  readonly bounds: CGRect;

  readonly type: string;
}

declare class AVCaptureMovieFileOutput extends AVCaptureFileOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  movieFragmentInterval: CMTime;

  get metadata(): NSArray;
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly availableVideoCodecTypes: NSArray;

  supportedOutputSettingsKeysForConnection(connection: AVCaptureConnection): NSArray;

  outputSettingsForConnection(connection: AVCaptureConnection): NSDictionary;

  setOutputSettingsForConnection(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, connection: AVCaptureConnection): void;

  recordsVideoOrientationAndMirroringChangesAsMetadataTrackForConnection(connection: AVCaptureConnection): boolean;

  setRecordsVideoOrientationAndMirroringChangesAsMetadataTrackForConnection(doRecordChanges: boolean, connection: AVCaptureConnection): void;

  isPrimaryConstituentDeviceSwitchingBehaviorForRecordingEnabled: boolean;

  setPrimaryConstituentDeviceSwitchingBehaviorForRecordingRestrictedSwitchingBehaviorConditions(switchingBehavior: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>, restrictedSwitchingBehaviorConditions: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>): void;

  readonly primaryConstituentDeviceSwitchingBehaviorForRecording: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>;

  readonly primaryConstituentDeviceRestrictedSwitchingBehaviorConditionsForRecording: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>;

  readonly isSpatialVideoCaptureSupported: boolean;

  isSpatialVideoCaptureEnabled: boolean;
}

declare class AVCaptureFileOutput extends AVCaptureOutput {
  readonly outputFileURL: NSURL;

  startRecordingToOutputFileURLRecordingDelegate(outputFileURL: NSURL, delegate: AVCaptureFileOutputRecordingDelegate): void;

  stopRecording(): void;

  readonly isRecording: boolean;

  readonly isRecordingPaused: boolean;

  pauseRecording(): void;

  resumeRecording(): void;

  readonly recordedDuration: CMTime;

  readonly recordedFileSize: number;

  maxRecordedDuration: CMTime;

  maxRecordedFileSize: number;

  minFreeDiskSpaceLimit: number;
}

declare class AVCaptureOutput extends NSObject {
  readonly connections: NSArray;

  connectionWithMediaType(mediaType: string): AVCaptureConnection;

  transformedMetadataObjectForMetadataObjectConnection(metadataObject: AVMetadataObject, connection: AVCaptureConnection): AVMetadataObject;

  metadataOutputRectOfInterestForRect(rectInOutputCoordinates: CGRect): CGRect;

  rectForMetadataOutputRectOfInterest(rectInMetadataOutputCoordinates: CGRect): CGRect;
}

declare class AVCaptureAudioChannel extends NSObject {
  readonly averagePowerLevel: number;

  readonly peakHoldLevel: number;
}

declare class AVCaptureConnection extends NSObject {
  static connectionWithInputPortsOutput<This extends abstract new (...args: any) => any>(this: This, ports: NSArray<interop.Object> | Array<interop.Object>, output: AVCaptureOutput): InstanceType<This>;

  static connectionWithInputPortVideoPreviewLayer<This extends abstract new (...args: any) => any>(this: This, port: AVCaptureInputPort, layer: AVCaptureVideoPreviewLayer): InstanceType<This>;

  initWithInputPortsOutput(ports: NSArray<interop.Object> | Array<interop.Object>, output: AVCaptureOutput): this;

  initWithInputPortVideoPreviewLayer(port: AVCaptureInputPort, layer: AVCaptureVideoPreviewLayer): this;

  readonly inputPorts: NSArray;

  readonly output: AVCaptureOutput;

  readonly videoPreviewLayer: AVCaptureVideoPreviewLayer;

  isEnabled: boolean;

  readonly isActive: boolean;

  readonly audioChannels: NSArray;

  readonly isVideoMirroringSupported: boolean;

  isVideoMirrored: boolean;

  automaticallyAdjustsVideoMirroring: boolean;

  isVideoRotationAngleSupported(videoRotationAngle: number): boolean;

  videoRotationAngle: number;

  readonly isVideoOrientationSupported: boolean;

  videoOrientation: interop.Enum<typeof AVCaptureVideoOrientation>;

  readonly isVideoMinFrameDurationSupported: boolean;

  videoMinFrameDuration: CMTime;

  readonly isVideoMaxFrameDurationSupported: boolean;

  videoMaxFrameDuration: CMTime;

  readonly videoMaxScaleAndCropFactor: number;

  videoScaleAndCropFactor: number;

  preferredVideoStabilizationMode: interop.Enum<typeof AVCaptureVideoStabilizationMode>;

  readonly activeVideoStabilizationMode: interop.Enum<typeof AVCaptureVideoStabilizationMode>;

  readonly isVideoStabilizationSupported: boolean;

  readonly isVideoStabilizationEnabled: boolean;

  enablesVideoStabilizationWhenAvailable: boolean;

  readonly isCameraIntrinsicMatrixDeliverySupported: boolean;

  isCameraIntrinsicMatrixDeliveryEnabled: boolean;
}

declare class AVCaptureSession extends NSObject {
  canSetSessionPreset(preset: string): boolean;

  sessionPreset: string;

  readonly inputs: NSArray;

  canAddInput(input: AVCaptureInput): boolean;

  addInput(input: AVCaptureInput): void;

  removeInput(input: AVCaptureInput): void;

  readonly outputs: NSArray;

  canAddOutput(output: AVCaptureOutput): boolean;

  addOutput(output: AVCaptureOutput): void;

  removeOutput(output: AVCaptureOutput): void;

  addInputWithNoConnections(input: AVCaptureInput): void;

  addOutputWithNoConnections(output: AVCaptureOutput): void;

  readonly connections: NSArray;

  canAddConnection(connection: AVCaptureConnection): boolean;

  addConnection(connection: AVCaptureConnection): void;

  removeConnection(connection: AVCaptureConnection): void;

  readonly supportsControls: boolean;

  readonly maxControlsCount: number;

  setControlsDelegateQueue(controlsDelegate: AVCaptureSessionControlsDelegate | null, controlsDelegateCallbackQueue: NSObject | null): void;

  readonly controlsDelegate: AVCaptureSessionControlsDelegate;

  readonly controlsDelegateCallbackQueue: NSObject;

  readonly controls: NSArray;

  canAddControl(control: AVCaptureControl): boolean;

  addControl(control: AVCaptureControl): void;

  removeControl(control: AVCaptureControl): void;

  beginConfiguration(): void;

  commitConfiguration(): void;

  readonly isRunning: boolean;

  readonly isInterrupted: boolean;

  readonly isMultitaskingCameraAccessSupported: boolean;

  isMultitaskingCameraAccessEnabled: boolean;

  usesApplicationAudioSession: boolean;

  automaticallyConfiguresApplicationAudioSession: boolean;

  configuresApplicationAudioSessionToMixWithOthers: boolean;

  automaticallyConfiguresCaptureDeviceForWideColor: boolean;

  startRunning(): void;

  stopRunning(): void;

  readonly synchronizationClock: interop.Pointer;

  readonly masterClock: interop.Pointer;

  readonly hardwareCost: number;
}

declare class AVFrameRateRange extends NSObject {
  readonly minFrameRate: number;

  readonly maxFrameRate: number;

  readonly maxFrameDuration: CMTime;

  readonly minFrameDuration: CMTime;
}

declare class AVExposureBiasRange extends NSObject {
  readonly minExposureBias: number;

  readonly maxExposureBias: number;

  containsExposureBias(exposureBias: number): boolean;
}

declare class AVCaptureDeviceRotationCoordinator extends NSObject {
  initWithDevicePreviewLayer(device: AVCaptureDevice, previewLayer: CALayer | null): this;

  readonly device: AVCaptureDevice;

  readonly previewLayer: CALayer;

  readonly videoRotationAngleForHorizonLevelPreview: number;

  readonly videoRotationAngleForHorizonLevelCapture: number;
}

declare class AVCaptureDeviceDiscoverySession extends NSObject {
  static discoverySessionWithDeviceTypesMediaTypePosition<This extends abstract new (...args: any) => any>(this: This, deviceTypes: NSArray<interop.Object> | Array<interop.Object>, mediaType: string | null, position: interop.Enum<typeof AVCaptureDevicePosition>): InstanceType<This>;

  readonly devices: NSArray;

  readonly supportedMultiCamDeviceSets: NSArray;
}

declare class AVCaptureReactionEffectState extends NSObject {
  readonly reactionType: string;

  readonly startTime: CMTime;

  readonly endTime: CMTime;
}

declare class AVCaptureSynchronizedMetadataObjectData extends AVCaptureSynchronizedData {
  readonly metadataObjects: NSArray;
}

declare class AVVideoPerformanceMetrics extends NSObject {
  readonly totalNumberOfFrames: number;

  readonly numberOfDroppedFrames: number;

  readonly numberOfCorruptedFrames: number;

  readonly numberOfFramesDisplayedUsingOptimizedCompositing: number;

  readonly totalAccumulatedFrameDelay: number;
}

declare class AVSynchronizedLayer extends CALayer {
  static synchronizedLayerWithPlayerItem(playerItem: AVPlayerItem): AVSynchronizedLayer;

  playerItem: AVPlayerItem;
}

declare class AVSampleBufferVideoRenderer extends NSObject implements AVQueuedSampleBufferRendering {
  readonly status: interop.Enum<typeof AVQueuedSampleBufferRenderingStatus>;

  readonly error: NSError;

  readonly requiresFlushToResumeDecoding: boolean;

  flushWithRemovalOfDisplayedImageCompletionHandler(removeDisplayedImage: boolean, handler: () => void | null): void;

  copyDisplayedPixelBuffer(): interop.Pointer;

  expectMinimumUpcomingSampleBufferPresentationTime(minimumUpcomingPresentationTime: CMTime): void;

  expectMonotonicallyIncreasingUpcomingSampleBufferPresentationTimes(): void;

  resetUpcomingSampleBufferPresentationTimeExpectations(): void;

  loadVideoPerformanceMetricsWithCompletionHandler(completionHandler: (p1: AVVideoPerformanceMetrics) => void | null): void;

  readonly timebase: interop.Pointer;

  enqueueSampleBuffer(sampleBuffer: interop.PointerConvertible): void;

  flush(): void;

  readonly isReadyForMoreMediaData: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  stopRequestingMediaData(): void;

  readonly hasSufficientMediaDataForReliablePlaybackStart: boolean;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;
}

declare class AVSampleBufferRequest extends NSObject {
  initWithStartCursor(startCursor: AVSampleCursor): this;

  readonly startCursor: AVSampleCursor;

  direction: interop.Enum<typeof AVSampleBufferRequestDirection>;

  limitCursor: AVSampleCursor;

  preferredMinSampleCount: number;

  maxSampleCount: number;

  mode: interop.Enum<typeof AVSampleBufferRequestMode>;

  overrideTime: CMTime;
}

declare class AVSampleBufferRenderSynchronizer extends NSObject {
  readonly timebase: interop.Pointer;

  rate: number;

  currentTime(): CMTime;

  setRateTime(rate: number, time: CMTime): void;

  setRateTimeAtHostTime(rate: number, time: CMTime, hostTime: CMTime): void;

  delaysRateChangeUntilHasSufficientMediaData: boolean;

  readonly renderers: NSArray;

  addRenderer(renderer: AVQueuedSampleBufferRendering): void;

  removeRendererAtTimeCompletionHandler(renderer: AVQueuedSampleBufferRendering, time: CMTime, completionHandler: (p1: boolean) => void | null): void;

  addPeriodicTimeObserverForIntervalQueueUsingBlock(interval: CMTime, queue: NSObject | null, block: (p1: CMTime) => void): interop.Object;

  addBoundaryTimeObserverForTimesQueueUsingBlock(times: NSArray<interop.Object> | Array<interop.Object>, queue: NSObject | null, block: () => void): interop.Object;

  removeTimeObserver(observer: interop.Object): void;
}

declare class AVSampleBufferDisplayLayer extends CALayer {
  get controlTimebase(): interop.Pointer;
  set controlTimebase(value: interop.PointerConvertible);

  videoGravity: string;

  readonly isReadyForDisplay: boolean;

  readonly timebase: interop.Pointer;

  readonly status: interop.Enum<typeof AVQueuedSampleBufferRenderingStatus>;

  readonly error: NSError;

  enqueueSampleBuffer(sampleBuffer: interop.PointerConvertible): void;

  flush(): void;

  flushAndRemoveImage(): void;

  readonly requiresFlushToResumeDecoding: boolean;

  readonly isReadyForMoreMediaData: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  stopRequestingMediaData(): void;

  readonly hasSufficientMediaDataForReliablePlaybackStart: boolean;

  preventsCapture: boolean;

  preventsDisplaySleepDuringVideoPlayback: boolean;

  readonly outputObscuredDueToInsufficientExternalProtection: boolean;

  readonly sampleBufferRenderer: AVSampleBufferVideoRenderer;
}

declare class AVSampleBufferAudioRenderer extends NSObject implements AVQueuedSampleBufferRendering {
  readonly status: interop.Enum<typeof AVQueuedSampleBufferRenderingStatus>;

  readonly error: NSError;

  audioTimePitchAlgorithm: string;

  allowedAudioSpatializationFormats: interop.Enum<typeof AVAudioSpatializationFormats>;

  volume: number;

  isMuted: boolean;

  flushFromSourceTimeCompletionHandler(time: CMTime, completionHandler: (p1: boolean) => void): void;

  readonly timebase: interop.Pointer;

  enqueueSampleBuffer(sampleBuffer: interop.PointerConvertible): void;

  flush(): void;

  readonly isReadyForMoreMediaData: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  stopRequestingMediaData(): void;

  readonly hasSufficientMediaDataForReliablePlaybackStart: boolean;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;
}

declare class AVRouteDetector extends NSObject {
  isRouteDetectionEnabled: boolean;

  readonly multipleRoutesDetected: boolean;

  detectsCustomRoutes: boolean;
}

declare class AVCaptureResolvedPhotoSettings extends NSObject {
  readonly uniqueID: number;

  readonly photoDimensions: CMVideoDimensions;

  readonly rawPhotoDimensions: CMVideoDimensions;

  readonly previewDimensions: CMVideoDimensions;

  readonly embeddedThumbnailDimensions: CMVideoDimensions;

  readonly rawEmbeddedThumbnailDimensions: CMVideoDimensions;

  readonly portraitEffectsMatteDimensions: CMVideoDimensions;

  dimensionsForSemanticSegmentationMatteOfType(semanticSegmentationMatteType: string): CMVideoDimensions;

  readonly livePhotoMovieDimensions: CMVideoDimensions;

  readonly isFlashEnabled: boolean;

  readonly isRedEyeReductionEnabled: boolean;

  readonly deferredPhotoProxyDimensions: CMVideoDimensions;

  readonly isStillImageStabilizationEnabled: boolean;

  readonly isVirtualDeviceFusionEnabled: boolean;

  readonly isDualCameraFusionEnabled: boolean;

  readonly expectedPhotoCount: number;

  readonly photoProcessingTimeRange: CMTimeRange;

  readonly isContentAwareDistortionCorrectionEnabled: boolean;

  readonly isFastCapturePrioritizationEnabled: boolean;
}

declare class AVRenderedCaptionImage extends NSObject {
  readonly pixelBuffer: interop.Pointer;

  readonly position: CGPoint;
}

declare class AVPlayerItemIntegratedTimelineSnapshot extends NSObject {
  readonly duration: CMTime;

  readonly currentSegment: AVPlayerItemSegment;

  readonly segments: NSArray;

  readonly currentTime: CMTime;

  readonly currentDate: NSDate;

  mapTimeToSegmentAtSegmentOffset(time: CMTime, timeSegmentOut: interop.PointerConvertible, segmentOffsetOut: interop.PointerConvertible): void;
}

declare class AVPlayerItemSegment extends NSObject {
  readonly segmentType: interop.Enum<typeof AVPlayerItemSegmentType>;

  readonly timeMapping: CMTimeMapping;

  readonly loadedTimeRanges: NSArray;

  readonly startDate: NSDate;

  readonly interstitialEvent: AVPlayerInterstitialEvent;
}

declare class AVPlayerInterstitialEventMonitor extends NSObject {
  static interstitialEventMonitorWithPrimaryPlayer<This extends abstract new (...args: any) => any>(this: This, primaryPlayer: AVPlayer): InstanceType<This>;

  initWithPrimaryPlayer(primaryPlayer: AVPlayer): this;

  readonly primaryPlayer: AVPlayer | null;

  readonly interstitialPlayer: AVQueuePlayer;

  readonly events: NSArray;

  readonly currentEvent: AVPlayerInterstitialEvent;
}

declare class AVPlayerInterstitialEvent extends NSObject implements NSCopying {
  static interstitialEventWithPrimaryItemIdentifierTimeTemplateItemsRestrictionsResumptionOffsetPlayoutLimitUserDefinedAttributes<This extends abstract new (...args: any) => any>(this: This, primaryItem: AVPlayerItem, identifier: string | null, time: CMTime, templateItems: NSArray<interop.Object> | Array<interop.Object>, restrictions: interop.Enum<typeof AVPlayerInterstitialEventRestrictions>, resumptionOffset: CMTime, playoutLimit: CMTime, userDefinedAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static interstitialEventWithPrimaryItemIdentifierDateTemplateItemsRestrictionsResumptionOffsetPlayoutLimitUserDefinedAttributes<This extends abstract new (...args: any) => any>(this: This, primaryItem: AVPlayerItem, identifier: string | null, date: NSDate, templateItems: NSArray<interop.Object> | Array<interop.Object>, restrictions: interop.Enum<typeof AVPlayerInterstitialEventRestrictions>, resumptionOffset: CMTime, playoutLimit: CMTime, userDefinedAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static interstitialEventWithPrimaryItemTime<This extends abstract new (...args: any) => any>(this: This, primaryItem: AVPlayerItem, time: CMTime): InstanceType<This>;

  static interstitialEventWithPrimaryItemDate<This extends abstract new (...args: any) => any>(this: This, primaryItem: AVPlayerItem, date: NSDate): InstanceType<This>;

  readonly primaryItem: AVPlayerItem | null;

  readonly identifier: string;

  readonly time: CMTime;

  readonly date: NSDate;

  readonly templateItems: NSArray;

  readonly restrictions: interop.Enum<typeof AVPlayerInterstitialEventRestrictions>;

  readonly resumptionOffset: CMTime;

  readonly playoutLimit: CMTime;

  readonly alignsStartWithPrimarySegmentBoundary: boolean;

  readonly alignsResumptionWithPrimarySegmentBoundary: boolean;

  readonly cue: string;

  readonly willPlayOnce: boolean;

  readonly userDefinedAttributes: NSDictionary;

  readonly assetListResponse: NSDictionary;

  readonly timelineOccupancy: interop.Enum<typeof AVPlayerInterstitialEventTimelineOccupancy>;

  readonly supplementsPrimaryContent: boolean;

  readonly contentMayVary: boolean;

  plannedDuration: CMTime;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVPlayerLooper extends NSObject {
  static playerLooperWithPlayerTemplateItemTimeRange<This extends abstract new (...args: any) => any>(this: This, player: AVQueuePlayer, itemToLoop: AVPlayerItem, loopRange: CMTimeRange): InstanceType<This>;

  static playerLooperWithPlayerTemplateItem<This extends abstract new (...args: any) => any>(this: This, player: AVQueuePlayer, itemToLoop: AVPlayerItem): InstanceType<This>;

  initWithPlayerTemplateItemTimeRange(player: AVQueuePlayer, itemToLoop: AVPlayerItem, loopRange: CMTimeRange): this;

  initWithPlayerTemplateItemTimeRangeExistingItemsOrdering(player: AVQueuePlayer, itemToLoop: AVPlayerItem, loopRange: CMTimeRange, itemOrdering: interop.Enum<typeof AVPlayerLooperItemOrdering>): this;

  readonly status: interop.Enum<typeof AVPlayerLooperStatus>;

  readonly error: NSError;

  disableLooping(): void;

  readonly loopCount: number;

  readonly loopingPlayerItems: NSArray;
}

declare class AVPlayerItemMetadataOutput extends AVPlayerItemOutput {
  initWithIdentifiers(identifiers: NSArray<interop.Object> | Array<interop.Object> | null): this;

  readonly delegate: AVPlayerItemMetadataOutputPushDelegate;

  readonly delegateQueue: NSObject;

  advanceIntervalForDelegateInvocation: number;
}

declare class AVPlayerItemOutput extends NSObject {
  itemTimeForHostTime(hostTimeInSeconds: number): CMTime;

  itemTimeForMachAbsoluteTime(machAbsoluteTime: number): CMTime;

  suppressesPlayerRendering: boolean;
}

declare class AVPlayerItemMetadataCollector extends AVPlayerItemMediaDataCollector {
  initWithIdentifiersClassifyingLabels(identifiers: NSArray<interop.Object> | Array<interop.Object> | null, classifyingLabels: NSArray<interop.Object> | Array<interop.Object> | null): this;

  readonly delegate: AVPlayerItemMetadataCollectorPushDelegate;

  readonly delegateQueue: NSObject;
}

declare class AVPlayerItemAccessLog extends NSObject implements NSCopying {
  extendedLogData(): NSData;

  readonly extendedLogDataStringEncoding: number;

  readonly events: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVPlayerItem extends NSObject implements NSCopying {
  static playerItemWithURL<This extends abstract new (...args: any) => any>(this: This, URL: NSURL): InstanceType<This>;

  static playerItemWithAsset<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset): InstanceType<This>;

  static playerItemWithAssetAutomaticallyLoadedAssetKeys<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset, automaticallyLoadedAssetKeys: NSArray<interop.Object> | Array<interop.Object> | null): InstanceType<This>;

  initWithURL(URL: NSURL): this;

  initWithAsset(asset: AVAsset): this;

  initWithAssetAutomaticallyLoadedAssetKeys(asset: AVAsset, automaticallyLoadedAssetKeys: NSArray<interop.Object> | Array<interop.Object> | null): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  copy(): interop.Object;

  readonly status: interop.Enum<typeof AVPlayerItemStatus>;

  readonly error: NSError;

  readonly asset: AVAsset;

  readonly tracks: NSArray;

  readonly duration: CMTime;

  readonly presentationSize: CGSize;

  readonly timedMetadata: NSArray;

  readonly automaticallyLoadedAssetKeys: NSArray;

  readonly canPlayFastForward: boolean;

  readonly canPlaySlowForward: boolean;

  readonly canPlayReverse: boolean;

  readonly canPlaySlowReverse: boolean;

  readonly canPlayFastReverse: boolean;

  readonly canStepForward: boolean;

  readonly canStepBackward: boolean;

  configuredTimeOffsetFromLive: CMTime;

  readonly recommendedTimeOffsetFromLive: CMTime;

  automaticallyPreservesTimeOffsetFromLive: boolean;

  currentTime(): CMTime;

  forwardPlaybackEndTime: CMTime;

  reversePlaybackEndTime: CMTime;

  readonly seekableTimeRanges: NSArray;

  seekToTimeCompletionHandler(time: CMTime, completionHandler: (p1: boolean) => void | null): void;

  seekToTimeToleranceBeforeToleranceAfterCompletionHandler(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime, completionHandler: (p1: boolean) => void | null): void;

  cancelPendingSeeks(): void;

  currentDate(): NSDate;

  seekToDateCompletionHandler(date: NSDate, completionHandler: (p1: boolean) => void | null): boolean;

  stepByCount(stepCount: number): void;

  readonly timebase: interop.Pointer;

  videoComposition: AVVideoComposition;

  readonly customVideoCompositor: AVVideoCompositing;

  seekingWaitsForVideoCompositionRendering: boolean;

  get textStyleRules(): NSArray;
  set textStyleRules(value: NSArray<interop.Object> | Array<interop.Object>);

  videoApertureMode: string;

  appliesPerFrameHDRDisplayMetadata: boolean;

  audioTimePitchAlgorithm: string;

  isAudioSpatializationAllowed: boolean;

  allowedAudioSpatializationFormats: interop.Enum<typeof AVAudioSpatializationFormats>;

  audioMix: AVAudioMix;

  readonly loadedTimeRanges: NSArray;

  readonly isPlaybackLikelyToKeepUp: boolean;

  readonly isPlaybackBufferFull: boolean;

  readonly isPlaybackBufferEmpty: boolean;

  canUseNetworkResourcesForLiveStreamingWhilePaused: boolean;

  preferredForwardBufferDuration: number;

  preferredPeakBitRate: number;

  preferredPeakBitRateForExpensiveNetworks: number;

  preferredMaximumResolution: CGSize;

  preferredMaximumResolutionForExpensiveNetworks: CGSize;

  startsOnFirstEligibleVariant: boolean;

  variantPreferences: interop.Enum<typeof AVVariantPreferences>;

  selectMediaOptionInMediaSelectionGroup(mediaSelectionOption: AVMediaSelectionOption | null, mediaSelectionGroup: AVMediaSelectionGroup): void;

  selectMediaOptionAutomaticallyInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): void;

  readonly currentMediaSelection: AVMediaSelection;

  accessLog(): AVPlayerItemAccessLog;

  errorLog(): AVPlayerItemErrorLog;

  addOutput(output: AVPlayerItemOutput): void;

  removeOutput(output: AVPlayerItemOutput): void;

  readonly outputs: NSArray;

  addMediaDataCollector(collector: AVPlayerItemMediaDataCollector): void;

  removeMediaDataCollector(collector: AVPlayerItemMediaDataCollector): void;

  readonly mediaDataCollectors: NSArray;

  seekToTime(time: CMTime): void;

  seekToTimeToleranceBeforeToleranceAfter(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime): void;

  seekToDate(date: NSDate): boolean;

  selectedMediaOptionInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): AVMediaSelectionOption;

  automaticallyHandlesInterstitialEvents: boolean;

  readonly templatePlayerItem: AVPlayerItem;

  readonly integratedTimeline: AVPlayerItemIntegratedTimeline;
}

declare class AVMetricPlayerItemVariantSwitchStartEvent extends AVMetricEvent {
  readonly fromVariant: AVAssetVariant;

  readonly toVariant: AVAssetVariant;

  readonly loadedTimeRanges: NSArray;
}

declare class AVMetricPlayerItemVariantSwitchEvent extends AVMetricEvent {
  readonly fromVariant: AVAssetVariant;

  readonly toVariant: AVAssetVariant;

  readonly loadedTimeRanges: NSArray;

  readonly didSucceed: boolean;
}

declare class AVMetricPlayerItemSeekDidCompleteEvent extends AVMetricPlayerItemRateChangeEvent {
  readonly didSeekInBuffer: boolean;
}

declare class AVMetricPlayerItemSeekEvent extends AVMetricPlayerItemRateChangeEvent {
}

declare class AVMetricPlayerItemStallEvent extends AVMetricPlayerItemRateChangeEvent {
}

declare class AVMetricPlayerItemRateChangeEvent extends AVMetricEvent {
  readonly rate: number;

  readonly previousRate: number;

  readonly variant: AVAssetVariant;
}

declare class AVMetricPlayerItemLikelyToKeepUpEvent extends AVMetricEvent {
  readonly variant: AVAssetVariant;

  readonly timeTaken: number;

  readonly loadedTimeRanges: NSArray;
}

declare class AVMetricHLSPlaylistRequestEvent extends AVMetricEvent {
  readonly url: NSURL;

  readonly isMultivariantPlaylist: boolean;

  readonly mediaType: string;

  readonly mediaResourceRequestEvent: AVMetricMediaResourceRequestEvent;
}

declare class AVMetricPlayerItemPlaybackSummaryEvent extends AVMetricEvent {
  readonly errorEvent: AVMetricErrorEvent;

  readonly recoverableErrorCount: number;

  readonly stallCount: number;

  readonly variantSwitchCount: number;

  readonly playbackDuration: number;

  readonly mediaResourceRequestCount: number;

  readonly timeSpentRecoveringFromStall: number;

  readonly timeSpentInInitialStartup: number;

  readonly timeWeightedAverageBitrate: number;

  readonly timeWeightedPeakBitrate: number;
}

declare class AVMetricMediaResourceRequestEvent extends AVMetricEvent {
  readonly url: NSURL;

  readonly serverAddress: string;

  readonly requestStartTime: NSDate;

  readonly requestEndTime: NSDate;

  readonly responseStartTime: NSDate;

  readonly responseEndTime: NSDate;

  readonly byteRange: _NSRange;

  readonly wasReadFromCache: boolean;

  readonly errorEvent: AVMetricErrorEvent;

  readonly networkTransactionMetrics: NSURLSessionTaskMetrics;
}

declare class AVPlayerVideoOutputConfiguration extends NSObject {
  readonly sourcePlayerItem: AVPlayerItem | null;

  readonly dataChannelDescriptions: NSArray;

  readonly preferredTransform: CGAffineTransform;

  readonly activationTime: CMTime;
}

declare class AVVideoOutputSpecification extends NSObject implements NSCopying {
  initWithTagCollections(tagCollections: NSArray<interop.Object> | Array<interop.Object>): this;

  setOutputPixelBufferAttributesForTagCollection(pixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, tagCollection: interop.PointerConvertible): void;

  setOutputSettingsForTagCollection(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, tagCollection: interop.PointerConvertible): void;

  readonly preferredTagCollections: NSArray;

  get defaultPixelBufferAttributes(): NSDictionary;
  set defaultPixelBufferAttributes(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  get defaultOutputSettings(): NSDictionary;
  set defaultOutputSettings(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVPlayerVideoOutput extends NSObject {
  initWithSpecification(specification: AVVideoOutputSpecification): this;

  copyTaggedBufferGroupForHostTimePresentationTimeStampActiveConfiguration(hostTime: CMTime, presentationTimeStampOut: interop.PointerConvertible, activeConfigurationOut: interop.PointerConvertible): interop.Pointer;
}

declare class AVDelegatingPlaybackCoordinatorSeekCommand extends AVDelegatingPlaybackCoordinatorPlaybackControlCommand {
  readonly itemTime: CMTime;

  readonly shouldBufferInAnticipationOfPlayback: boolean;

  readonly anticipatedPlaybackRate: number;

  readonly completionDueDate: NSDate;
}

declare class AVDelegatingPlaybackCoordinatorPauseCommand extends AVDelegatingPlaybackCoordinatorPlaybackControlCommand {
  readonly shouldBufferInAnticipationOfPlayback: boolean;

  readonly anticipatedPlaybackRate: number;
}

declare class AVDelegatingPlaybackCoordinatorBufferingCommand extends AVDelegatingPlaybackCoordinatorPlaybackControlCommand {
  readonly anticipatedPlaybackRate: number;

  readonly completionDueDate: NSDate;
}

declare class AVDelegatingPlaybackCoordinatorPlayCommand extends AVDelegatingPlaybackCoordinatorPlaybackControlCommand {
  readonly rate: number;

  readonly itemTime: CMTime;

  readonly hostClockTime: CMTime;
}

declare class AVDelegatingPlaybackCoordinatorPlaybackControlCommand extends NSObject {
  readonly originator: AVCoordinatedPlaybackParticipant;

  readonly expectedCurrentItemIdentifier: string;
}

declare class AVCoordinatedPlaybackParticipant extends NSObject {
  readonly suspensionReasons: NSArray;

  readonly isReadyToPlay: boolean;

  readonly identifier: NSUUID;
}

declare class AVPlaybackCoordinator extends NSObject {
  readonly otherParticipants: NSArray;

  readonly suspensionReasons: NSArray;

  beginSuspensionForReason(suspensionReason: string): AVCoordinatedPlaybackSuspension;

  expectedItemTimeAtHostTime(hostClockTime: CMTime): CMTime;

  setParticipantLimitForWaitingOutSuspensionsWithReason(participantLimit: number, reason: string): void;

  participantLimitForWaitingOutSuspensionsWithReason(reason: string): number;

  get suspensionReasonsThatTriggerWaiting(): NSArray;
  set suspensionReasonsThatTriggerWaiting(value: NSArray<interop.Object> | Array<interop.Object>);

  pauseSnapsToMediaTimeOfOriginator: boolean;
}

declare class AVQueuePlayer extends AVPlayer {
  static queuePlayerWithItems<This extends abstract new (...args: any) => any>(this: This, items: NSArray<interop.Object> | Array<interop.Object>): InstanceType<This>;

  initWithItems(items: NSArray<interop.Object> | Array<interop.Object>): this;

  items(): NSArray;

  advanceToNextItem(): void;

  canInsertItemAfterItem(item: AVPlayerItem, afterItem: AVPlayerItem | null): boolean;

  insertItemAfterItem(item: AVPlayerItem, afterItem: AVPlayerItem | null): void;

  removeItem(item: AVPlayerItem): void;

  removeAllItems(): void;
}

declare class AVOutputSettingsAssistant extends NSObject {
  static availableOutputSettingsPresets(): NSArray;

  static outputSettingsAssistantWithPreset<This extends abstract new (...args: any) => any>(this: This, presetIdentifier: string): InstanceType<This>;

  readonly audioSettings: NSDictionary;

  readonly videoSettings: NSDictionary;

  readonly outputFileType: string;

  get sourceAudioFormat(): interop.Pointer;
  set sourceAudioFormat(value: interop.PointerConvertible);

  get sourceVideoFormat(): interop.Pointer;
  set sourceVideoFormat(value: interop.PointerConvertible);

  sourceVideoAverageFrameDuration: CMTime;

  sourceVideoMinFrameDuration: CMTime;
}

declare class AVFragmentedMovieMinder extends AVFragmentedAssetMinder {
  static fragmentedMovieMinderWithMovieMindingInterval<This extends abstract new (...args: any) => any>(this: This, movie: AVFragmentedMovie, mindingInterval: number): InstanceType<This>;

  initWithMovieMindingInterval(movie: AVFragmentedMovie, mindingInterval: number): this;

  mindingInterval: number;

  readonly movies: NSArray;

  addFragmentedMovie(movie: AVFragmentedMovie): void;

  removeFragmentedMovie(movie: AVFragmentedMovie): void;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVFragmentedMovie extends AVMovie implements AVFragmentMinding {
  readonly tracks: NSArray;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVFragmentedMovieTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVFragmentedMovieTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly isAssociatedWithFragmentMinder: boolean;
}

declare class AVMediaDataStorage extends NSObject {
  initWithURLOptions(URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  URL(): NSURL;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableMovie extends AVMovie {
  static movieWithURLOptionsError<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): InstanceType<This>;

  initWithURLOptionsError(URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): this;

  static movieWithDataOptionsError<This extends abstract new (...args: any) => any>(this: This, data: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): InstanceType<This>;

  initWithDataOptionsError(data: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): this;

  static movieWithSettingsFromMovieOptionsError<This extends abstract new (...args: any) => any>(this: This, movie: AVMovie | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): InstanceType<This>;

  initWithSettingsFromMovieOptionsError(movie: AVMovie | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): this;

  // @ts-ignore MemberDecl.tsIgnore
  preferredRate: number;

  // @ts-ignore MemberDecl.tsIgnore
  preferredVolume: number;

  // @ts-ignore MemberDecl.tsIgnore
  preferredTransform: CGAffineTransform;

  timescale: number;

  readonly tracks: NSArray;

  isModified: boolean;

  // @ts-ignore MemberDecl.tsIgnore
  defaultMediaDataStorage: AVMediaDataStorage;

  interleavingPeriod: CMTime;

  insertTimeRangeOfAssetAtTimeCopySampleDataError(timeRange: CMTimeRange, asset: AVAsset, startTime: CMTime, copySampleData: boolean, outError: interop.PointerConvertible): boolean;

  insertEmptyTimeRange(timeRange: CMTimeRange): void;

  removeTimeRange(timeRange: CMTimeRange): void;

  scaleTimeRangeToDuration(timeRange: CMTimeRange, duration: CMTime): void;

  mutableTrackCompatibleWithTrack(track: AVAssetTrack): AVMutableMovieTrack;

  addMutableTrackWithMediaTypeCopySettingsFromTrackOptions(mediaType: string, track: AVAssetTrack | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): AVMutableMovieTrack;

  addMutableTracksCopyingSettingsFromTracksOptions(existingTracks: NSArray<interop.Object> | Array<interop.Object>, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): NSArray;

  removeTrack(track: AVMovieTrack): void;

  // @ts-ignore MemberDecl.tsIgnore
  get metadata(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVMutableMovieTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVMutableMovieTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  metadataForFormat(format: string): NSArray;

  chapterMetadataGroupsWithTitleLocaleContainingItemsWithCommonKeys(locale: NSLocale, commonKeys: NSArray<interop.Object> | Array<interop.Object> | null): NSArray;

  chapterMetadataGroupsBestMatchingPreferredLanguages(preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  mediaSelectionGroupForMediaCharacteristic(mediaCharacteristic: string): AVMediaSelectionGroup;

  unusedTrackID(): number;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMovie extends AVAsset implements NSCopying, NSMutableCopying {
  static movieTypes(): NSArray;

  static movieWithURLOptions<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithURLOptions(URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  static movieWithDataOptions<This extends abstract new (...args: any) => any>(this: This, data: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithDataOptions(data: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly URL: NSURL;

  readonly data: NSData;

  readonly defaultMediaDataStorage: AVMediaDataStorage;

  readonly tracks: NSArray;

  readonly canContainMovieFragments: boolean;

  readonly containsMovieFragments: boolean;

  movieHeaderWithFileTypeError(fileType: string, outError: interop.PointerConvertible): NSData;

  writeMovieHeaderToURLFileTypeOptionsError(URL: NSURL, fileType: string, options: interop.Enum<typeof AVMovieWritingOptions>, outError: interop.PointerConvertible): boolean;

  isCompatibleWithFileType(fileType: string): boolean;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVMovieTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVMovieTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableMovieTrack extends AVMovieTrack {
  // @ts-ignore MemberDecl.tsIgnore
  mediaDataStorage: AVMediaDataStorage;

  sampleReferenceBaseURL: NSURL;

  // @ts-ignore MemberDecl.tsIgnore
  isEnabled: boolean;

  // @ts-ignore MemberDecl.tsIgnore
  alternateGroupID: number;

  isModified: boolean;

  readonly hasProtectedContent: boolean;

  timescale: number;

  // @ts-ignore MemberDecl.tsIgnore
  languageCode: string;

  // @ts-ignore MemberDecl.tsIgnore
  extendedLanguageTag: string;

  // @ts-ignore MemberDecl.tsIgnore
  naturalSize: CGSize;

  // @ts-ignore MemberDecl.tsIgnore
  preferredTransform: CGAffineTransform;

  layer: number;

  cleanApertureDimensions: CGSize;

  productionApertureDimensions: CGSize;

  encodedPixelsDimensions: CGSize;

  // @ts-ignore MemberDecl.tsIgnore
  preferredVolume: number;

  preferredMediaChunkSize: number;

  preferredMediaChunkDuration: CMTime;

  preferredMediaChunkAlignment: number;

  insertTimeRangeOfTrackAtTimeCopySampleDataError(timeRange: CMTimeRange, track: AVAssetTrack, startTime: CMTime, copySampleData: boolean, outError: interop.PointerConvertible): boolean;

  insertEmptyTimeRange(timeRange: CMTimeRange): void;

  removeTimeRange(timeRange: CMTimeRange): void;

  scaleTimeRangeToDuration(timeRange: CMTimeRange, duration: CMTime): void;

  // @ts-ignore MemberDecl.tsIgnore
  get metadata(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  addTrackAssociationToTrackType(movieTrack: AVMovieTrack, trackAssociationType: string): void;

  removeTrackAssociationToTrackType(movieTrack: AVMovieTrack, trackAssociationType: string): void;

  replaceFormatDescriptionWithFormatDescription(formatDescription: interop.PointerConvertible, newFormatDescription: interop.PointerConvertible): void;

  appendSampleBufferDecodeTimePresentationTimeError(sampleBuffer: interop.PointerConvertible, outDecodeTime: interop.PointerConvertible, outPresentationTime: interop.PointerConvertible, outError: interop.PointerConvertible): boolean;

  insertMediaTimeRangeIntoTimeRange(mediaTimeRange: CMTimeRange, trackTimeRange: CMTimeRange): boolean;

  hasMediaCharacteristic(mediaCharacteristic: string): boolean;

  segmentForTrackTime(trackTime: CMTime): AVAssetTrackSegment;

  samplePresentationTimeForTrackTime(trackTime: CMTime): CMTime;

  metadataForFormat(format: string): NSArray;

  associatedTracksOfType(trackAssociationType: string): NSArray;
}

declare class AVMovieTrack extends AVAssetTrack {
  readonly mediaPresentationTimeRange: CMTimeRange;

  readonly mediaDecodeTimeRange: CMTimeRange;

  readonly alternateGroupID: number;

  readonly mediaDataStorage: AVMediaDataStorage;
}

declare class AVMetadataItemFilter extends NSObject {
  static metadataItemFilterForSharing(): AVMetadataItemFilter;
}

declare class AVSampleBufferGeneratorBatch extends NSObject {
  makeDataReadyWithCompletionHandler(completionHandler: (p1: NSError) => void | null): void;

  cancel(): void;
}

declare class AVMetadataItemValueRequest extends NSObject {
  readonly metadataItem: AVMetadataItem | null;

  respondWithValue(value: NSCopying): void;

  respondWithError(error: NSError): void;
}

declare class AVMetadataItem extends NSObject implements AVAsynchronousKeyValueLoading, NSCopying, NSMutableCopying {
  readonly identifier: string;

  readonly extendedLanguageTag: string;

  readonly locale: NSLocale;

  readonly time: CMTime;

  readonly duration: CMTime;

  readonly dataType: string;

  readonly value: NSCopying;

  readonly extraAttributes: NSDictionary;

  readonly startDate: NSDate;

  readonly stringValue: string;

  readonly numberValue: NSNumber;

  readonly dateValue: NSDate;

  readonly dataValue: NSData;

  statusOfValueForKeyError(key: string, outError: interop.PointerConvertible): interop.Enum<typeof AVKeyValueStatus>;

  loadValuesAsynchronouslyForKeysCompletionHandler(keys: NSArray<interop.Object> | Array<interop.Object>, handler: () => void | null): void;

  static metadataItemsFromArrayFilteredAndSortedAccordingToPreferredLanguages(metadataItems: NSArray<interop.Object> | Array<interop.Object>, preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  static metadataItemsFromArrayFilteredByIdentifier(metadataItems: NSArray<interop.Object> | Array<interop.Object>, identifier: string): NSArray;

  static metadataItemsFromArrayFilteredByMetadataItemFilter(metadataItems: NSArray<interop.Object> | Array<interop.Object>, metadataItemFilter: AVMetadataItemFilter): NSArray;

  static identifierForKeyKeySpace(key: interop.Object, keySpace: string): string;

  static keySpaceForIdentifier(identifier: string): string;

  static keyForIdentifier(identifier: string): interop.Object;

  readonly key: NSCopying;

  readonly commonKey: string;

  readonly keySpace: string;

  static metadataItemWithPropertiesOfMetadataItemValueLoadingHandler(metadataItem: AVMetadataItem, handler: (p1: AVMetadataItemValueRequest) => void): AVMetadataItem;

  static metadataItemsFromArrayWithLocale(metadataItems: NSArray<interop.Object> | Array<interop.Object>, locale: NSLocale): NSArray;

  static metadataItemsFromArrayWithKeyKeySpace(metadataItems: NSArray<interop.Object> | Array<interop.Object>, key: interop.Object | null, keySpace: string | null): NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCompositionTrackSegment extends AVAssetTrackSegment {
  static compositionTrackSegmentWithURLTrackIDSourceTimeRangeTargetTimeRange<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, trackID: number, sourceTimeRange: CMTimeRange, targetTimeRange: CMTimeRange): InstanceType<This>;

  static compositionTrackSegmentWithTimeRange<This extends abstract new (...args: any) => any>(this: This, timeRange: CMTimeRange): InstanceType<This>;

  initWithURLTrackIDSourceTimeRangeTargetTimeRange(URL: NSURL, trackID: number, sourceTimeRange: CMTimeRange, targetTimeRange: CMTimeRange): this;

  initWithTimeRange(timeRange: CMTimeRange): this;

  readonly isEmpty: boolean;

  readonly sourceURL: NSURL;

  readonly sourceTrackID: number;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVComposition extends AVAsset implements NSMutableCopying {
  readonly tracks: NSArray;

  readonly naturalSize: CGSize;

  readonly URLAssetInitializationOptions: NSDictionary;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVCompositionTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVCompositionTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  metadataForFormat(format: string): NSArray;

  chapterMetadataGroupsWithTitleLocaleContainingItemsWithCommonKeys(locale: NSLocale, commonKeys: NSArray<interop.Object> | Array<interop.Object> | null): NSArray;

  chapterMetadataGroupsBestMatchingPreferredLanguages(preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  mediaSelectionGroupForMediaCharacteristic(mediaCharacteristic: string): AVMediaSelectionGroup;

  unusedTrackID(): number;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableCompositionTrack extends AVCompositionTrack {
  // @ts-ignore MemberDecl.tsIgnore
  isEnabled: boolean;

  // @ts-ignore MemberDecl.tsIgnore
  naturalTimeScale: number;

  // @ts-ignore MemberDecl.tsIgnore
  languageCode: string;

  // @ts-ignore MemberDecl.tsIgnore
  extendedLanguageTag: string;

  // @ts-ignore MemberDecl.tsIgnore
  preferredTransform: CGAffineTransform;

  // @ts-ignore MemberDecl.tsIgnore
  preferredVolume: number;

  // @ts-ignore MemberDecl.tsIgnore
  get segments(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set segments(value: NSArray<interop.Object> | Array<interop.Object>);

  insertTimeRangeOfTrackAtTimeError(timeRange: CMTimeRange, track: AVAssetTrack, startTime: CMTime, outError: interop.PointerConvertible): boolean;

  insertTimeRangesOfTracksAtTimeError(timeRanges: NSArray<interop.Object> | Array<interop.Object>, tracks: NSArray<interop.Object> | Array<interop.Object>, startTime: CMTime, outError: interop.PointerConvertible): boolean;

  insertEmptyTimeRange(timeRange: CMTimeRange): void;

  removeTimeRange(timeRange: CMTimeRange): void;

  scaleTimeRangeToDuration(timeRange: CMTimeRange, duration: CMTime): void;

  validateTrackSegmentsError(trackSegments: NSArray<interop.Object> | Array<interop.Object>, outError: interop.PointerConvertible): boolean;

  addTrackAssociationToTrackType(compositionTrack: AVCompositionTrack, trackAssociationType: string): void;

  removeTrackAssociationToTrackType(compositionTrack: AVCompositionTrack, trackAssociationType: string): void;

  replaceFormatDescriptionWithFormatDescription(originalFormatDescription: interop.PointerConvertible, replacementFormatDescription: interop.PointerConvertible): void;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVCompositionTrack extends AVAssetTrack {
  readonly segments: NSArray;

  // @ts-ignore MemberDecl.tsIgnore
  segmentForTrackTime(trackTime: CMTime): AVCompositionTrackSegment;

  readonly formatDescriptionReplacements: NSArray;

  hasMediaCharacteristic(mediaCharacteristic: string): boolean;

  samplePresentationTimeForTrackTime(trackTime: CMTime): CMTime;

  metadataForFormat(format: string): NSArray;

  associatedTracksOfType(trackAssociationType: string): NSArray;
}

declare class AVCaptionRendererScene extends NSObject implements NSCopying {
  readonly timeRange: CMTimeRange;

  readonly hasActiveCaptions: boolean;

  readonly needsPeriodicRefresh: boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVTextStyleRule extends NSObject implements NSCopying {
  static propertyListForTextStyleRules(textStyleRules: NSArray<interop.Object> | Array<interop.Object>): interop.Object;

  static textStyleRulesFromPropertyList(plist: interop.Object): NSArray;

  static textStyleRuleWithTextMarkupAttributes(textMarkupAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): AVTextStyleRule;

  static textStyleRuleWithTextMarkupAttributesTextSelector(textMarkupAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, textSelector: string | null): AVTextStyleRule;

  initWithTextMarkupAttributes(textMarkupAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  initWithTextMarkupAttributesTextSelector(textMarkupAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, textSelector: string | null): this;

  readonly textMarkupAttributes: NSDictionary;

  readonly textSelector: string;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptionFormatConformer extends NSObject {
  static captionFormatConformerWithConversionSettings<This extends abstract new (...args: any) => any>(this: This, conversionSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): InstanceType<This>;

  initWithConversionSettings(conversionSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  conformsCaptionsToTimeRange: boolean;

  conformedCaptionForCaptionError(caption: AVCaption, outError: interop.PointerConvertible): AVCaption;
}

declare class AVCaptionConversionAdjustment extends NSObject {
  readonly adjustmentType: string;
}

declare class AVCaptionGrouper extends NSObject {
  addCaption(input: AVCaption): void;

  flushAddedCaptionsIntoGroupsUpToTime(upToTime: CMTime): NSArray;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableCaption extends AVCaption {
  // @ts-ignore MemberDecl.tsIgnore
  text: string;

  // @ts-ignore MemberDecl.tsIgnore
  timeRange: CMTimeRange;

  setTextColorInRange(color: interop.PointerConvertible, range: _NSRange): void;

  setBackgroundColorInRange(color: interop.PointerConvertible, range: _NSRange): void;

  setFontWeightInRange(fontWeight: interop.Enum<typeof AVCaptionFontWeight>, range: _NSRange): void;

  setFontStyleInRange(fontStyle: interop.Enum<typeof AVCaptionFontStyle>, range: _NSRange): void;

  setDecorationInRange(decoration: interop.Enum<typeof AVCaptionDecoration>, range: _NSRange): void;

  setTextCombineInRange(textCombine: interop.Enum<typeof AVCaptionTextCombine>, range: _NSRange): void;

  setRubyInRange(ruby: AVCaptionRuby, range: _NSRange): void;

  removeTextColorInRange(range: _NSRange): void;

  removeBackgroundColorInRange(range: _NSRange): void;

  removeFontWeightInRange(range: _NSRange): void;

  removeFontStyleInRange(range: _NSRange): void;

  removeDecorationInRange(range: _NSRange): void;

  removeTextCombineInRange(range: _NSRange): void;

  removeRubyInRange(range: _NSRange): void;

  // @ts-ignore MemberDecl.tsIgnore
  region: AVCaptionRegion;

  // @ts-ignore MemberDecl.tsIgnore
  textAlignment: interop.Enum<typeof AVCaptionTextAlignment>;

  // @ts-ignore MemberDecl.tsIgnore
  animation: interop.Enum<typeof AVCaptionAnimation>;
}

declare class AVCaption extends NSObject implements NSCopying, NSMutableCopying, NSSecureCoding {
  initWithTextTimeRange(text: string, timeRange: CMTimeRange): this;

  readonly text: string;

  readonly timeRange: CMTimeRange;

  textColorAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Pointer;

  backgroundColorAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Pointer;

  fontWeightAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Enum<typeof AVCaptionFontWeight>;

  fontStyleAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Enum<typeof AVCaptionFontStyle>;

  decorationAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Enum<typeof AVCaptionDecoration>;

  textCombineAtIndexRange(index: number, outRange: interop.PointerConvertible): interop.Enum<typeof AVCaptionTextCombine>;

  rubyAtIndexRange(index: number, outRange: interop.PointerConvertible): AVCaptionRuby;

  readonly region: AVCaptionRegion;

  readonly textAlignment: interop.Enum<typeof AVCaptionTextAlignment>;

  readonly animation: interop.Enum<typeof AVCaptionAnimation>;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVCaptionRegion extends NSObject implements NSCopying, NSMutableCopying, NSSecureCoding {
  static readonly appleITTTopRegion: AVCaptionRegion;

  static readonly appleITTBottomRegion: AVCaptionRegion;

  static readonly appleITTLeftRegion: AVCaptionRegion;

  static readonly appleITTRightRegion: AVCaptionRegion;

  static readonly subRipTextBottomRegion: AVCaptionRegion;

  readonly identifier: string;

  readonly origin: AVCaptionPoint;

  readonly size: AVCaptionSize;

  readonly scroll: interop.Enum<typeof AVCaptionRegionScroll>;

  readonly displayAlignment: interop.Enum<typeof AVCaptionRegionDisplayAlignment>;

  readonly writingMode: interop.Enum<typeof AVCaptionRegionWritingMode>;

  encodeWithCoder(encoder: NSCoder): void;

  isEqual(object: interop.Object): boolean;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  static readonly supportsSecureCoding: boolean;

  initWithCoder(coder: NSCoder): this;
}

declare class AVCaptionConversionWarning extends NSObject {
  readonly warningType: string;

  readonly rangeOfCaptions: _NSRange;

  readonly adjustment: AVCaptionConversionAdjustment;
}

declare class AVAssetDownloadStorageManager extends NSObject {
  static sharedDownloadStorageManager(): AVAssetDownloadStorageManager;

  setStorageManagementPolicyForURL(storageManagementPolicy: AVAssetDownloadStorageManagementPolicy, downloadStorageURL: NSURL): void;

  storageManagementPolicyForURL(downloadStorageURL: NSURL): AVAssetDownloadStorageManagementPolicy;
}

declare class AVAssetDownloadURLSession extends NSURLSession {
  static sessionWithConfigurationAssetDownloadDelegateDelegateQueue(configuration: NSURLSessionConfiguration, delegate: AVAssetDownloadDelegate | null, delegateQueue: NSOperationQueue | null): AVAssetDownloadURLSession;

  assetDownloadTaskWithURLAssetDestinationURLOptions(URLAsset: AVURLAsset, destinationURL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): AVAssetDownloadTask;

  assetDownloadTaskWithURLAssetAssetTitleAssetArtworkDataOptions(URLAsset: AVURLAsset, title: string, artworkData: NSData | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): AVAssetDownloadTask;

  aggregateAssetDownloadTaskWithURLAssetMediaSelectionsAssetTitleAssetArtworkDataOptions(URLAsset: AVURLAsset, mediaSelections: NSArray<interop.Object> | Array<interop.Object>, title: string, artworkData: NSData | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): AVAggregateAssetDownloadTask;

  assetDownloadTaskWithConfiguration(downloadConfiguration: AVAssetDownloadConfiguration): AVAssetDownloadTask;
}

declare class AVAggregateAssetDownloadTask extends NSURLSessionTask {
  readonly URLAsset: AVURLAsset;
}

declare class AVAssetDownloadContentConfiguration extends NSObject implements NSCopying {
  get variantQualifiers(): NSArray;
  set variantQualifiers(value: NSArray<interop.Object> | Array<interop.Object>);

  get mediaSelections(): NSArray;
  set mediaSelections(value: NSArray<interop.Object> | Array<interop.Object>);

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetDownloadTask extends NSURLSessionTask {
  readonly URLAsset: AVURLAsset;

  readonly destinationURL: NSURL;

  readonly options: NSDictionary;

  readonly loadedTimeRanges: NSArray;
}

declare class AVMediaSelection extends NSObject implements NSCopying, NSMutableCopying {
  readonly asset: AVAsset | null;

  selectedMediaOptionInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): AVMediaSelectionOption;

  mediaSelectionCriteriaCanBeAppliedAutomaticallyToMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableAudioMixInputParameters extends AVAudioMixInputParameters {
  static audioMixInputParametersWithTrack<This extends abstract new (...args: any) => any>(this: This, track: AVAssetTrack | null): InstanceType<This>;

  static audioMixInputParameters<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  // @ts-ignore MemberDecl.tsIgnore
  trackID: number;

  // @ts-ignore MemberDecl.tsIgnore
  audioTimePitchAlgorithm: string;

  // @ts-ignore MemberDecl.tsIgnore
  get audioTapProcessor(): interop.Pointer;
  // @ts-ignore MemberDecl.tsIgnore
  set audioTapProcessor(value: interop.PointerConvertible);

  setVolumeRampFromStartVolumeToEndVolumeTimeRange(startVolume: number, endVolume: number, timeRange: CMTimeRange): void;

  setVolumeAtTime(volume: number, time: CMTime): void;
}

declare class AVAudioMixInputParameters extends NSObject implements NSCopying, NSMutableCopying {
  readonly trackID: number;

  readonly audioTimePitchAlgorithm: string;

  readonly audioTapProcessor: interop.Pointer;

  getVolumeRampForTimeStartVolumeEndVolumeTimeRange(time: CMTime, startVolume: interop.PointerConvertible, endVolume: interop.PointerConvertible, timeRange: interop.PointerConvertible): boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableAudioMix extends AVAudioMix {
  static audioMix<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  // @ts-ignore MemberDecl.tsIgnore
  get inputParameters(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set inputParameters(value: NSArray<interop.Object> | Array<interop.Object>);
}

declare class AVAudioMix extends NSObject implements NSCopying, NSMutableCopying {
  readonly inputParameters: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetPlaybackAssistant extends NSObject {
  static assetPlaybackAssistantWithAsset<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset): InstanceType<This>;

  loadPlaybackConfigurationOptionsWithCompletionHandler(completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>) => void): void;
}

declare class AVAssetWriterInputCaptionAdaptor extends NSObject {
  static assetWriterInputCaptionAdaptorWithAssetWriterInput<This extends abstract new (...args: any) => any>(this: This, input: AVAssetWriterInput): InstanceType<This>;

  initWithAssetWriterInput(input: AVAssetWriterInput): this;

  readonly assetWriterInput: AVAssetWriterInput;

  appendCaption(caption: AVCaption): boolean;

  appendCaptionGroup(captionGroup: AVCaptionGroup): boolean;
}

declare class AVAssetWriterInputTaggedPixelBufferGroupAdaptor extends NSObject {
  static assetWriterInputTaggedPixelBufferGroupAdaptorWithAssetWriterInputSourcePixelBufferAttributes<This extends abstract new (...args: any) => any>(this: This, input: AVAssetWriterInput, sourcePixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithAssetWriterInputSourcePixelBufferAttributes(input: AVAssetWriterInput, sourcePixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly assetWriterInput: AVAssetWriterInput;

  readonly sourcePixelBufferAttributes: NSDictionary;

  readonly pixelBufferPool: interop.Pointer;

  appendTaggedPixelBufferGroupWithPresentationTime(taggedPixelBufferGroup: interop.PointerConvertible, presentationTime: CMTime): boolean;
}

declare class AVAssetWriterInputPixelBufferAdaptor extends NSObject {
  static assetWriterInputPixelBufferAdaptorWithAssetWriterInputSourcePixelBufferAttributes<This extends abstract new (...args: any) => any>(this: This, input: AVAssetWriterInput, sourcePixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithAssetWriterInputSourcePixelBufferAttributes(input: AVAssetWriterInput, sourcePixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly assetWriterInput: AVAssetWriterInput;

  readonly sourcePixelBufferAttributes: NSDictionary;

  readonly pixelBufferPool: interop.Pointer;

  appendPixelBufferWithPresentationTime(pixelBuffer: interop.PointerConvertible, presentationTime: CMTime): boolean;
}

declare class AVAssetWriterInputGroup extends AVMediaSelectionGroup {
  static assetWriterInputGroupWithInputsDefaultInput<This extends abstract new (...args: any) => any>(this: This, inputs: NSArray<interop.Object> | Array<interop.Object>, defaultInput: AVAssetWriterInput | null): InstanceType<This>;

  initWithInputsDefaultInput(inputs: NSArray<interop.Object> | Array<interop.Object>, defaultInput: AVAssetWriterInput | null): this;

  readonly inputs: NSArray;

  readonly defaultInput: AVAssetWriterInput;
}

declare class AVAssetSegmentTrackReport extends NSObject {
  readonly trackID: number;

  readonly mediaType: string;

  readonly earliestPresentationTimeStamp: CMTime;

  readonly duration: CMTime;

  readonly firstVideoSampleInformation: AVAssetSegmentReportSampleInformation;
}

declare class AVAssetSegmentReport extends NSObject {
  readonly segmentType: interop.Enum<typeof AVAssetSegmentType>;

  readonly trackReports: NSArray;
}

declare class AVPlayerPlaybackCoordinator extends AVPlaybackCoordinator {
  readonly player: AVPlayer | null;

  delegate: AVPlayerPlaybackCoordinatorDelegate | null;
}

declare class AVMediaSelectionGroup extends NSObject implements NSCopying {
  readonly options: NSArray;

  readonly defaultOption: AVMediaSelectionOption;

  readonly allowsEmptySelection: boolean;

  mediaSelectionOptionWithPropertyList(plist: interop.Object): AVMediaSelectionOption;

  static playableMediaSelectionOptionsFromArray(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  static mediaSelectionOptionsFromArrayFilteredAndSortedAccordingToPreferredLanguages(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>, preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  static mediaSelectionOptionsFromArrayWithLocale(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>, locale: NSLocale): NSArray;

  static mediaSelectionOptionsFromArrayWithMediaCharacteristics(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>, mediaCharacteristics: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  static mediaSelectionOptionsFromArrayWithoutMediaCharacteristics(mediaSelectionOptions: NSArray<interop.Object> | Array<interop.Object>, mediaCharacteristics: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetTrackGroup extends NSObject implements NSCopying {
  readonly trackIDs: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetTrack extends NSObject implements NSCopying, AVAsynchronousKeyValueLoading {
  readonly asset: AVAsset | null;

  readonly trackID: number;

  readonly mediaType: string;

  readonly formatDescriptions: NSArray;

  readonly isPlayable: boolean;

  readonly isDecodable: boolean;

  readonly isEnabled: boolean;

  readonly isSelfContained: boolean;

  readonly totalSampleDataLength: number;

  hasMediaCharacteristic(mediaCharacteristic: string): boolean;

  readonly timeRange: CMTimeRange;

  readonly naturalTimeScale: number;

  readonly estimatedDataRate: number;

  readonly languageCode: string;

  readonly extendedLanguageTag: string;

  readonly naturalSize: CGSize;

  readonly preferredTransform: CGAffineTransform;

  readonly preferredVolume: number;

  readonly hasAudioSampleDependencies: boolean;

  readonly nominalFrameRate: number;

  readonly minFrameDuration: CMTime;

  readonly requiresFrameReordering: boolean;

  readonly segments: NSArray;

  segmentForTrackTime(trackTime: CMTime): AVAssetTrackSegment;

  loadSegmentForTrackTimeCompletionHandler(trackTime: CMTime, completionHandler: (p1: AVAssetTrackSegment, p2: NSError) => void | null): void;

  samplePresentationTimeForTrackTime(trackTime: CMTime): CMTime;

  loadSamplePresentationTimeForTrackTimeCompletionHandler(trackTime: CMTime, completionHandler: (p1: CMTime, p2: NSError) => void | null): void;

  readonly commonMetadata: NSArray;

  readonly metadata: NSArray;

  readonly availableMetadataFormats: NSArray;

  metadataForFormat(format: string): NSArray;

  loadMetadataForFormatCompletionHandler(format: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly availableTrackAssociationTypes: NSArray;

  associatedTracksOfType(trackAssociationType: string): NSArray;

  loadAssociatedTracksOfTypeCompletionHandler(trackAssociationType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly canProvideSampleCursors: boolean;

  makeSampleCursorWithPresentationTimeStamp(presentationTimeStamp: CMTime): AVSampleCursor;

  makeSampleCursorAtFirstSampleInDecodeOrder(): AVSampleCursor;

  makeSampleCursorAtLastSampleInDecodeOrder(): AVSampleCursor;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  statusOfValueForKeyError(key: string, outError: interop.PointerConvertible): interop.Enum<typeof AVKeyValueStatus>;

  loadValuesAsynchronouslyForKeysCompletionHandler(keys: NSArray<interop.Object> | Array<interop.Object>, handler: () => void | null): void;
}

declare class AVAssetTrackSegment extends NSObject {
  readonly timeMapping: CMTimeMapping;

  readonly isEmpty: boolean;
}

declare class AVAssetResourceLoadingDataRequest extends NSObject {
  readonly requestedOffset: number;

  readonly requestedLength: number;

  readonly requestsAllDataToEndOfResource: boolean;

  readonly currentOffset: number;

  respondWithData(data: NSData): void;
}

declare class AVAssetResourceLoadingContentInformationRequest extends NSObject {
  contentType: string;

  readonly allowedContentTypes: NSArray;

  contentLength: number;

  isByteRangeAccessSupported: boolean;

  renewalDate: NSDate;

  isEntireLengthAvailableOnDemand: boolean;
}

declare class AVAssetResourceLoadingRequestor extends NSObject {
  readonly providesExpiredSessionReports: boolean;
}

declare class AVAssetResourceLoader extends NSObject {
  readonly delegate: AVAssetResourceLoaderDelegate;

  readonly delegateQueue: NSObject;

  preloadsEligibleContentKeys: boolean;

  sendsCommonMediaClientDataAsHTTPHeaders: boolean;
}

declare class AVAssetReaderOutputMetadataAdaptor extends NSObject {
  static assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput<This extends abstract new (...args: any) => any>(this: This, trackOutput: AVAssetReaderTrackOutput): InstanceType<This>;

  initWithAssetReaderTrackOutput(trackOutput: AVAssetReaderTrackOutput): this;

  readonly assetReaderTrackOutput: AVAssetReaderTrackOutput;

  nextTimedMetadataGroup(): AVTimedMetadataGroup;
}

declare class AVAssetReaderVideoCompositionOutput extends AVAssetReaderOutput {
  static assetReaderVideoCompositionOutputWithVideoTracksVideoSettings<This extends abstract new (...args: any) => any>(this: This, videoTracks: NSArray<interop.Object> | Array<interop.Object>, videoSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithVideoTracksVideoSettings(videoTracks: NSArray<interop.Object> | Array<interop.Object>, videoSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly videoTracks: NSArray;

  readonly videoSettings: NSDictionary;

  videoComposition: AVVideoComposition;

  readonly customVideoCompositor: AVVideoCompositing;
}

declare class AVAssetReaderAudioMixOutput extends AVAssetReaderOutput {
  static assetReaderAudioMixOutputWithAudioTracksAudioSettings<This extends abstract new (...args: any) => any>(this: This, audioTracks: NSArray<interop.Object> | Array<interop.Object>, audioSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithAudioTracksAudioSettings(audioTracks: NSArray<interop.Object> | Array<interop.Object>, audioSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly audioTracks: NSArray;

  readonly audioSettings: NSDictionary;

  audioMix: AVAudioMix;

  audioTimePitchAlgorithm: string;
}

declare class AVAssetReaderTrackOutput extends AVAssetReaderOutput {
  static assetReaderTrackOutputWithTrackOutputSettings<This extends abstract new (...args: any) => any>(this: This, track: AVAssetTrack, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithTrackOutputSettings(track: AVAssetTrack, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly track: AVAssetTrack;

  readonly outputSettings: NSDictionary;

  audioTimePitchAlgorithm: string;
}

declare class AVVideoCompositionCoreAnimationTool extends NSObject {
  static videoCompositionCoreAnimationToolWithAdditionalLayerAsTrackID<This extends abstract new (...args: any) => any>(this: This, layer: CALayer, trackID: number): InstanceType<This>;

  static videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayerInLayer<This extends abstract new (...args: any) => any>(this: This, videoLayer: CALayer, animationLayer: CALayer): InstanceType<This>;

  static videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayersInLayer<This extends abstract new (...args: any) => any>(this: This, videoLayers: NSArray<interop.Object> | Array<interop.Object>, animationLayer: CALayer): InstanceType<This>;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableVideoCompositionLayerInstruction extends AVVideoCompositionLayerInstruction {
  static videoCompositionLayerInstructionWithAssetTrack<This extends abstract new (...args: any) => any>(this: This, track: AVAssetTrack): InstanceType<This>;

  static videoCompositionLayerInstruction<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  // @ts-ignore MemberDecl.tsIgnore
  trackID: number;

  setTransformRampFromStartTransformToEndTransformTimeRange(startTransform: CGAffineTransform, endTransform: CGAffineTransform, timeRange: CMTimeRange): void;

  setTransformAtTime(transform: CGAffineTransform, time: CMTime): void;

  setOpacityRampFromStartOpacityToEndOpacityTimeRange(startOpacity: number, endOpacity: number, timeRange: CMTimeRange): void;

  setOpacityAtTime(opacity: number, time: CMTime): void;

  setCropRectangleRampFromStartCropRectangleToEndCropRectangleTimeRange(startCropRectangle: CGRect, endCropRectangle: CGRect, timeRange: CMTimeRange): void;

  setCropRectangleAtTime(cropRectangle: CGRect, time: CMTime): void;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableVideoCompositionInstruction extends AVVideoCompositionInstruction {
  static videoCompositionInstruction<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  // @ts-ignore MemberDecl.tsIgnore
  timeRange: CMTimeRange;

  // @ts-ignore MemberDecl.tsIgnore
  get backgroundColor(): interop.Pointer;
  // @ts-ignore MemberDecl.tsIgnore
  set backgroundColor(value: interop.PointerConvertible);

  // @ts-ignore MemberDecl.tsIgnore
  get layerInstructions(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set layerInstructions(value: NSArray<interop.Object> | Array<interop.Object>);

  // @ts-ignore MemberDecl.tsIgnore
  enablePostProcessing: boolean;

  // @ts-ignore MemberDecl.tsIgnore
  get requiredSourceSampleDataTrackIDs(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set requiredSourceSampleDataTrackIDs(value: NSArray<interop.Object> | Array<interop.Object>);
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableVideoComposition extends AVVideoComposition {
  static videoComposition(): AVMutableVideoComposition;

  // @ts-ignore MemberDecl.tsIgnore
  static videoCompositionWithPropertiesOfAsset(asset: AVAsset): AVMutableVideoComposition;

  // @ts-ignore MemberDecl.tsIgnore
  static videoCompositionWithPropertiesOfAssetCompletionHandler(asset: AVAsset, completionHandler: (p1: AVMutableVideoComposition, p2: NSError) => void | null): void;

  static videoCompositionWithPropertiesOfAssetPrototypeInstruction(asset: AVAsset, prototypeInstruction: AVVideoCompositionInstruction): AVMutableVideoComposition;

  static videoCompositionWithPropertiesOfAssetPrototypeInstructionCompletionHandler(asset: AVAsset, prototypeInstruction: AVVideoCompositionInstruction, completionHandler: (p1: AVMutableVideoComposition, p2: NSError) => void | null): void;

  // @ts-ignore MemberDecl.tsIgnore
  customVideoCompositorClass: AVVideoCompositing;

  // @ts-ignore MemberDecl.tsIgnore
  frameDuration: CMTime;

  // @ts-ignore MemberDecl.tsIgnore
  sourceTrackIDForFrameTiming: number;

  // @ts-ignore MemberDecl.tsIgnore
  renderSize: CGSize;

  // @ts-ignore MemberDecl.tsIgnore
  renderScale: number;

  // @ts-ignore MemberDecl.tsIgnore
  get instructions(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set instructions(value: NSArray<interop.Object> | Array<interop.Object>);

  // @ts-ignore MemberDecl.tsIgnore
  animationTool: AVVideoCompositionCoreAnimationTool;

  // @ts-ignore MemberDecl.tsIgnore
  get sourceSampleDataTrackIDs(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set sourceSampleDataTrackIDs(value: NSArray<interop.Object> | Array<interop.Object>);

  // @ts-ignore MemberDecl.tsIgnore
  colorPrimaries: string;

  // @ts-ignore MemberDecl.tsIgnore
  colorYCbCrMatrix: string;

  // @ts-ignore MemberDecl.tsIgnore
  colorTransferFunction: string;

  // @ts-ignore MemberDecl.tsIgnore
  perFrameHDRDisplayMetadataPolicy: string;

  // @ts-ignore MemberDecl.tsIgnore
  static videoCompositionWithAssetApplyingCIFiltersWithHandler(asset: AVAsset, applier: (p1: AVAsynchronousCIImageFilteringRequest) => void): AVMutableVideoComposition;

  // @ts-ignore MemberDecl.tsIgnore
  static videoCompositionWithAssetApplyingCIFiltersWithHandlerCompletionHandler(asset: AVAsset, applier: (p1: AVAsynchronousCIImageFilteringRequest) => void, completionHandler: (p1: AVMutableVideoComposition, p2: NSError) => void | null): void;
}

declare class AVVideoComposition extends NSObject implements NSCopying, NSMutableCopying {
  static videoCompositionWithPropertiesOfAsset(asset: AVAsset): AVVideoComposition;

  static videoCompositionWithPropertiesOfAssetCompletionHandler(asset: AVAsset, completionHandler: (p1: AVVideoComposition, p2: NSError) => void | null): void;

  readonly customVideoCompositorClass: AVVideoCompositing;

  readonly frameDuration: CMTime;

  readonly sourceTrackIDForFrameTiming: number;

  readonly renderSize: CGSize;

  readonly renderScale: number;

  readonly instructions: NSArray;

  readonly animationTool: AVVideoCompositionCoreAnimationTool;

  readonly sourceSampleDataTrackIDs: NSArray;

  readonly colorPrimaries: string;

  readonly colorYCbCrMatrix: string;

  readonly colorTransferFunction: string;

  readonly perFrameHDRDisplayMetadataPolicy: string;

  static videoCompositionWithAssetApplyingCIFiltersWithHandler(asset: AVAsset, applier: (p1: AVAsynchronousCIImageFilteringRequest) => void): AVVideoComposition;

  static videoCompositionWithAssetApplyingCIFiltersWithHandlerCompletionHandler(asset: AVAsset, applier: (p1: AVAsynchronousCIImageFilteringRequest) => void, completionHandler: (p1: AVVideoComposition, p2: NSError) => void | null): void;

  isValidForAssetTimeRangeValidationDelegate(asset: AVAsset | null, timeRange: CMTimeRange, validationDelegate: AVVideoCompositionValidationHandling | null): boolean;

  determineValidityForAssetTimeRangeValidationDelegateCompletionHandler(asset: AVAsset | null, timeRange: CMTimeRange, validationDelegate: AVVideoCompositionValidationHandling | null, completionHandler: (p1: boolean, p2: NSError) => void | null): void;

  isValidForTracksAssetDurationTimeRangeValidationDelegate(tracks: NSArray<interop.Object> | Array<interop.Object>, duration: CMTime, timeRange: CMTimeRange, validationDelegate: AVVideoCompositionValidationHandling | null): boolean;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAsynchronousCIImageFilteringRequest extends NSObject implements NSCopying {
  readonly renderSize: CGSize;

  readonly compositionTime: CMTime;

  readonly sourceImage: CIImage;

  finishWithImageContext(filteredImage: CIImage, context: CIContext | null): void;

  finishWithError(error: NSError): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVVideoCompositionRenderHint extends NSObject {
  readonly startCompositionTime: CMTime;

  readonly endCompositionTime: CMTime;
}

declare class AVMetadataGroup extends NSObject {
  readonly items: NSArray;

  readonly classifyingLabel: string;

  readonly uniqueID: string;
}

declare class AVCoordinatedPlaybackSuspension extends NSObject {
  readonly reason: string;

  readonly beginDate: NSDate;

  end(): void;

  endProposingNewTime(time: CMTime): void;
}

declare class AVAssetExportSession extends NSObject {
  static exportSessionWithAssetPresetName<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset, presetName: string): InstanceType<This>;

  initWithAssetPresetName(asset: AVAsset, presetName: string): this;

  readonly presetName: string;

  readonly asset: AVAsset;

  outputFileType: string;

  outputURL: NSURL;

  shouldOptimizeForNetworkUse: boolean;

  readonly status: interop.Enum<typeof AVAssetExportSessionStatus>;

  readonly error: NSError;

  exportAsynchronouslyWithCompletionHandler(handler: () => void): void;

  readonly progress: number;

  cancelExport(): void;

  static allExportPresets(): NSArray;

  static exportPresetsCompatibleWithAsset(asset: AVAsset): NSArray;

  static determineCompatibilityOfExportPresetWithAssetOutputFileTypeCompletionHandler(presetName: string, asset: AVAsset, outputFileType: string | null, handler: (p1: boolean) => void): void;

  readonly supportedFileTypes: NSArray;

  determineCompatibleFileTypesWithCompletionHandler(handler: (p1: NSArray<interop.Object> | Array<interop.Object>) => void): void;

  timeRange: CMTimeRange;

  readonly maxDuration: CMTime;

  readonly estimatedOutputFileLength: number;

  fileLengthLimit: number;

  estimateMaximumDurationWithCompletionHandler(handler: (p1: CMTime, p2: NSError) => void | null): void;

  estimateOutputFileLengthWithCompletionHandler(handler: (p1: number, p2: NSError) => void | null): void;

  get metadata(): NSArray;
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  metadataItemFilter: AVMetadataItemFilter;

  audioTimePitchAlgorithm: string;

  audioMix: AVAudioMix;

  videoComposition: AVVideoComposition;

  readonly customVideoCompositor: AVVideoCompositing;

  audioTrackGroupHandling: interop.Enum<typeof AVAssetTrackGroupOutputHandling>;

  canPerformMultiplePassesOverSourceMediaData: boolean;

  directoryForTemporaryFiles: NSURL;
}

declare class AVFragmentedAssetMinder extends NSObject {
  static fragmentedAssetMinderWithAssetMindingInterval<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset, mindingInterval: number): InstanceType<This>;

  initWithAssetMindingInterval(asset: AVAsset, mindingInterval: number): this;

  mindingInterval: number;

  readonly assets: NSArray;

  addFragmentedAsset(asset: AVAsset): void;

  removeFragmentedAsset(asset: AVAsset): void;
}

declare class AVURLAsset extends AVAsset {
  static audiovisualTypes(): NSArray;

  static audiovisualMIMETypes(): NSArray;

  static isPlayableExtendedMIMEType(extendedMIMEType: string): boolean;

  static URLAssetWithURLOptions<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  initWithURLOptions(URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  readonly URL: NSURL;

  readonly httpSessionIdentifier: NSUUID;

  readonly resourceLoader: AVAssetResourceLoader;

  readonly assetCache: AVAssetCache;

  compatibleTrackForCompositionTrack(compositionTrack: AVCompositionTrack): AVAssetTrack;

  findCompatibleTrackForCompositionTrackCompletionHandler(compositionTrack: AVCompositionTrack, completionHandler: (p1: AVAssetTrack, p2: NSError) => void | null): void;

  readonly variants: NSArray;

  readonly mayRequireContentKeysForMediaDataProcessing: boolean;
}

declare class AVAssetVariantQualifier extends NSObject implements NSCopying {
  static assetVariantQualifierWithPredicate<This extends abstract new (...args: any) => any>(this: This, predicate: NSPredicate): InstanceType<This>;

  static assetVariantQualifierWithVariant<This extends abstract new (...args: any) => any>(this: This, variant: AVAssetVariant): InstanceType<This>;

  static predicateForChannelCountMediaSelectionOptionOperatorType(channelCount: number, mediaSelectionOption: AVMediaSelectionOption, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  static predicateForBinauralAudioMediaSelectionOption(isBinauralAudio: boolean, mediaSelectionOption: AVMediaSelectionOption): NSPredicate;

  static predicateForImmersiveAudioMediaSelectionOption(isImmersiveAudio: boolean, mediaSelectionOption: AVMediaSelectionOption): NSPredicate;

  static predicateForDownmixAudioMediaSelectionOption(isDownmixAudio: boolean, mediaSelectionOption: AVMediaSelectionOption): NSPredicate;

  static predicateForPresentationWidthOperatorType(width: number, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  static predicateForPresentationHeightOperatorType(height: number, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  static predicateForAudioSampleRateMediaSelectionOptionOperatorType(sampleRate: number, mediaSelectionOption: AVMediaSelectionOption, operatorType: interop.Enum<typeof NSPredicateOperatorType>): NSPredicate;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetVariantAudioRenditionSpecificAttributes extends NSObject {
  readonly channelCount: number;

  readonly isBinaural: boolean;

  readonly isImmersive: boolean;

  readonly isDownmix: boolean;
}

declare class AVContentKeySpecifier extends NSObject {
  static contentKeySpecifierForKeySystemIdentifierOptions<This extends abstract new (...args: any) => any>(this: This, keySystem: string, contentKeyIdentifier: interop.Object, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): InstanceType<This>;

  initForKeySystemIdentifierOptions(keySystem: string, contentKeyIdentifier: interop.Object, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  readonly keySystem: string;

  readonly identifier: interop.Object;

  readonly options: NSDictionary;
}

declare class AVExternalStorageDeviceDiscoverySession extends NSObject {
  static readonly sharedSession: AVExternalStorageDeviceDiscoverySession;

  readonly externalStorageDevices: NSArray;

  static readonly isSupported: boolean;
}

declare class AVMediaSelectionOption extends NSObject implements NSCopying {
  readonly mediaType: string;

  readonly mediaSubTypes: NSArray;

  hasMediaCharacteristic(mediaCharacteristic: string): boolean;

  readonly isPlayable: boolean;

  readonly extendedLanguageTag: string;

  readonly locale: NSLocale;

  readonly commonMetadata: NSArray;

  readonly availableMetadataFormats: NSArray;

  metadataForFormat(format: string): NSArray;

  associatedMediaSelectionOptionInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): AVMediaSelectionOption;

  propertyList(): interop.Object;

  displayNameWithLocale(locale: NSLocale): string;

  readonly displayName: string;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVPlayerLayer extends CALayer {
  static playerLayerWithPlayer(player: AVPlayer | null): AVPlayerLayer;

  player: AVPlayer;

  videoGravity: string;

  readonly isReadyForDisplay: boolean;

  readonly videoRect: CGRect;

  get pixelBufferAttributes(): NSDictionary;
  set pixelBufferAttributes(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  copyDisplayedPixelBuffer(): interop.Pointer;
}

declare class AVContentKeyRequest extends NSObject {
  readonly status: interop.Enum<typeof AVContentKeyRequestStatus>;

  readonly error: NSError;

  readonly identifier: interop.Object;

  readonly initializationData: NSData;

  readonly options: NSDictionary;

  readonly canProvidePersistableContentKey: boolean;

  readonly contentKeySpecifier: AVContentKeySpecifier;

  readonly contentKey: AVContentKey;

  makeStreamingContentKeyRequestDataForAppContentIdentifierOptionsCompletionHandler(appIdentifier: NSData, contentIdentifier: NSData | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, handler: (p1: NSData, p2: NSError) => void | null): void;

  processContentKeyResponse(keyResponse: AVContentKeyResponse): void;

  processContentKeyResponseError(error: NSError): void;

  respondByRequestingPersistableContentKeyRequest(): void;

  respondByRequestingPersistableContentKeyRequestAndReturnError(outError: interop.PointerConvertible): boolean;

  readonly renewsExpiringResponseData: boolean;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableAssetDownloadStorageManagementPolicy extends AVAssetDownloadStorageManagementPolicy {
  // @ts-ignore MemberDecl.tsIgnore
  priority: string;

  // @ts-ignore MemberDecl.tsIgnore
  expirationDate: NSDate;
}

declare class AVAsset extends NSObject implements NSCopying, AVAsynchronousKeyValueLoading {
  static assetWithURL<This extends abstract new (...args: any) => any>(this: This, URL: NSURL): InstanceType<This>;

  readonly duration: CMTime;

  readonly preferredRate: number;

  readonly preferredVolume: number;

  readonly preferredTransform: CGAffineTransform;

  readonly naturalSize: CGSize;

  readonly minimumTimeOffsetFromLive: CMTime;

  readonly providesPreciseDurationAndTiming: boolean;

  cancelLoading(): void;

  readonly referenceRestrictions: interop.Enum<typeof AVAssetReferenceRestrictions>;

  readonly tracks: NSArray;

  trackWithTrackID(trackID: number): AVAssetTrack;

  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVAssetTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly trackGroups: NSArray;

  readonly creationDate: AVMetadataItem;

  readonly lyrics: string;

  readonly commonMetadata: NSArray;

  readonly metadata: NSArray;

  readonly availableMetadataFormats: NSArray;

  metadataForFormat(format: string): NSArray;

  loadMetadataForFormatCompletionHandler(format: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly availableChapterLocales: NSArray;

  chapterMetadataGroupsWithTitleLocaleContainingItemsWithCommonKeys(locale: NSLocale, commonKeys: NSArray<interop.Object> | Array<interop.Object> | null): NSArray;

  loadChapterMetadataGroupsWithTitleLocaleContainingItemsWithCommonKeysCompletionHandler(locale: NSLocale, commonKeys: NSArray<interop.Object> | Array<interop.Object>, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  chapterMetadataGroupsBestMatchingPreferredLanguages(preferredLanguages: NSArray<interop.Object> | Array<interop.Object>): NSArray;

  loadChapterMetadataGroupsBestMatchingPreferredLanguagesCompletionHandler(preferredLanguages: NSArray<interop.Object> | Array<interop.Object>, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly availableMediaCharacteristicsWithMediaSelectionOptions: NSArray;

  mediaSelectionGroupForMediaCharacteristic(mediaCharacteristic: string): AVMediaSelectionGroup;

  loadMediaSelectionGroupForMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: AVMediaSelectionGroup, p2: NSError) => void | null): void;

  readonly preferredMediaSelection: AVMediaSelection;

  readonly allMediaSelections: NSArray;

  readonly hasProtectedContent: boolean;

  readonly canContainFragments: boolean;

  readonly containsFragments: boolean;

  readonly overallDurationHint: CMTime;

  readonly isPlayable: boolean;

  readonly isExportable: boolean;

  readonly isReadable: boolean;

  readonly isComposable: boolean;

  readonly isCompatibleWithSavedPhotosAlbum: boolean;

  readonly isCompatibleWithAirPlayVideo: boolean;

  unusedTrackID(): number;

  findUnusedTrackIDWithCompletionHandler(completionHandler: (p1: number, p2: NSError) => void | null): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  statusOfValueForKeyError(key: string, outError: interop.PointerConvertible): interop.Enum<typeof AVKeyValueStatus>;

  loadValuesAsynchronouslyForKeysCompletionHandler(keys: NSArray<interop.Object> | Array<interop.Object>, handler: () => void | null): void;
}

declare class AVMetricErrorEvent extends AVMetricEvent {
  readonly didRecover: boolean;

  readonly error: NSError;
}

declare class AVVideoCompositionInstruction extends NSObject implements NSSecureCoding, NSCopying, NSMutableCopying, AVVideoCompositionInstructionProtocol {
  readonly timeRange: CMTimeRange;

  readonly backgroundColor: interop.Pointer;

  readonly layerInstructions: NSArray;

  readonly enablePostProcessing: boolean;

  readonly requiredSourceTrackIDs: NSArray;

  readonly passthroughTrackID: number;

  readonly requiredSourceSampleDataTrackIDs: NSArray;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;

  readonly containsTweening: boolean;

  isEqual(object: interop.Object): boolean;

  readonly hash: number;

  readonly superclass: interop.Object;

  class(): interop.Object;

  self(): this;

  performSelector(aSelector: string): interop.Object;

  performSelectorWithObject(aSelector: string, object: interop.Object): interop.Object;

  performSelectorWithObjectWithObject(aSelector: string, object1: interop.Object, object2: interop.Object): interop.Object;

  readonly isProxy: boolean;

  isKindOfClass(aClass: interop.Object): boolean;

  isMemberOfClass(aClass: interop.Object): boolean;

  conformsToProtocol(aProtocol: interop.PointerConvertible): boolean;

  respondsToSelector(aSelector: string): boolean;

  retain(): this;

  release(): void;

  autorelease(): this;

  retainCount(): number;

  readonly zone: interop.Pointer;

  readonly description: string;

  readonly debugDescription: string;
}

declare class AVContentKeySession extends NSObject {
  static contentKeySessionWithKeySystem<This extends abstract new (...args: any) => any>(this: This, keySystem: string): InstanceType<This>;

  static contentKeySessionWithKeySystemStorageDirectoryAtURL<This extends abstract new (...args: any) => any>(this: This, keySystem: string, storageURL: NSURL): InstanceType<This>;

  readonly delegate: AVContentKeySessionDelegate;

  readonly delegateQueue: NSObject;

  readonly storageURL: NSURL;

  readonly keySystem: string;

  expire(): void;

  readonly contentProtectionSessionIdentifier: NSData;

  processContentKeyRequestWithIdentifierInitializationDataOptions(identifier: interop.Object | null, initializationData: NSData | null, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): void;

  renewExpiringResponseDataForContentKeyRequest(contentKeyRequest: AVContentKeyRequest): void;

  makeSecureTokenForExpirationDateOfPersistableContentKeyCompletionHandler(persistableContentKeyData: NSData, handler: (p1: NSData, p2: NSError) => void | null): void;

  invalidatePersistableContentKeyOptionsCompletionHandler(persistableContentKeyData: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, handler: (p1: NSData, p2: NSError) => void | null): void;

  invalidateAllPersistableContentKeysForAppOptionsCompletionHandler(appIdentifier: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, handler: (p1: NSData, p2: NSError) => void | null): void;

  addContentKeyRecipient(recipient: AVContentKeyRecipient): void;

  removeContentKeyRecipient(recipient: AVContentKeyRecipient): void;

  readonly contentKeyRecipients: NSArray;

  static pendingExpiredSessionReportsWithAppIdentifierStorageDirectoryAtURL(appIdentifier: NSData, storageURL: NSURL): NSArray;

  static removePendingExpiredSessionReportsWithAppIdentifierStorageDirectoryAtURL(expiredSessionReports: NSArray<interop.Object> | Array<interop.Object>, appIdentifier: NSData, storageURL: NSURL): void;
}

declare class AVAssetReaderSampleReferenceOutput extends AVAssetReaderOutput {
  static assetReaderSampleReferenceOutputWithTrack<This extends abstract new (...args: any) => any>(this: This, track: AVAssetTrack): InstanceType<This>;

  initWithTrack(track: AVAssetTrack): this;

  readonly track: AVAssetTrack;
}

declare class AVAssetCache extends NSObject {
  readonly isPlayableOffline: boolean;

  mediaSelectionOptionsInMediaSelectionGroup(mediaSelectionGroup: AVMediaSelectionGroup): NSArray;
}

declare class AVAssetWriterInputPassDescription extends NSObject {
  readonly sourceTimeRanges: NSArray;
}

declare class AVAssetResourceRenewalRequest extends AVAssetResourceLoadingRequest {
}

declare class AVDateRangeMetadataGroup extends AVMetadataGroup implements NSCopying, NSMutableCopying {
  initWithItemsStartDateEndDate(items: NSArray<interop.Object> | Array<interop.Object>, startDate: NSDate, endDate: NSDate | null): this;

  readonly startDate: NSDate;

  readonly endDate: NSDate;

  readonly items: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptureVideoDataOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  setSampleBufferDelegateQueue(sampleBufferDelegate: AVCaptureVideoDataOutputSampleBufferDelegate | null, sampleBufferCallbackQueue: NSObject | null): void;

  readonly sampleBufferDelegate: AVCaptureVideoDataOutputSampleBufferDelegate;

  readonly sampleBufferCallbackQueue: NSObject;

  get videoSettings(): NSDictionary;
  set videoSettings(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  recommendedVideoSettingsForAssetWriterWithOutputFileType(outputFileType: string): NSDictionary;

  availableVideoCodecTypesForAssetWriterWithOutputFileType(outputFileType: string): NSArray;

  recommendedVideoSettingsForVideoCodecTypeAssetWriterOutputFileType(videoCodecType: string, outputFileType: string): NSDictionary;

  recommendedVideoSettingsForVideoCodecTypeAssetWriterOutputFileTypeOutputFileURL(videoCodecType: string, outputFileType: string, outputFileURL: NSURL | null): NSDictionary;

  readonly availableVideoCVPixelFormatTypes: NSArray;

  readonly availableVideoCodecTypes: NSArray;

  minFrameDuration: CMTime;

  alwaysDiscardsLateVideoFrames: boolean;

  automaticallyConfiguresOutputBufferDimensions: boolean;

  deliversPreviewSizedOutputBuffers: boolean;
}

declare class AVSampleBufferGenerator extends NSObject {
  initWithAssetTimebase(asset: AVAsset, timebase: interop.PointerConvertible): this;

  createSampleBufferForRequestError(request: AVSampleBufferRequest, outError: interop.PointerConvertible): interop.Pointer;

  makeBatch(): AVSampleBufferGeneratorBatch;

  createSampleBufferForRequestAddingToBatchError(request: AVSampleBufferRequest, batch: AVSampleBufferGeneratorBatch, outError: interop.PointerConvertible): interop.Pointer;

  static notifyOfDataReadyForSampleBufferCompletionHandler(sbuf: interop.PointerConvertible, completionHandler: (p1: boolean, p2: NSError) => void | null): void;
}

declare class AVCaptureInput extends NSObject {
  readonly ports: NSArray;
}

declare class AVPlayerItemAccessLogEvent extends NSObject implements NSCopying {
  readonly numberOfSegmentsDownloaded: number;

  readonly numberOfMediaRequests: number;

  readonly playbackStartDate: NSDate;

  readonly URI: string;

  readonly serverAddress: string;

  readonly numberOfServerAddressChanges: number;

  readonly playbackSessionID: string;

  readonly playbackStartOffset: number;

  readonly segmentsDownloadedDuration: number;

  readonly durationWatched: number;

  readonly numberOfStalls: number;

  readonly numberOfBytesTransferred: number;

  readonly transferDuration: number;

  readonly observedBitrate: number;

  readonly indicatedBitrate: number;

  readonly indicatedAverageBitrate: number;

  readonly averageVideoBitrate: number;

  readonly averageAudioBitrate: number;

  readonly numberOfDroppedVideoFrames: number;

  readonly startupTime: number;

  readonly downloadOverdue: number;

  readonly observedMaxBitrate: number;

  readonly observedMinBitrate: number;

  readonly observedBitrateStandardDeviation: number;

  readonly playbackType: string;

  readonly mediaRequestsWWAN: number;

  readonly switchBitrate: number;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVFragmentedAsset extends AVURLAsset implements AVFragmentMinding {
  static fragmentedAssetWithURLOptions<This extends abstract new (...args: any) => any>(this: This, URL: NSURL, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  readonly tracks: NSArray;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVFragmentedAssetTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVFragmentedAssetTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  readonly isAssociatedWithFragmentMinder: boolean;
}

declare class AVAsynchronousVideoCompositionRequest extends NSObject implements NSCopying {
  readonly renderContext: AVVideoCompositionRenderContext;

  readonly compositionTime: CMTime;

  readonly sourceTrackIDs: NSArray;

  readonly sourceSampleDataTrackIDs: NSArray;

  readonly videoCompositionInstruction: AVVideoCompositionInstruction;

  sourceFrameByTrackID(trackID: number): interop.Pointer;

  sourceSampleBufferByTrackID(trackID: number): interop.Pointer;

  sourceTimedMetadataByTrackID(trackID: number): AVTimedMetadataGroup;

  finishWithComposedVideoFrame(composedVideoFrame: interop.PointerConvertible): void;

  finishWithError(error: NSError): void;

  finishCancelledRequest(): void;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptureMultiCamSession extends AVCaptureSession {
  static readonly isMultiCamSupported: boolean;

  readonly hardwareCost: number;

  readonly systemPressureCost: number;
}

declare class AVSampleCursor extends NSObject implements NSCopying {
  stepInDecodeOrderByCount(stepCount: number): number;

  stepInPresentationOrderByCount(stepCount: number): number;

  stepByDecodeTimeWasPinned(deltaDecodeTime: CMTime, outWasPinned: interop.PointerConvertible): CMTime;

  stepByPresentationTimeWasPinned(deltaPresentationTime: CMTime, outWasPinned: interop.PointerConvertible): CMTime;

  readonly presentationTimeStamp: CMTime;

  readonly decodeTimeStamp: CMTime;

  comparePositionInDecodeOrderWithPositionOfCursor(cursor: AVSampleCursor): interop.Enum<typeof NSComparisonResult>;

  samplesWithEarlierDecodeTimeStampsMayHaveLaterPresentationTimeStampsThanCursor(cursor: AVSampleCursor): boolean;

  samplesWithLaterDecodeTimeStampsMayHaveEarlierPresentationTimeStampsThanCursor(cursor: AVSampleCursor): boolean;

  readonly currentSampleDuration: CMTime;

  copyCurrentSampleFormatDescription(): interop.Pointer;

  readonly currentSampleSyncInfo: AVSampleCursorSyncInfo;

  readonly currentSampleDependencyInfo: AVSampleCursorDependencyInfo;

  readonly currentSampleDependencyAttachments: NSDictionary;

  readonly currentSampleAudioDependencyInfo: AVSampleCursorAudioDependencyInfo;

  readonly samplesRequiredForDecoderRefresh: number;

  readonly currentChunkStorageURL: NSURL;

  readonly currentChunkStorageRange: AVSampleCursorStorageRange;

  readonly currentChunkInfo: AVSampleCursorChunkInfo;

  readonly currentSampleIndexInChunk: number;

  readonly currentSampleStorageRange: AVSampleCursorStorageRange;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataHumanFullBodyObject extends AVMetadataBodyObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetReaderOutputCaptionAdaptor extends NSObject {
  static assetReaderOutputCaptionAdaptorWithAssetReaderTrackOutput<This extends abstract new (...args: any) => any>(this: This, trackOutput: AVAssetReaderTrackOutput): InstanceType<This>;

  initWithAssetReaderTrackOutput(trackOutput: AVAssetReaderTrackOutput): this;

  readonly assetReaderTrackOutput: AVAssetReaderTrackOutput;

  nextCaptionGroup(): AVCaptionGroup;

  captionsNotPresentInPreviousGroupsInCaptionGroup(captionGroup: AVCaptionGroup): NSArray;

  validationDelegate: AVAssetReaderCaptionValidationHandling | null;
}

declare class AVDelegatingPlaybackCoordinator extends AVPlaybackCoordinator {
  initWithPlaybackControlDelegate(playbackControlDelegate: AVPlaybackCoordinatorPlaybackControlDelegate): this;

  readonly playbackControlDelegate: AVPlaybackCoordinatorPlaybackControlDelegate | null;

  coordinateRateChangeToRateOptions(rate: number, options: interop.Enum<typeof AVDelegatingPlaybackCoordinatorRateChangeOptions>): void;

  coordinateSeekToTimeOptions(time: CMTime, options: interop.Enum<typeof AVDelegatingPlaybackCoordinatorSeekOptions>): void;

  transitionToItemWithIdentifierProposingInitialTimingBasedOnTimebase(itemIdentifier: string | null, snapshotTimebase: interop.PointerConvertible): void;

  readonly currentItemIdentifier: string;

  reapplyCurrentItemStateToPlaybackControlDelegate(): void;
}

declare class AVAssetReader extends NSObject {
  static assetReaderWithAssetError<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset, outError: interop.PointerConvertible): InstanceType<This>;

  initWithAssetError(asset: AVAsset, outError: interop.PointerConvertible): this;

  readonly asset: AVAsset;

  readonly status: interop.Enum<typeof AVAssetReaderStatus>;

  readonly error: NSError;

  timeRange: CMTimeRange;

  readonly outputs: NSArray;

  canAddOutput(output: AVAssetReaderOutput): boolean;

  addOutput(output: AVAssetReaderOutput): void;

  startReading(): boolean;

  cancelReading(): void;
}

declare class AVCaptureDepthDataOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  readonly delegate: AVCaptureDepthDataOutputDelegate;

  readonly delegateCallbackQueue: NSObject;

  alwaysDiscardsLateDepthData: boolean;

  isFilteringEnabled: boolean;
}

declare class AVPlayerItemErrorLog extends NSObject implements NSCopying {
  extendedLogData(): NSData;

  readonly extendedLogDataStringEncoding: number;

  readonly events: NSArray;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataHumanBodyObject extends AVMetadataBodyObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVFragmentedAssetTrack extends AVAssetTrack {
}

declare class AVMutableMediaSelection extends AVMediaSelection {
  selectMediaOptionInMediaSelectionGroup(mediaSelectionOption: AVMediaSelectionOption | null, mediaSelectionGroup: AVMediaSelectionGroup): void;
}

declare class AVZoomRange extends NSObject {
  readonly minZoomFactor: number;

  readonly maxZoomFactor: number;

  containsZoomFactor(zoomFactor: number): boolean;
}

declare class AVContentKeyResponse extends NSObject {
  static contentKeyResponseWithFairPlayStreamingKeyResponseData<This extends abstract new (...args: any) => any>(this: This, keyResponseData: NSData): InstanceType<This>;

  static contentKeyResponseWithClearKeyDataInitializationVector<This extends abstract new (...args: any) => any>(this: This, keyData: NSData, initializationVector: NSData | null): InstanceType<This>;

  static contentKeyResponseWithAuthorizationTokenData<This extends abstract new (...args: any) => any>(this: This, authorizationTokenData: NSData): InstanceType<This>;
}

declare class AVAssetVariantVideoLayoutAttributes extends NSObject {
  readonly stereoViewComponents: interop.Enum<typeof CMStereoViewComponents>;
}

declare class AVFragmentedMovieTrack extends AVMovieTrack {
}

declare class AVPlayerItemVideoOutput extends AVPlayerItemOutput {
  initWithPixelBufferAttributes(pixelBufferAttributes: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  initWithOutputSettings(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  hasNewPixelBufferForItemTime(itemTime: CMTime): boolean;

  copyPixelBufferForItemTimeItemTimeForDisplay(itemTime: CMTime, outItemTimeForDisplay: interop.PointerConvertible): interop.Pointer;

  requestNotificationOfMediaDataChangeWithAdvanceInterval(interval: number): void;

  readonly delegate: AVPlayerItemOutputPullDelegate;

  readonly delegateQueue: NSObject;
}

declare class AVDepthData extends NSObject {
  static depthDataFromDictionaryRepresentationError<This extends abstract new (...args: any) => any>(this: This, imageSourceAuxDataInfoDictionary: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>, outError: interop.PointerConvertible): InstanceType<This>;

  depthDataByConvertingToDepthDataType(depthDataType: number): this;

  depthDataByApplyingExifOrientation(exifOrientation: interop.Enum<typeof CGImagePropertyOrientation>): this;

  depthDataByReplacingDepthDataMapWithPixelBufferError(pixelBuffer: interop.PointerConvertible, outError: interop.PointerConvertible): this;

  readonly availableDepthDataTypes: NSArray;

  dictionaryRepresentationForAuxiliaryDataType(outAuxDataType: interop.PointerConvertible): NSDictionary;

  readonly depthDataType: number;

  readonly depthDataMap: interop.Pointer;

  readonly depthDataQuality: interop.Enum<typeof AVDepthDataQuality>;

  readonly isDepthDataFiltered: boolean;

  readonly depthDataAccuracy: interop.Enum<typeof AVDepthDataAccuracy>;

  readonly cameraCalibrationData: AVCameraCalibrationData;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableCaptionRegion extends AVCaptionRegion {
  init(): this;

  initWithIdentifier(identifier: string): this;

  // @ts-ignore MemberDecl.tsIgnore
  origin: AVCaptionPoint;

  // @ts-ignore MemberDecl.tsIgnore
  size: AVCaptionSize;

  // @ts-ignore MemberDecl.tsIgnore
  scroll: interop.Enum<typeof AVCaptionRegionScroll>;

  // @ts-ignore MemberDecl.tsIgnore
  displayAlignment: interop.Enum<typeof AVCaptionRegionDisplayAlignment>;

  // @ts-ignore MemberDecl.tsIgnore
  writingMode: interop.Enum<typeof AVCaptionRegionWritingMode>;
}

declare class AVAssetDownloadStorageManagementPolicy extends NSObject implements NSCopying, NSMutableCopying {
  readonly priority: string;

  readonly expirationDate: NSDate;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetResourceLoadingRequest extends NSObject {
  readonly request: NSURLRequest;

  readonly isFinished: boolean;

  readonly isCancelled: boolean;

  readonly contentInformationRequest: AVAssetResourceLoadingContentInformationRequest;

  readonly dataRequest: AVAssetResourceLoadingDataRequest;

  response: NSURLResponse;

  redirect: NSURLRequest;

  readonly requestor: AVAssetResourceLoadingRequestor;

  finishLoading(): void;

  finishLoadingWithError(error: NSError | null): void;

  streamingContentKeyRequestDataForAppContentIdentifierOptionsError(appIdentifier: NSData, contentIdentifier: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): NSData;

  persistentContentKeyFromKeyVendorResponseOptionsError(keyVendorResponse: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): NSData;

  finishLoadingWithResponseDataRedirect(response: NSURLResponse | null, data: NSData | null, redirect: NSURLRequest | null): void;
}

declare class AVCaptureAudioDataOutput extends AVCaptureOutput {
  init(): this;

  static new<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  setSampleBufferDelegateQueue(sampleBufferDelegate: AVCaptureAudioDataOutputSampleBufferDelegate | null, sampleBufferCallbackQueue: NSObject | null): void;

  readonly sampleBufferDelegate: AVCaptureAudioDataOutputSampleBufferDelegate;

  readonly sampleBufferCallbackQueue: NSObject;

  recommendedAudioSettingsForAssetWriterWithOutputFileType(outputFileType: string): NSDictionary;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableDateRangeMetadataGroup extends AVDateRangeMetadataGroup {
  // @ts-ignore MemberDecl.tsIgnore
  startDate: NSDate;

  // @ts-ignore MemberDecl.tsIgnore
  endDate: NSDate;

  // @ts-ignore MemberDecl.tsIgnore
  get items(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set items(value: NSArray<interop.Object> | Array<interop.Object>);
}

declare class AVAssetSegmentReportSampleInformation extends NSObject {
  readonly presentationTimeStamp: CMTime;

  readonly offset: number;

  readonly length: number;

  readonly isSyncSample: boolean;
}

declare class AVCapturePhotoBracketSettings extends AVCapturePhotoSettings {
  static photoBracketSettingsWithRawPixelFormatTypeProcessedFormatBracketedSettings<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number, processedFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, bracketedSettings: NSArray<interop.Object> | Array<interop.Object>): InstanceType<This>;

  static photoBracketSettingsWithRawPixelFormatTypeRawFileTypeProcessedFormatProcessedFileTypeBracketedSettings<This extends abstract new (...args: any) => any>(this: This, rawPixelFormatType: number, rawFileType: string | null, processedFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, processedFileType: string | null, bracketedSettings: NSArray<interop.Object> | Array<interop.Object>): InstanceType<This>;

  readonly bracketedSettings: NSArray;

  isLensStabilizationEnabled: boolean;
}

declare class AVPlayerItemMediaDataCollector extends NSObject {
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableComposition extends AVComposition {
  readonly tracks: NSArray;

  // @ts-ignore MemberDecl.tsIgnore
  naturalSize: CGSize;

  static composition<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  static compositionWithURLAssetInitializationOptions<This extends abstract new (...args: any) => any>(this: This, URLAssetInitializationOptions: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  insertTimeRangeOfAssetAtTimeError(timeRange: CMTimeRange, asset: AVAsset, startTime: CMTime, outError: interop.PointerConvertible): boolean;

  insertTimeRangeOfAssetAtTimeCompletionHandler(timeRange: CMTimeRange, asset: AVAsset, startTime: CMTime, completionHandler: (p1: NSError) => void | null): void;

  insertEmptyTimeRange(timeRange: CMTimeRange): void;

  removeTimeRange(timeRange: CMTimeRange): void;

  scaleTimeRangeToDuration(timeRange: CMTimeRange, duration: CMTime): void;

  addMutableTrackWithMediaTypePreferredTrackID(mediaType: string, preferredTrackID: number): AVMutableCompositionTrack;

  removeTrack(track: AVCompositionTrack): void;

  mutableTrackCompatibleWithTrack(track: AVAssetTrack): AVMutableCompositionTrack;

  // @ts-ignore MemberDecl.tsIgnore
  trackWithTrackID(trackID: number): AVMutableCompositionTrack;

  // @ts-ignore MemberDecl.tsIgnore
  loadTrackWithTrackIDCompletionHandler(trackID: number, completionHandler: (p1: AVMutableCompositionTrack, p2: NSError) => void | null): void;

  tracksWithMediaType(mediaType: string): NSArray;

  loadTracksWithMediaTypeCompletionHandler(mediaType: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;

  tracksWithMediaCharacteristic(mediaCharacteristic: string): NSArray;

  loadTracksWithMediaCharacteristicCompletionHandler(mediaCharacteristic: string, completionHandler: (p1: NSArray<interop.Object> | Array<interop.Object>, p2: NSError) => void | null): void;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVPlayerInterstitialEventController extends AVPlayerInterstitialEventMonitor {
  static interstitialEventControllerWithPrimaryPlayer<This extends abstract new (...args: any) => any>(this: This, primaryPlayer: AVPlayer): InstanceType<This>;

  initWithPrimaryPlayer(primaryPlayer: AVPlayer): this;

  // @ts-ignore MemberDecl.tsIgnore
  get events(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set events(value: NSArray<interop.Object> | Array<interop.Object>);

  cancelCurrentEventWithResumptionOffset(resumptionOffset: CMTime): void;
}

declare class AVAssetVariantAudioAttributes extends NSObject {
  readonly formatIDs: NSArray;

  renditionSpecificAttributesForMediaOption(mediaSelectionOption: AVMediaSelectionOption): AVAssetVariantAudioRenditionSpecificAttributes;
}

declare class AVCaptionConversionValidator extends NSObject {
  static captionConversionValidatorWithCaptionsTimeRangeConversionSettings<This extends abstract new (...args: any) => any>(this: This, captions: NSArray<interop.Object> | Array<interop.Object>, timeRange: CMTimeRange, conversionSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): InstanceType<This>;

  initWithCaptionsTimeRangeConversionSettings(captions: NSArray<interop.Object> | Array<interop.Object>, timeRange: CMTimeRange, conversionSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>): this;

  readonly status: interop.Enum<typeof AVCaptionConversionValidatorStatus>;

  readonly captions: NSArray;

  readonly timeRange: CMTimeRange;

  validateCaptionConversionWithWarningHandler(handler: (p1: AVCaptionConversionWarning) => void | null): void;

  stopValidating(): void;

  readonly warnings: NSArray;
}

declare class AVAssetReaderOutput extends NSObject {
  readonly mediaType: string;

  alwaysCopiesSampleData: boolean;

  copyNextSampleBuffer(): interop.Pointer;

  supportsRandomAccess: boolean;

  resetForReadingTimeRanges(timeRanges: NSArray<interop.Object> | Array<interop.Object>): void;

  markConfigurationAsFinal(): void;
}

declare class AVVideoCompositionLayerInstruction extends NSObject implements NSSecureCoding, NSCopying, NSMutableCopying {
  readonly trackID: number;

  getTransformRampForTimeStartTransformEndTransformTimeRange(time: CMTime, startTransform: interop.PointerConvertible, endTransform: interop.PointerConvertible, timeRange: interop.PointerConvertible): boolean;

  getOpacityRampForTimeStartOpacityEndOpacityTimeRange(time: CMTime, startOpacity: interop.PointerConvertible, endOpacity: interop.PointerConvertible, timeRange: interop.PointerConvertible): boolean;

  getCropRectangleRampForTimeStartCropRectangleEndCropRectangleTimeRange(time: CMTime, startCropRectangle: interop.PointerConvertible, endCropRectangle: interop.PointerConvertible, timeRange: interop.PointerConvertible): boolean;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptionRenderer extends NSObject {
  get captions(): NSArray;
  set captions(value: NSArray<interop.Object> | Array<interop.Object>);

  bounds: CGRect;

  captionSceneChangesInRange(consideredTimeRange: CMTimeRange): NSArray;

  renderInContextForTime(ctx: interop.PointerConvertible, time: CMTime): void;
}

declare class AVPlayerItemLegibleOutput extends AVPlayerItemOutput {
  readonly delegate: AVPlayerItemLegibleOutputPushDelegate;

  readonly delegateQueue: NSObject;

  advanceIntervalForDelegateInvocation: number;

  initWithMediaSubtypesForNativeRepresentation(subtypes: NSArray<interop.Object> | Array<interop.Object>): this;

  textStylingResolution: string;
}

declare class AVMetricEvent extends NSObject implements NSSecureCoding {
  readonly date: NSDate;

  readonly mediaTime: CMTime;

  readonly sessionID: string;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVPlayerItemErrorLogEvent extends NSObject implements NSCopying {
  readonly date: NSDate;

  readonly URI: string;

  readonly serverAddress: string;

  readonly playbackSessionID: string;

  readonly errorStatusCode: number;

  readonly errorDomain: string;

  readonly errorComment: string;

  readonly allHTTPResponseHeaderFields: NSDictionary;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetadataBodyObject extends AVMetadataObject implements NSCopying {
  readonly bodyID: number;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVCaptionRuby extends NSObject implements NSCopying, NSSecureCoding {
  initWithText(text: string): this;

  initWithTextPositionAlignment(text: string, position: interop.Enum<typeof AVCaptionRubyPosition>, alignment: interop.Enum<typeof AVCaptionRubyAlignment>): this;

  readonly text: string;

  readonly position: interop.Enum<typeof AVCaptionRubyPosition>;

  readonly alignment: interop.Enum<typeof AVCaptionRubyAlignment>;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVCompositionTrackFormatDescriptionReplacement extends NSObject implements NSSecureCoding {
  readonly originalFormatDescription: interop.Pointer;

  readonly replacementFormatDescription: interop.Pointer;

  static readonly supportsSecureCoding: boolean;

  encodeWithCoder(coder: NSCoder): void;

  initWithCoder(coder: NSCoder): this;
}

declare class AVMetricHLSMediaSegmentRequestEvent extends AVMetricEvent {
  readonly url: NSURL;

  readonly isMapSegment: boolean;

  readonly mediaType: string;

  readonly byteRange: _NSRange;

  readonly indexFileURL: NSURL;

  readonly mediaResourceRequestEvent: AVMetricMediaResourceRequestEvent;
}

declare class AVAssetVariant extends NSObject {
  readonly peakBitRate: number;

  readonly averageBitRate: number;

  readonly videoAttributes: AVAssetVariantVideoAttributes;

  readonly audioAttributes: AVAssetVariantAudioAttributes;
}

declare class AVCaptionGroup extends NSObject {
  initWithCaptionsTimeRange(captions: NSArray<interop.Object> | Array<interop.Object>, timeRange: CMTimeRange): this;

  initWithTimeRange(timeRange: CMTimeRange): this;

  readonly timeRange: CMTimeRange;

  readonly captions: NSArray;
}

declare class AVPlayer extends NSObject {
  init(): this;

  static playerWithURL<This extends abstract new (...args: any) => any>(this: This, URL: NSURL): InstanceType<This>;

  static playerWithPlayerItem<This extends abstract new (...args: any) => any>(this: This, item: AVPlayerItem | null): InstanceType<This>;

  initWithURL(URL: NSURL): this;

  initWithPlayerItem(item: AVPlayerItem | null): this;

  readonly status: interop.Enum<typeof AVPlayerStatus>;

  readonly error: NSError;

  rate: number;

  defaultRate: number;

  play(): void;

  pause(): void;

  readonly timeControlStatus: interop.Enum<typeof AVPlayerTimeControlStatus>;

  readonly reasonForWaitingToPlay: string;

  playImmediatelyAtRate(rate: number): void;

  readonly currentItem: AVPlayerItem;

  replaceCurrentItemWithPlayerItem(item: AVPlayerItem | null): void;

  actionAtItemEnd: interop.Enum<typeof AVPlayerActionAtItemEnd>;

  currentTime(): CMTime;

  seekToDate(date: NSDate): void;

  seekToDateCompletionHandler(date: NSDate, completionHandler: (p1: boolean) => void): void;

  seekToTime(time: CMTime): void;

  seekToTimeToleranceBeforeToleranceAfter(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime): void;

  seekToTimeCompletionHandler(time: CMTime, completionHandler: (p1: boolean) => void): void;

  seekToTimeToleranceBeforeToleranceAfterCompletionHandler(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime, completionHandler: (p1: boolean) => void): void;

  automaticallyWaitsToMinimizeStalling: boolean;

  setRateTimeAtHostTime(rate: number, itemTime: CMTime, hostClockTime: CMTime): void;

  prerollAtRateCompletionHandler(rate: number, completionHandler: (p1: boolean) => void | null): void;

  cancelPendingPrerolls(): void;

  get sourceClock(): interop.Pointer;
  set sourceClock(value: interop.PointerConvertible);

  addPeriodicTimeObserverForIntervalQueueUsingBlock(interval: CMTime, queue: NSObject | null, block: (p1: CMTime) => void): interop.Object;

  addBoundaryTimeObserverForTimesQueueUsingBlock(times: NSArray<interop.Object> | Array<interop.Object>, queue: NSObject | null, block: () => void): interop.Object;

  removeTimeObserver(observer: interop.Object): void;

  volume: number;

  isMuted: boolean;

  appliesMediaSelectionCriteriaAutomatically: boolean;

  setMediaSelectionCriteriaForMediaCharacteristic(criteria: AVPlayerMediaSelectionCriteria | null, mediaCharacteristic: string): void;

  mediaSelectionCriteriaForMediaCharacteristic(mediaCharacteristic: string): AVPlayerMediaSelectionCriteria;

  allowsExternalPlayback: boolean;

  readonly isExternalPlaybackActive: boolean;

  usesExternalPlaybackWhileExternalScreenIsActive: boolean;

  externalPlaybackVideoGravity: string;

  allowsAirPlayVideo: boolean;

  readonly isAirPlayVideoActive: boolean;

  usesAirPlayVideoWhileAirPlayScreenIsActive: boolean;

  readonly outputObscuredDueToInsufficientExternalProtection: boolean;

  static readonly availableHDRModes: interop.Enum<typeof AVPlayerHDRMode>;

  static readonly eligibleForHDRPlayback: boolean;

  preventsDisplaySleepDuringVideoPlayback: boolean;

  audiovisualBackgroundPlaybackPolicy: interop.Enum<typeof AVPlayerAudiovisualBackgroundPlaybackPolicy>;

  readonly playbackCoordinator: AVPlayerPlaybackCoordinator;

  videoOutput: AVPlayerVideoOutput;

  isClosedCaptionDisplayEnabled: boolean;

  get masterClock(): interop.Pointer;
  set masterClock(value: interop.PointerConvertible);
}

declare class AVAssetWriterInput extends NSObject {
  static assetWriterInputWithMediaTypeOutputSettings<This extends abstract new (...args: any) => any>(this: This, mediaType: string, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): InstanceType<This>;

  static assetWriterInputWithMediaTypeOutputSettingsSourceFormatHint<This extends abstract new (...args: any) => any>(this: This, mediaType: string, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, sourceFormatHint: interop.PointerConvertible): InstanceType<This>;

  initWithMediaTypeOutputSettings(mediaType: string, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null): this;

  initWithMediaTypeOutputSettingsSourceFormatHint(mediaType: string, outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, sourceFormatHint: interop.PointerConvertible): this;

  readonly mediaType: string;

  readonly outputSettings: NSDictionary;

  readonly sourceFormatHint: interop.Pointer;

  get metadata(): NSArray;
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly isReadyForMoreMediaData: boolean;

  expectsMediaDataInRealTime: boolean;

  requestMediaDataWhenReadyOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  appendSampleBuffer(sampleBuffer: interop.PointerConvertible): boolean;

  markAsFinished(): void;

  languageCode: string;

  extendedLanguageTag: string;

  naturalSize: CGSize;

  transform: CGAffineTransform;

  preferredVolume: number;

  marksOutputTrackAsEnabled: boolean;

  mediaTimeScale: number;

  preferredMediaChunkDuration: CMTime;

  preferredMediaChunkAlignment: number;

  sampleReferenceBaseURL: NSURL;

  mediaDataLocation: string;

  canAddTrackAssociationWithTrackOfInputType(input: AVAssetWriterInput, trackAssociationType: string): boolean;

  addTrackAssociationWithTrackOfInputType(input: AVAssetWriterInput, trackAssociationType: string): void;

  performsMultiPassEncodingIfSupported: boolean;

  readonly canPerformMultiplePasses: boolean;

  readonly currentPassDescription: AVAssetWriterInputPassDescription;

  respondToEachPassDescriptionOnQueueUsingBlock(queue: NSObject, block: () => void): void;

  markCurrentPassAsFinished(): void;
}

declare class AVCaptureDeferredPhotoProxy extends AVCapturePhoto {
}

declare class AVPlayerItemRenderedLegibleOutput extends AVPlayerItemOutput {
  initWithVideoDisplaySize(videoDisplaySize: CGSize): this;

  readonly delegate: AVPlayerItemRenderedLegibleOutputPushDelegate;

  readonly delegateQueue: NSObject;

  advanceIntervalForDelegateInvocation: number;

  videoDisplaySize: CGSize;
}

declare class AVMetricPlayerItemInitialLikelyToKeepUpEvent extends AVMetricPlayerItemLikelyToKeepUpEvent {
  readonly playlistRequestEvents: NSArray;

  readonly mediaSegmentRequestEvents: NSArray;

  readonly contentKeyRequestEvents: NSArray;
}

declare class AVMetadataSalientObject extends AVMetadataObject implements NSCopying {
  readonly objectID: number;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVPlayerItemIntegratedTimeline extends NSObject {
  readonly currentSnapshot: AVPlayerItemIntegratedTimelineSnapshot;

  readonly currentTime: CMTime;

  readonly currentDate: NSDate;

  seekToTimeToleranceBeforeToleranceAfterCompletionHandler(time: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime, completionHandler: (p1: boolean) => void | null): void;

  seekToDateCompletionHandler(date: NSDate, completionHandler: (p1: boolean) => void | null): void;

  addPeriodicTimeObserverForIntervalQueueUsingBlock(interval: CMTime, queue: NSObject | null, block: (p1: CMTime) => void): AVPlayerItemIntegratedTimelineObserver;

  addBoundaryTimeObserverForSegmentOffsetsIntoSegmentQueueUsingBlock(segment: AVPlayerItemSegment, offsetsIntoSegment: NSArray<interop.Object> | Array<interop.Object>, queue: NSObject | null, block: (p1: boolean) => void): AVPlayerItemIntegratedTimelineObserver;

  removeTimeObserver(observer: AVPlayerItemIntegratedTimelineObserver): void;
}

declare class AVAssetWriter extends NSObject {
  static assetWriterWithURLFileTypeError<This extends abstract new (...args: any) => any>(this: This, outputURL: NSURL, outputFileType: string, outError: interop.PointerConvertible): InstanceType<This>;

  initWithURLFileTypeError(outputURL: NSURL, outputFileType: string, outError: interop.PointerConvertible): this;

  initWithContentType(outputContentType: UTType): this;

  readonly outputURL: NSURL;

  readonly outputFileType: string;

  readonly availableMediaTypes: NSArray;

  readonly status: interop.Enum<typeof AVAssetWriterStatus>;

  readonly error: NSError;

  get metadata(): NSArray;
  set metadata(value: NSArray<interop.Object> | Array<interop.Object>);

  shouldOptimizeForNetworkUse: boolean;

  directoryForTemporaryFiles: NSURL;

  readonly inputs: NSArray;

  canApplyOutputSettingsForMediaType(outputSettings: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, mediaType: string): boolean;

  canAddInput(input: AVAssetWriterInput): boolean;

  addInput(input: AVAssetWriterInput): void;

  startWriting(): boolean;

  startSessionAtSourceTime(startTime: CMTime): void;

  endSessionAtSourceTime(endTime: CMTime): void;

  cancelWriting(): void;

  finishWriting(): boolean;

  finishWritingWithCompletionHandler(handler: () => void): void;

  movieFragmentInterval: CMTime;

  initialMovieFragmentInterval: CMTime;

  initialMovieFragmentSequenceNumber: number;

  producesCombinableFragments: boolean;

  overallDurationHint: CMTime;

  movieTimeScale: number;

  canAddInputGroup(inputGroup: AVAssetWriterInputGroup): boolean;

  addInputGroup(inputGroup: AVAssetWriterInputGroup): void;

  readonly inputGroups: NSArray;

  preferredOutputSegmentInterval: CMTime;

  initialSegmentStartTime: CMTime;

  outputFileTypeProfile: string;

  delegate: AVAssetWriterDelegate;

  flushSegment(): void;
}

declare class AVMetadataCatBodyObject extends AVMetadataBodyObject implements NSCopying {
  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVPlayerMediaSelectionCriteria extends NSObject {
  readonly preferredLanguages: NSArray;

  readonly preferredMediaCharacteristics: NSArray;

  readonly principalMediaCharacteristics: NSArray;

  initWithPreferredLanguagesPreferredMediaCharacteristics(preferredLanguages: NSArray<interop.Object> | Array<interop.Object> | null, preferredMediaCharacteristics: NSArray<interop.Object> | Array<interop.Object> | null): this;

  initWithPrincipalMediaCharacteristicsPreferredLanguagesPreferredMediaCharacteristics(principalMediaCharacteristics: NSArray<interop.Object> | Array<interop.Object> | null, preferredLanguages: NSArray<interop.Object> | Array<interop.Object> | null, preferredMediaCharacteristics: NSArray<interop.Object> | Array<interop.Object> | null): this;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableMetadataItem extends AVMetadataItem {
  // @ts-ignore MemberDecl.tsIgnore
  identifier: string;

  // @ts-ignore MemberDecl.tsIgnore
  extendedLanguageTag: string;

  // @ts-ignore MemberDecl.tsIgnore
  locale: NSLocale;

  // @ts-ignore MemberDecl.tsIgnore
  time: CMTime;

  // @ts-ignore MemberDecl.tsIgnore
  duration: CMTime;

  // @ts-ignore MemberDecl.tsIgnore
  dataType: string;

  // @ts-ignore MemberDecl.tsIgnore
  value: NSCopying;

  // @ts-ignore MemberDecl.tsIgnore
  get extraAttributes(): NSDictionary;
  // @ts-ignore MemberDecl.tsIgnore
  set extraAttributes(value: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object>);

  static metadataItem(): AVMutableMetadataItem;

  // @ts-ignore MemberDecl.tsIgnore
  startDate: NSDate;

  // @ts-ignore MemberDecl.tsIgnore
  keySpace: string;

  // @ts-ignore MemberDecl.tsIgnore
  key: NSCopying;
}

declare class AVContentKey extends NSObject {
  readonly contentKeySpecifier: AVContentKeySpecifier;

  readonly externalContentProtectionStatus: interop.Enum<typeof AVExternalContentProtectionStatus>;

  revoke(): void;
}

declare class AVCaptionConversionTimeRangeAdjustment extends AVCaptionConversionAdjustment {
  readonly startTimeOffset: CMTime;

  readonly durationOffset: CMTime;
}

declare class AVAssetDownloadConfiguration extends NSObject {
  static downloadConfigurationWithAssetTitle<This extends abstract new (...args: any) => any>(this: This, asset: AVURLAsset, title: string): InstanceType<This>;

  artworkData: NSData;

  readonly primaryContentConfiguration: AVAssetDownloadContentConfiguration;

  get auxiliaryContentConfigurations(): NSArray;
  set auxiliaryContentConfigurations(value: NSArray<interop.Object> | Array<interop.Object>);

  optimizesAuxiliaryContentConfigurations: boolean;
}

declare class AVPlayerItemTrack extends NSObject {
  readonly assetTrack: AVAssetTrack;

  isEnabled: boolean;

  readonly currentVideoFrameRate: number;
}

declare class AVVideoCompositionRenderContext extends NSObject {
  readonly size: CGSize;

  readonly renderTransform: CGAffineTransform;

  readonly renderScale: number;

  readonly pixelAspectRatio: AVPixelAspectRatio;

  readonly edgeWidths: AVEdgeWidths;

  readonly highQualityRendering: boolean;

  readonly videoComposition: AVVideoComposition;

  newPixelBuffer(): interop.Pointer;
}

declare class AVAssetWriterInputMetadataAdaptor extends NSObject {
  static assetWriterInputMetadataAdaptorWithAssetWriterInput<This extends abstract new (...args: any) => any>(this: This, input: AVAssetWriterInput): InstanceType<This>;

  initWithAssetWriterInput(input: AVAssetWriterInput): this;

  readonly assetWriterInput: AVAssetWriterInput;

  appendTimedMetadataGroup(timedMetadataGroup: AVTimedMetadataGroup): boolean;
}

declare class AVCapturePhoto extends NSObject {
  readonly timestamp: CMTime;

  readonly isRawPhoto: boolean;

  readonly pixelBuffer: interop.Pointer;

  readonly previewPixelBuffer: interop.Pointer;

  readonly embeddedThumbnailPhotoFormat: NSDictionary;

  readonly depthData: AVDepthData;

  readonly portraitEffectsMatte: AVPortraitEffectsMatte;

  semanticSegmentationMatteForType(semanticSegmentationMatteType: string): AVSemanticSegmentationMatte;

  readonly metadata: NSDictionary;

  readonly cameraCalibrationData: AVCameraCalibrationData;

  readonly resolvedSettings: AVCaptureResolvedPhotoSettings;

  readonly photoCount: number;

  readonly sourceDeviceType: string;

  readonly constantColorConfidenceMap: interop.Pointer;

  readonly constantColorCenterWeightedMeanConfidenceLevel: number;

  readonly isConstantColorFallbackPhoto: boolean;

  fileDataRepresentation(): NSData;

  fileDataRepresentationWithCustomizer(customizer: AVCapturePhotoFileDataRepresentationCustomizer): NSData;

  fileDataRepresentationWithReplacementMetadataReplacementEmbeddedThumbnailPhotoFormatReplacementEmbeddedThumbnailPixelBufferReplacementDepthData(replacementMetadata: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, replacementEmbeddedThumbnailPhotoFormat: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, replacementEmbeddedThumbnailPixelBuffer: interop.PointerConvertible, replacementDepthData: AVDepthData | null): NSData;

  CGImageRepresentation(): interop.Pointer;

  previewCGImageRepresentation(): interop.Pointer;

  readonly bracketSettings: AVCaptureBracketedStillImageSettings;

  readonly sequenceCount: number;

  readonly lensStabilizationStatus: interop.Enum<typeof AVCaptureLensStabilizationStatus>;
}

declare class AVCaptureDevice extends NSObject {
  static devices(): NSArray;

  static devicesWithMediaType(mediaType: string): NSArray;

  static defaultDeviceWithMediaType(mediaType: string): AVCaptureDevice;

  static deviceWithUniqueID(deviceUniqueID: string): AVCaptureDevice;

  readonly uniqueID: string;

  readonly modelID: string;

  readonly localizedName: string;

  readonly manufacturer: string;

  hasMediaType(mediaType: string): boolean;

  lockForConfiguration(outError: interop.PointerConvertible): boolean;

  unlockForConfiguration(): void;

  supportsAVCaptureSessionPreset(preset: string): boolean;

  readonly isConnected: boolean;

  readonly isSuspended: boolean;

  readonly formats: NSArray;

  activeFormat: AVCaptureDeviceFormat;

  activeVideoMinFrameDuration: CMTime;

  activeVideoMaxFrameDuration: CMTime;

  isAutoVideoFrameRateEnabled: boolean;

  readonly position: interop.Enum<typeof AVCaptureDevicePosition>;

  readonly deviceType: string;

  static defaultDeviceWithDeviceTypeMediaTypePosition(deviceType: string, mediaType: string | null, position: interop.Enum<typeof AVCaptureDevicePosition>): AVCaptureDevice;

  static userPreferredCamera: AVCaptureDevice;

  static readonly systemPreferredCamera: AVCaptureDevice;

  readonly systemPressureState: AVCaptureSystemPressureState;

  readonly isVirtualDevice: boolean;

  readonly constituentDevices: NSArray;

  readonly virtualDeviceSwitchOverVideoZoomFactors: NSArray;

  setPrimaryConstituentDeviceSwitchingBehaviorRestrictedSwitchingBehaviorConditions(switchingBehavior: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>, restrictedSwitchingBehaviorConditions: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>): void;

  readonly primaryConstituentDeviceSwitchingBehavior: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>;

  readonly primaryConstituentDeviceRestrictedSwitchingBehaviorConditions: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>;

  readonly activePrimaryConstituentDeviceSwitchingBehavior: interop.Enum<typeof AVCapturePrimaryConstituentDeviceSwitchingBehavior>;

  readonly activePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions: interop.Enum<typeof AVCapturePrimaryConstituentDeviceRestrictedSwitchingBehaviorConditions>;

  readonly activePrimaryConstituentDevice: AVCaptureDevice;

  readonly supportedFallbackPrimaryConstituentDevices: NSArray;

  get fallbackPrimaryConstituentDevices(): NSArray;
  set fallbackPrimaryConstituentDevices(value: NSArray<interop.Object> | Array<interop.Object>);

  readonly hasFlash: boolean;

  readonly isFlashAvailable: boolean;

  readonly isFlashActive: boolean;

  isFlashModeSupported(flashMode: interop.Enum<typeof AVCaptureFlashMode>): boolean;

  flashMode: interop.Enum<typeof AVCaptureFlashMode>;

  readonly hasTorch: boolean;

  readonly isTorchAvailable: boolean;

  readonly isTorchActive: boolean;

  readonly torchLevel: number;

  isTorchModeSupported(torchMode: interop.Enum<typeof AVCaptureTorchMode>): boolean;

  torchMode: interop.Enum<typeof AVCaptureTorchMode>;

  setTorchModeOnWithLevelError(torchLevel: number, outError: interop.PointerConvertible): boolean;

  isFocusModeSupported(focusMode: interop.Enum<typeof AVCaptureFocusMode>): boolean;

  readonly isLockingFocusWithCustomLensPositionSupported: boolean;

  focusMode: interop.Enum<typeof AVCaptureFocusMode>;

  readonly isFocusPointOfInterestSupported: boolean;

  focusPointOfInterest: CGPoint;

  readonly isAdjustingFocus: boolean;

  readonly isAutoFocusRangeRestrictionSupported: boolean;

  autoFocusRangeRestriction: interop.Enum<typeof AVCaptureAutoFocusRangeRestriction>;

  readonly isSmoothAutoFocusSupported: boolean;

  isSmoothAutoFocusEnabled: boolean;

  automaticallyAdjustsFaceDrivenAutoFocusEnabled: boolean;

  isFaceDrivenAutoFocusEnabled: boolean;

  readonly lensPosition: number;

  setFocusModeLockedWithLensPositionCompletionHandler(lensPosition: number, handler: (p1: CMTime) => void | null): void;

  readonly minimumFocusDistance: number;

  isExposureModeSupported(exposureMode: interop.Enum<typeof AVCaptureExposureMode>): boolean;

  exposureMode: interop.Enum<typeof AVCaptureExposureMode>;

  readonly isExposurePointOfInterestSupported: boolean;

  exposurePointOfInterest: CGPoint;

  automaticallyAdjustsFaceDrivenAutoExposureEnabled: boolean;

  isFaceDrivenAutoExposureEnabled: boolean;

  activeMaxExposureDuration: CMTime;

  readonly isAdjustingExposure: boolean;

  readonly lensAperture: number;

  readonly exposureDuration: CMTime;

  readonly ISO: number;

  setExposureModeCustomWithDurationISOCompletionHandler(duration: CMTime, ISO: number, handler: (p1: CMTime) => void | null): void;

  readonly exposureTargetOffset: number;

  readonly exposureTargetBias: number;

  readonly minExposureTargetBias: number;

  readonly maxExposureTargetBias: number;

  setExposureTargetBiasCompletionHandler(bias: number, handler: (p1: CMTime) => void | null): void;

  isGlobalToneMappingEnabled: boolean;

  isWhiteBalanceModeSupported(whiteBalanceMode: interop.Enum<typeof AVCaptureWhiteBalanceMode>): boolean;

  readonly isLockingWhiteBalanceWithCustomDeviceGainsSupported: boolean;

  whiteBalanceMode: interop.Enum<typeof AVCaptureWhiteBalanceMode>;

  readonly isAdjustingWhiteBalance: boolean;

  readonly deviceWhiteBalanceGains: AVCaptureWhiteBalanceGains;

  readonly grayWorldDeviceWhiteBalanceGains: AVCaptureWhiteBalanceGains;

  readonly maxWhiteBalanceGain: number;

  setWhiteBalanceModeLockedWithDeviceWhiteBalanceGainsCompletionHandler(whiteBalanceGains: AVCaptureWhiteBalanceGains, handler: (p1: CMTime) => void | null): void;

  chromaticityValuesForDeviceWhiteBalanceGains(whiteBalanceGains: AVCaptureWhiteBalanceGains): AVCaptureWhiteBalanceChromaticityValues;

  deviceWhiteBalanceGainsForChromaticityValues(chromaticityValues: AVCaptureWhiteBalanceChromaticityValues): AVCaptureWhiteBalanceGains;

  temperatureAndTintValuesForDeviceWhiteBalanceGains(whiteBalanceGains: AVCaptureWhiteBalanceGains): AVCaptureWhiteBalanceTemperatureAndTintValues;

  deviceWhiteBalanceGainsForTemperatureAndTintValues(tempAndTintValues: AVCaptureWhiteBalanceTemperatureAndTintValues): AVCaptureWhiteBalanceGains;

  isSubjectAreaChangeMonitoringEnabled: boolean;

  readonly isLowLightBoostSupported: boolean;

  readonly isLowLightBoostEnabled: boolean;

  automaticallyEnablesLowLightBoostWhenAvailable: boolean;

  videoZoomFactor: number;

  rampToVideoZoomFactorWithRate(factor: number, rate: number): void;

  readonly isRampingVideoZoom: boolean;

  cancelVideoZoomRamp(): void;

  readonly dualCameraSwitchOverVideoZoomFactor: number;

  readonly displayVideoZoomFactorMultiplier: number;

  static authorizationStatusForMediaType(mediaType: string): interop.Enum<typeof AVAuthorizationStatus>;

  static requestAccessForMediaTypeCompletionHandler(mediaType: string, handler: (p1: boolean) => void): void;

  automaticallyAdjustsVideoHDREnabled: boolean;

  isVideoHDREnabled: boolean;

  activeColorSpace: interop.Enum<typeof AVCaptureColorSpace>;

  activeDepthDataFormat: AVCaptureDeviceFormat;

  activeDepthDataMinFrameDuration: CMTime;

  readonly minAvailableVideoZoomFactor: number;

  readonly maxAvailableVideoZoomFactor: number;

  readonly isGeometricDistortionCorrectionSupported: boolean;

  isGeometricDistortionCorrectionEnabled: boolean;

  static extrinsicMatrixFromDeviceToDevice(fromDevice: AVCaptureDevice, toDevice: AVCaptureDevice): NSData;

  static centerStageControlMode: interop.Enum<typeof AVCaptureCenterStageControlMode>;

  static isCenterStageEnabled: boolean;

  readonly isCenterStageActive: boolean;

  centerStageRectOfInterest: CGRect;

  static readonly isPortraitEffectEnabled: boolean;

  readonly isPortraitEffectActive: boolean;

  static readonly reactionEffectsEnabled: boolean;

  static readonly reactionEffectGesturesEnabled: boolean;

  readonly canPerformReactionEffects: boolean;

  readonly availableReactionTypes: NSSet;

  performEffectForReaction(reactionType: string): void;

  readonly reactionEffectsInProgress: NSArray;

  static readonly isBackgroundReplacementEnabled: boolean;

  readonly isBackgroundReplacementActive: boolean;

  readonly isContinuityCamera: boolean;

  readonly companionDeskViewCamera: AVCaptureDevice;

  static readonly preferredMicrophoneMode: interop.Enum<typeof AVCaptureMicrophoneMode>;

  static readonly activeMicrophoneMode: interop.Enum<typeof AVCaptureMicrophoneMode>;

  static showSystemUserInterface(systemUserInterface: interop.Enum<typeof AVCaptureSystemUserInterface>): void;

  readonly spatialCaptureDiscomfortReasons: NSSet;

  static readonly isStudioLightEnabled: boolean;

  readonly isStudioLightActive: boolean;
}

declare class AVPersistableContentKeyRequest extends AVContentKeyRequest {
  persistableContentKeyFromKeyVendorResponseOptionsError(keyVendorResponse: NSData, options: NSDictionary<interop.Object, interop.Object> | Record<interop.Object, interop.Object> | null, outError: interop.PointerConvertible): NSData;
}

declare class AVMetricEventStream extends NSObject {
  static eventStream<This extends abstract new (...args: any) => any>(this: This): InstanceType<This>;

  addPublisher(publisher: AVMetricEventStreamPublisher): boolean;

  setSubscriberQueue(subscriber: AVMetricEventStreamSubscriber, queue: NSObject | null): boolean;

  subscribeToMetricEvent(metricEventClass: interop.Object): void;

  subscribeToMetricEvents(metricEventClasses: NSArray<interop.Object> | Array<interop.Object>): void;

  subscribeToAllMetricEvents(): void;
}

declare class AVAssetImageGenerator extends NSObject {
  readonly asset: AVAsset;

  appliesPreferredTrackTransform: boolean;

  maximumSize: CGSize;

  apertureMode: string;

  dynamicRangePolicy: string;

  videoComposition: AVVideoComposition;

  readonly customVideoCompositor: AVVideoCompositing;

  requestedTimeToleranceBefore: CMTime;

  requestedTimeToleranceAfter: CMTime;

  static assetImageGeneratorWithAsset<This extends abstract new (...args: any) => any>(this: This, asset: AVAsset): InstanceType<This>;

  initWithAsset(asset: AVAsset): this;

  copyCGImageAtTimeActualTimeError(requestedTime: CMTime, actualTime: interop.PointerConvertible, outError: interop.PointerConvertible): interop.Pointer;

  generateCGImagesAsynchronouslyForTimesCompletionHandler(requestedTimes: NSArray<interop.Object> | Array<interop.Object>, handler: (p1: CMTime, p2: interop.PointerConvertible, p3: CMTime, p4: interop.Enum<typeof AVAssetImageGeneratorResult>, p5: NSError) => void): void;

  generateCGImageAsynchronouslyForTimeCompletionHandler(requestedTime: CMTime, handler: (p1: interop.PointerConvertible, p2: CMTime, p3: NSError) => void | null): void;

  cancelAllCGImageGeneration(): void;
}

declare class AVCaptureDeviceFormat extends NSObject {
  readonly mediaType: string;

  readonly formatDescription: interop.Pointer;

  readonly videoSupportedFrameRateRanges: NSArray;

  readonly videoFieldOfView: number;

  readonly isVideoBinned: boolean;

  isVideoStabilizationModeSupported(videoStabilizationMode: interop.Enum<typeof AVCaptureVideoStabilizationMode>): boolean;

  readonly isVideoStabilizationSupported: boolean;

  readonly videoMaxZoomFactor: number;

  readonly videoZoomFactorUpscaleThreshold: number;

  readonly systemRecommendedVideoZoomRange: AVZoomRange;

  readonly minExposureDuration: CMTime;

  readonly maxExposureDuration: CMTime;

  readonly systemRecommendedExposureBiasRange: AVExposureBiasRange;

  readonly minISO: number;

  readonly maxISO: number;

  readonly isGlobalToneMappingSupported: boolean;

  readonly isVideoHDRSupported: boolean;

  readonly highResolutionStillImageDimensions: CMVideoDimensions;

  readonly isHighPhotoQualitySupported: boolean;

  readonly isHighestPhotoQualitySupported: boolean;

  readonly autoFocusSystem: interop.Enum<typeof AVCaptureAutoFocusSystem>;

  readonly supportedColorSpaces: NSArray;

  readonly videoMinZoomFactorForDepthDataDelivery: number;

  readonly videoMaxZoomFactorForDepthDataDelivery: number;

  readonly supportedVideoZoomFactorsForDepthDataDelivery: NSArray;

  readonly supportedVideoZoomRangesForDepthDataDelivery: NSArray;

  readonly zoomFactorsOutsideOfVideoZoomRangesForDepthDeliverySupported: boolean;

  readonly supportedDepthDataFormats: NSArray;

  readonly unsupportedCaptureOutputClasses: NSArray;

  readonly supportedMaxPhotoDimensions: NSArray;

  readonly secondaryNativeResolutionZoomFactors: NSArray;

  readonly isAutoVideoFrameRateSupported: boolean;

  readonly isPortraitEffectsMatteStillImageDeliverySupported: boolean;

  readonly isMultiCamSupported: boolean;

  readonly isSpatialVideoCaptureSupported: boolean;

  readonly geometricDistortionCorrectedVideoFieldOfView: number;

  readonly isCenterStageSupported: boolean;

  readonly videoMinZoomFactorForCenterStage: number;

  readonly videoMaxZoomFactorForCenterStage: number;

  readonly videoFrameRateRangeForCenterStage: AVFrameRateRange;

  readonly isPortraitEffectSupported: boolean;

  readonly videoFrameRateRangeForPortraitEffect: AVFrameRateRange;

  readonly isStudioLightSupported: boolean;

  readonly videoFrameRateRangeForStudioLight: AVFrameRateRange;

  readonly reactionEffectsSupported: boolean;

  readonly videoFrameRateRangeForReactionEffectsInProgress: AVFrameRateRange;

  readonly isBackgroundReplacementSupported: boolean;

  readonly videoFrameRateRangeForBackgroundReplacement: AVFrameRateRange;
}

declare class AVMetadataFaceObject extends AVMetadataObject implements NSCopying {
  readonly faceID: number;

  readonly hasRollAngle: boolean;

  readonly rollAngle: number;

  readonly hasYawAngle: boolean;

  readonly yawAngle: number;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVMetricContentKeyRequestEvent extends AVMetricEvent {
  readonly contentKeySpecifier: AVContentKeySpecifier;

  readonly mediaType: string;

  readonly isClientInitiated: boolean;

  readonly mediaResourceRequestEvent: AVMetricMediaResourceRequestEvent;
}

// @ts-ignore ClassDecl.tsIgnore
declare class AVMutableTimedMetadataGroup extends AVTimedMetadataGroup {
  // @ts-ignore MemberDecl.tsIgnore
  timeRange: CMTimeRange;

  // @ts-ignore MemberDecl.tsIgnore
  get items(): NSArray;
  // @ts-ignore MemberDecl.tsIgnore
  set items(value: NSArray<interop.Object> | Array<interop.Object>);
}

declare class AVTimedMetadataGroup extends AVMetadataGroup implements NSCopying, NSMutableCopying {
  initWithItemsTimeRange(items: NSArray<interop.Object> | Array<interop.Object>, timeRange: CMTimeRange): this;

  initWithSampleBuffer(sampleBuffer: interop.PointerConvertible): this;

  readonly timeRange: CMTimeRange;

  readonly items: NSArray;

  copyFormatDescription(): interop.Pointer;

  copyWithZone(zone: interop.PointerConvertible): interop.Object;

  mutableCopyWithZone(zone: interop.PointerConvertible): interop.Object;
}

declare class AVAssetVariantVideoAttributes extends NSObject {
  readonly videoRange: string;

  readonly codecTypes: NSArray;

  readonly presentationSize: CGSize;

  readonly nominalFrameRate: number;

  readonly videoLayoutAttributes: NSArray;
}

